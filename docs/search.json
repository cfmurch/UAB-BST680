[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BST680 2024",
    "section": "",
    "text": "This is the website for BST680 for 2024\nNavigation can be done from the navbar\nTo download exercise .R and .qmd files, go to the Downloads section"
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html",
    "href": "Lectures/06_Adv_Visual/index.html",
    "title": "Advanced Visualization",
    "section": "",
    "text": "Data Reading\nggplot2 Review\nAdditional Geoms\nAdvanced Aesthetics\nLayering for Communication",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#agenda",
    "href": "Lectures/06_Adv_Visual/index.html#agenda",
    "title": "Advanced Visualization",
    "section": "Agenda",
    "text": "Agenda\n\n\n\nData Reading\nggplot2 Review\nAdditional Geoms\nAdvanced Aesthetics\nLayering for Communication",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---many-options",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---many-options",
    "title": "Advanced Visualization",
    "section": "Data Reading - Many Options",
    "text": "Data Reading - Many Options\n\nBase R can use read.table() and more specific variants like read.csv() and read.delim()\n\n\n\nImportant arguments are the header (take first row as column names) and the delimiter which defines how your columns are separated\nCommon delimiters are a space ( ), a tab (\\t), commas (,) and pipes (|)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---many-packages",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---many-packages",
    "title": "Advanced Visualization",
    "section": "Data Reading - Many Packages",
    "text": "Data Reading - Many Packages\n\nSeveral packages can be used to read other more specialized file types\n\nhaven for SAS, SPSS, and Stata files\nhttr2 for general API connections\ngooglesheets4 to interface with Google Sheets\njsonlite for JSON exchange files\nreadxl, xlsx, and openxlsx2 all engage with Excel workbooks\n\nWe focus on readxl as part of the tidyverse",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---supermarket-transactions",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---supermarket-transactions",
    "title": "Advanced Visualization",
    "section": "Data Reading - Supermarket Transactions",
    "text": "Data Reading - Supermarket Transactions\n\nA widely used dataset in data science is called “Supermarket Transactions”\nOver 14,000 observations i.e. transations\nSixteen variables\nCan be found online as a .xlsx file\nUgly as sin but very realistic",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---supermarket-start-point",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---supermarket-start-point",
    "title": "Advanced Visualization",
    "section": "Data Reading - Supermarket Start Point",
    "text": "Data Reading - Supermarket Start Point",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---supermarket-goal",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---supermarket-goal",
    "title": "Advanced Visualization",
    "section": "Data Reading - Supermarket Goal",
    "text": "Data Reading - Supermarket Goal\n\nglimpse(supermarket, width = 100)\n\nRows: 14,059\nColumns: 16\n$ transaction        &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, …\n$ purchase_date      &lt;dttm&gt; 2011-12-18, 2011-12-20, 2011-12-21, 2011-12-21, 2011-12-22, 2011-12-22…\n$ customer_id        &lt;dbl&gt; 7223, 7841, 8374, 9619, 1900, 6696, 9673, 354, 1293, 7938, 9357, 3097, …\n$ gender             &lt;chr&gt; \"F\", \"M\", \"F\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"…\n$ marital_status     &lt;chr&gt; \"S\", \"M\", \"M\", \"M\", \"S\", \"M\", \"S\", \"M\", \"M\", \"S\", \"M\", \"M\", \"S\", \"M\", \"…\n$ homeowner          &lt;chr&gt; \"Y\", \"Y\", \"N\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"…\n$ children           &lt;dbl&gt; 2, 5, 2, 3, 3, 3, 2, 2, 3, 1, 0, 1, 3, 3, 0, 3, 1, 0, 2, 5, 1, 2, 2, 4,…\n$ annual_income      &lt;chr&gt; \"$30K - $50K\", \"$70K - $90K\", \"$50K - $70K\", \"$30K - $50K\", \"$130K - $1…\n$ city               &lt;chr&gt; \"Los Angeles\", \"Los Angeles\", \"Bremerton\", \"Portland\", \"Beverly Hills\",…\n$ state_or_province  &lt;chr&gt; \"CA\", \"CA\", \"WA\", \"OR\", \"CA\", \"CA\", \"OR\", \"WA\", \"WA\", \"CA\", \"CA\", \"CA\",…\n$ country            &lt;chr&gt; \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"…\n$ product_family     &lt;chr&gt; \"Food\", \"Food\", \"Food\", \"Food\", \"Drink\", \"Food\", \"Food\", \"Food\", \"Non-C…\n$ product_department &lt;chr&gt; \"Snack Foods\", \"Produce\", \"Snack Foods\", \"Snacks\", \"Beverages\", \"Deli\",…\n$ product_category   &lt;chr&gt; \"Snack Foods\", \"Vegetables\", \"Snack Foods\", \"Candy\", \"Carbonated Bevera…\n$ units_sold         &lt;dbl&gt; 5, 5, 3, 4, 4, 3, 4, 6, 1, 2, 3, 5, 4, 4, 5, 5, 5, 3, 5, 5, 4, 5, 5, 4,…\n$ revenue            &lt;dbl&gt; 27.38, 14.90, 5.52, 4.44, 14.00, 4.37, 13.78, 7.34, 2.41, 8.96, 11.82, …",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---import-with-readxl",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---import-with-readxl",
    "title": "Advanced Visualization",
    "section": "Data Reading - Import with readxl",
    "text": "Data Reading - Import with readxl\n\nreadxl::read_excel() can read specific sheets into R as tibbles\n\n\nsupermarket &lt;- readxl::read_excel(\n  path  = \"data/Supermarket Transactions.xlsx\",\n  sheet = \"Data\"\n)\n\nsupermarket[1:2, 1:3]\n\n# A tibble: 2 × 3\n  Transaction `Purchase Date`     `Customer ID`\n        &lt;dbl&gt; &lt;dttm&gt;                      &lt;dbl&gt;\n1           1 2011-12-18 00:00:00          7223\n2           2 2011-12-20 00:00:00          7841\n\n\n\nBut what do we notice about the first three columns names",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---variable-names",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---variable-names",
    "title": "Advanced Visualization",
    "section": "Data Reading - Variable Names",
    "text": "Data Reading - Variable Names\n\nThe names are informative but a little too human friendly\nThe variable names have spaces and are written in Title Case\nNothing wrong with this per se but it makes workflows difficult\n\nNeed backticks like supermarket$`Purchase Date`\n\njanitor is an R package for examining and cleaning data\n\n\n\n\n\n\n\nTip\n\n\nRemember, write data for computers and code for humans",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---always-thank-your-janitor",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---always-thank-your-janitor",
    "title": "Advanced Visualization",
    "section": "Data Reading - Always Thank Your janitor",
    "text": "Data Reading - Always Thank Your janitor\n\n\nhttps://allisonhorst.com/r-packages-functions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---clean-names",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---clean-names",
    "title": "Advanced Visualization",
    "section": "Data Reading - Clean Names",
    "text": "Data Reading - Clean Names\n\nMany options for case from clean_names()\n\n\nsnake_case\n\n\n\njanitor::clean_names(supermarket, case = 'snake')[1:2, 1:3]\n\n# A tibble: 2 × 3\n  transaction purchase_date       customer_id\n        &lt;dbl&gt; &lt;dttm&gt;                    &lt;dbl&gt;\n1           1 2011-12-18 00:00:00        7223\n2           2 2011-12-20 00:00:00        7841",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---clean-names-1",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---clean-names-1",
    "title": "Advanced Visualization",
    "section": "Data Reading - Clean Names",
    "text": "Data Reading - Clean Names\n\nMany options for case from clean_names()\n\n\nlowerCamel\n\n\n\njanitor::clean_names(supermarket, case = 'lower_camel')[1:2, 1:3]\n\n# A tibble: 2 × 3\n  transaction purchaseDate        customerId\n        &lt;dbl&gt; &lt;dttm&gt;                   &lt;dbl&gt;\n1           1 2011-12-18 00:00:00       7223\n2           2 2011-12-20 00:00:00       7841",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#data-reading---clean-names-2",
    "href": "Lectures/06_Adv_Visual/index.html#data-reading---clean-names-2",
    "title": "Advanced Visualization",
    "section": "Data Reading - Clean Names",
    "text": "Data Reading - Clean Names\n\nMany options for case from clean_names()\n\n\nSCREAMING_SNAKE\n\n\n\njanitor::clean_names(supermarket, case = 'screaming_snake')[1:2, 1:3]\n\n# A tibble: 2 × 3\n  TRANSACTION PURCHASE_DATE       CUSTOMER_ID\n        &lt;dbl&gt; &lt;dttm&gt;                    &lt;dbl&gt;\n1           1 2011-12-18 00:00:00        7223\n2           2 2011-12-20 00:00:00        7841\n\n\n\nWriting to Excel and other I/O will be later, for now I like snake_case",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#review-of-ggplot2---the-main-components",
    "href": "Lectures/06_Adv_Visual/index.html#review-of-ggplot2---the-main-components",
    "title": "Advanced Visualization",
    "section": "Review of ggplot2 - The Main Components",
    "text": "Review of ggplot2 - The Main Components\n\nA data argument which indicates what dataset is being visualized\nAn aesthetics function using aes() which indicates how variables from the dataset are mapped to your plot\nFor example, you define what variables map to the x-axis and y-axis\nOne or more geoms which define the geometrical objects that graphically represent the data\n\n\nWe’ve also started to touch on other ggplot aspects that support communication like layers, scales, labels, and themes",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#review-of-ggplot2---working-with-gapminder",
    "href": "Lectures/06_Adv_Visual/index.html#review-of-ggplot2---working-with-gapminder",
    "title": "Advanced Visualization",
    "section": "Review of ggplot2 - Working with gapminder",
    "text": "Review of ggplot2 - Working with gapminder\n\n\n\nWith gapminder we made a layered scatterplot with a line of best fit, colored by continent, and a logarithmic scale x-axis\n\n\nggplot(gapminder, \n       aes(x = gdpPercap, y = lifeExp)) + \n  geom_point(aes(color = continent)) + \n  geom_smooth(se = FALSE) + \n  scale_x_log10(name = \"GDP per Capita\") + \n  labs(y = \"Life Expectancy (yrs)\") + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow let’s play with the supermarket data",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---questions-of-interest",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---questions-of-interest",
    "title": "Advanced Visualization",
    "section": "Geoms - Questions of Interest",
    "text": "Geoms - Questions of Interest\n\nLet’s try to visualize the following:\n\nMean and SD revenue by product family\nTotal revenue from supermarkets for each city\nNumber of transactions by children and annual income\n\nWe can get to all of these using dplyr and some new geoms",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---boxplots",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---boxplots",
    "title": "Advanced Visualization",
    "section": "Geoms - Boxplots",
    "text": "Geoms - Boxplots\n\nBoxplots via geom_boxplot() provide mean, IQR, and outliers (1.5x past) the IQR; great for visualizing numeric data within categories\n\n\nggplot(data=supermarket) + \n  geom_boxplot(aes(x=product_family, y=revenue))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---point-range-and-error-bars",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---point-range-and-error-bars",
    "title": "Advanced Visualization",
    "section": "Geoms - Point Range and Error Bars",
    "text": "Geoms - Point Range and Error Bars\n\nPointrange plots give points plus ranges\nFirst, we use summarise() to get some output\n\n\nsupermarket_summary &lt;- supermarket|&gt;\n  group_by(product_family) |&gt;\n  summarise(revenue_mn = mean(revenue),\n            revenue_sd = sd(revenue))\nsupermarket_summary\n\n# A tibble: 3 × 3\n  product_family revenue_mn revenue_sd\n  &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n1 Drink                12.7       8.39\n2 Food                 13.1       8.23\n3 Non-Consumable       12.9       8.07",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---point-range-and-error-bars-1",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---point-range-and-error-bars-1",
    "title": "Advanced Visualization",
    "section": "Geoms - Point Range and Error Bars",
    "text": "Geoms - Point Range and Error Bars\n\nNow provide ymin and ymax aesthetics to geom_pointrange()\n\n\nggplot(data=supermarket_summary) + \n  geom_pointrange(aes(x=product_family, y=revenue_mn, \n                      ymin=revenue_mn - revenue_sd, ymax=revenue_mn + revenue_sd))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---point-range-and-error-bars-2",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---point-range-and-error-bars-2",
    "title": "Advanced Visualization",
    "section": "Geoms - Point Range and Error Bars",
    "text": "Geoms - Point Range and Error Bars\n\nYou can also use geom_errorbar() for more publish-ready figures\n\n\nggplot(data=supermarket_summary, aes(x=product_family)) + \n  geom_point(aes(y=revenue_mn), shape=\"-\", size=18) +\n  geom_errorbar(aes(ymin=revenue_mn - revenue_sd, ymax=revenue_mn + revenue_sd), width=0.2)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts",
    "title": "Advanced Visualization",
    "section": "Geoms - Bar Charts",
    "text": "Geoms - Bar Charts\n\nLet’s use dplyr again to get total revenue by city\n\n\ncity_rev &lt;- supermarket |&gt;\n  group_by(city) |&gt;\n  summarise(revenue = sum(revenue, na.rm = TRUE)) \n\ncity_rev\n\n# A tibble: 23 × 2\n   city          revenue\n   &lt;chr&gt;           &lt;dbl&gt;\n 1 Acapulco        5161.\n 2 Bellingham       993.\n 3 Beverly Hills  10320.\n 4 Bremerton      10975.\n 5 Camacho         5797.\n 6 Guadalajara      523.\n 7 Hidalgo        11313.\n 8 Los Angeles    12296.\n 9 Merida          8740.\n10 Mexico City     2488.\n# ℹ 13 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-1",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-1",
    "title": "Advanced Visualization",
    "section": "Geoms - Bar Charts",
    "text": "Geoms - Bar Charts\n\ngeom_col() gets us most of the way but needs some hygiene\n\n\nggplot(city_rev, aes(x = city, y = revenue)) +\n  geom_col()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-2",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-2",
    "title": "Advanced Visualization",
    "section": "Geoms - Bar Charts",
    "text": "Geoms - Bar Charts\n\nUse fct_reorder() to get a more intuitive order by revenue size\n\n\nggplot(city_rev) +\n  aes(x = fct_reorder(city, revenue), y = revenue) + #&lt;&lt;\n  geom_col()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-3",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-3",
    "title": "Advanced Visualization",
    "section": "Geoms - Bar Charts",
    "text": "Geoms - Bar Charts\n\nReorient the plot to get horizontal bars with coord_flip()\n\n\nggplot(city_rev) +\n  aes(x = fct_reorder(city, revenue), y = revenue) +\n  geom_col() + \n  coord_flip() #&lt;&lt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-4",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---bar-charts-4",
    "title": "Advanced Visualization",
    "section": "Geoms - Bar Charts",
    "text": "Geoms - Bar Charts\n\nNote, geom_col() gives heights equal to the value in a row, good when using summarise(), while geom_bar() makes the height proportional to the number of instances of data\n\n\nggplot(supermarket) + \n  aes(x=interaction(homeowner, marital_status)) + \n  geom_bar()  #&lt;&lt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#geoms---tile-plots-and-heatmaps",
    "href": "Lectures/06_Adv_Visual/index.html#geoms---tile-plots-and-heatmaps",
    "title": "Advanced Visualization",
    "section": "Geoms - Tile Plots and Heatmaps",
    "text": "Geoms - Tile Plots and Heatmaps\n\nTile plots / heatmaps show counts when working with two categorical variables via geom_tile() or base R’s heatmap()\n\n\nsupermarket |&gt;\n  count(annual_income, children) |&gt;\n  ggplot(aes(x = annual_income, y = children)) +\n  geom_tile(aes(fill = n))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#aesthetics---more-research-questions",
    "href": "Lectures/06_Adv_Visual/index.html#aesthetics---more-research-questions",
    "title": "Advanced Visualization",
    "section": "Aesthetics - More Research Questions",
    "text": "Aesthetics - More Research Questions\n\nWho generates more revenue for super markets, men or women?\n\n\ncity_rev_gender &lt;- supermarket |&gt;\n  group_by(city, gender) |&gt;\n  summarise(revenue = sum(revenue, na.rm = TRUE)) |&gt; \n  ungroup() |&gt; #&lt;&lt;\n  mutate(\n    gender = recode(gender, 'F' = 'Female', 'M' = 'Male'),\n    # re-order city in the data rather than the plot\n    # why would this fail if data were grouped?\n    city = fct_reorder(city, .x = revenue) #&lt;&lt;\n  )\n\ncity_rev_gender[1:3,]\n\n# A tibble: 3 × 3\n  city       gender revenue\n  &lt;fct&gt;      &lt;chr&gt;    &lt;dbl&gt;\n1 Acapulco   Female   2566.\n2 Acapulco   Male     2596.\n3 Bellingham Female    453.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#aesthetics---fill-vs-color-in-bars",
    "href": "Lectures/06_Adv_Visual/index.html#aesthetics---fill-vs-color-in-bars",
    "title": "Advanced Visualization",
    "section": "Aesthetics - Fill vs Color in Bars",
    "text": "Aesthetics - Fill vs Color in Bars\nThe fill aesthetic applies inside of bars but color applies to their border\n\nggplot(city_rev_gender, aes(city, revenue, fill = gender)) + #&lt;&lt;\n  geom_col(color = 'purple') +\n  coord_flip()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#aesthetics---stacked-vs-dodged",
    "href": "Lectures/06_Adv_Visual/index.html#aesthetics---stacked-vs-dodged",
    "title": "Advanced Visualization",
    "section": "Aesthetics - Stacked vs Dodged",
    "text": "Aesthetics - Stacked vs Dodged\n\nposition governs how the bars are placed, default is stacked while dodge places bars side-by-side\n\n\nggplot(city_rev_gender, aes(city, revenue, fill = gender)) +\n  geom_col(position = \"dodge\") + #&lt;&lt;\n  coord_flip()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#aesthetics---faceting",
    "href": "Lectures/06_Adv_Visual/index.html#aesthetics---faceting",
    "title": "Advanced Visualization",
    "section": "Aesthetics - Faceting",
    "text": "Aesthetics - Faceting\n\nfacet_wrap() and facet_grid() give one plot per group\n\n\nggplot(city_rev_gender, aes(city, revenue, fill = gender)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  coord_flip() +\n  facet_wrap( ~ gender) #&lt;&lt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#aesthetics---too-many-to-list",
    "href": "Lectures/06_Adv_Visual/index.html#aesthetics---too-many-to-list",
    "title": "Advanced Visualization",
    "section": "Aesthetics - Too Many to List",
    "text": "Aesthetics - Too Many to List\n\nDon’t forget the other aesthetics you can use via group_by() like color, size, shape, and alpha (transparency)\nUse these with groups within aes() or as geom arguments to use fixed values e.g. color=“black”\nImportantly, all aesthetics within an aes() can be controlled with scales like scale_color_manual() or scale_x_continuous()\nCheck the various help pages for the geom functions for info on other arguments like position\n\n\nAgain, make use of the reference manual",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#aesthetics---max-info-with-minimal-ink",
    "href": "Lectures/06_Adv_Visual/index.html#aesthetics---max-info-with-minimal-ink",
    "title": "Advanced Visualization",
    "section": "Aesthetics - Max Info with Minimal Ink",
    "text": "Aesthetics - Max Info with Minimal Ink\n\nGraphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space.\n\n— Edward R. Tufte\n\n\n\nHow can we make it easy to pick out the patterns across cities?\nCan we use less ink to communicate even more?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---points",
    "href": "Lectures/06_Adv_Visual/index.html#layering---points",
    "title": "Advanced Visualization",
    "section": "Layering - Points",
    "text": "Layering - Points\n\nInstead of bars, let’s use points\n\n\nggplot(city_rev_gender, aes(revenue, city)) +\n  geom_point(aes(color = gender))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---size",
    "href": "Lectures/06_Adv_Visual/index.html#layering---size",
    "title": "Advanced Visualization",
    "section": "Layering - Size",
    "text": "Layering - Size\n\nMake the points bigger and then use theme() to increase all text size\n\n\nggplot(city_rev_gender, aes(revenue, city)) +\n  geom_point(aes(color = gender), size = 3) + \n  theme(text = element_text(size = 16)) #&lt;&lt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---aesthetic-inheritance",
    "href": "Lectures/06_Adv_Visual/index.html#layering---aesthetic-inheritance",
    "title": "Advanced Visualization",
    "section": "Layering - Aesthetic Inheritance",
    "text": "Layering - Aesthetic Inheritance\n\nggplot2 adds layers, one after the other, to a plot\nGeneral aesthetics for the whole graph can be set using aes() either…\n\nWithin the ggplot() function\nAs a stand-alone aes() function.\n\nThe aesthetics of the current geom can be set using an aes() inside the geom function.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---aesthetic-inheritance-1",
    "href": "Lectures/06_Adv_Visual/index.html#layering---aesthetic-inheritance-1",
    "title": "Advanced Visualization",
    "section": "Layering - Aesthetic Inheritance",
    "text": "Layering - Aesthetic Inheritance\n\nThe x and y aesthetics from the global aes() are inherited by both geom_point() and geom_line()\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + #&lt;&lt; \n  geom_point(aes(color = gender), size = 3) +\n  theme(text = element_text(size = 16)) +\n  geom_line()  #Inherits x = revenue, y = city #&lt;&lt;\n\n\nThe color aesthetic in geom_point() is not inherited by geom_line()\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + \n  geom_point(aes(color = gender), size = 3) + #&lt;&lt; \n  theme(text = element_text(size = 16)) +\n  geom_line()  #Inherits x = revenue, y = city",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---lines",
    "href": "Lectures/06_Adv_Visual/index.html#layering---lines",
    "title": "Advanced Visualization",
    "section": "Layering - Lines",
    "text": "Layering - Lines\n\nWhen we group on gender for geom_line() we just ruin the plot\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + \n  geom_point(aes(color = gender), size = 3) +\n  theme(text = element_text(size = 16)) +\n  geom_line(aes(group = gender))  #Disaster!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---lines-1",
    "href": "Lectures/06_Adv_Visual/index.html#layering---lines-1",
    "title": "Advanced Visualization",
    "section": "Layering - Lines",
    "text": "Layering - Lines\n\nInstead, group on city for a dot plot; good groupings should draw the eye to the relevant comparisons\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + \n  geom_point(aes(color = gender), size = 3) + \n  theme(text = element_text(size = 16)) +\n  geom_line(aes(group = city))  #Success!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---order-matters",
    "href": "Lectures/06_Adv_Visual/index.html#layering---order-matters",
    "title": "Advanced Visualization",
    "section": "Layering - Order Matters",
    "text": "Layering - Order Matters\n\nIf we want points to appear on top of the lines, put the line layer down before the point layer.\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + \n  geom_line(aes(group = city)) + #&lt;&lt;\n  geom_point(aes(color = gender), size = 3) + \n  theme(text = element_text(size = 16))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---using-text-annotation",
    "href": "Lectures/06_Adv_Visual/index.html#layering---using-text-annotation",
    "title": "Advanced Visualization",
    "section": "Layering - Using Text Annotation",
    "text": "Layering - Using Text Annotation\n\nAnnotation can help readers understand the most relevant parts of your data\n\nggplot2 uses geom_text() to add text layers\nThe main aesthetic for geom_text() is label\nggrepel, an extensions of ggplot2, has a lot of handy annotation helpers for proper positioning\nggforce has similar functionality but many other advanced options as well (reference manual here)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---using-text-annotation-1",
    "href": "Lectures/06_Adv_Visual/index.html#layering---using-text-annotation-1",
    "title": "Advanced Visualization",
    "section": "Layering - Using Text Annotation",
    "text": "Layering - Using Text Annotation\n\nWe still have some work ahead of us…in the exercises!\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city, label = revenue) +  #&lt;&lt;\n  geom_line(aes(group = city)) +\n  geom_point(aes(color = gender), size = 3) + \n  geom_text(aes(color = gender)) + #&lt;&lt;\n  theme(text = element_text(size = 16))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---scales",
    "href": "Lectures/06_Adv_Visual/index.html#layering---scales",
    "title": "Advanced Visualization",
    "section": "Layering - Scales",
    "text": "Layering - Scales\n\nScales control aesthetics details, including x and y axes\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + \n  geom_line(aes(group = city)) + \n  geom_point(aes(color = gender), size = 3) + \n  scale_color_manual(labels = c(\"M\", \"F\"), values = c(\"#00FF00\", \"Purple\"), name=\"Gender\") + #&lt;&lt;\n  scale_y_discrete(name = NULL) + scale_x_continuous(breaks = seq(0, 10000, 2000)) + #&lt;&lt;\n  theme(text = element_text(size = 16))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#layering---themes",
    "href": "Lectures/06_Adv_Visual/index.html#layering---themes",
    "title": "Advanced Visualization",
    "section": "Layering - Themes",
    "text": "Layering - Themes\n\nThemes customize non-data elements both globally and by individually\n\n\nggplot(city_rev_gender) +\n  aes(x = revenue, y = city) + \n  geom_line(aes(group = city)) + \n  geom_point(aes(color = gender), size = 3) + \n  scale_color_manual(labels = c(\"M\", \"F\"), values = c(\"#00FF00\", \"Purple\"), name=\"Gender\") +\n  scale_y_discrete(name = NULL) + scale_x_continuous(breaks = seq(0, 10000, 2000)) +\n  theme_bw() + theme(text = element_text(size = 16)) #&lt;&lt;\n\n\n\nFor more themes check out the ggthemes package",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/06_Adv_Visual/index.html#additional-resources",
    "href": "Lectures/06_Adv_Visual/index.html#additional-resources",
    "title": "Advanced Visualization",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nChapters 9-11 in R4DS\nggplot2: Elegant Graphics for Data Analysis by Hadley Wickham; a textbook resource dedicated solely to ggplot2\nR Graphics Cookbook by Winston Chang; a practical guide with over 150 different recipes for making plots in R\nThe ggplot2 extensions gallery; over 130 different extensions to ggplot2 with extensive utility\nThe R Graph Gallery; hundreds of examples of plots across 50 types with step-by-step guides",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html",
    "href": "Lectures/04_Isolation/index.html",
    "title": "Getting Started with dplyr",
    "section": "",
    "text": "Any questions on programming fundamentals from last time?\n\nFor review, see chapter 3 from R4DS\nFor recipes, you can check the fourth, fifth, and seventh recipes under Visualize Data on Posit Cloud\n\n\n\n\n\n\n\n\nTip\n\n\n\nAlthough challenging, these are the backbone of R and will get easier with practice",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#from-last-time",
    "href": "Lectures/04_Isolation/index.html#from-last-time",
    "title": "Getting Started with dplyr",
    "section": "From Last Time",
    "text": "From Last Time\n\nAny questions on programming fundamentals from last time?\n\nFor review, see chapter 3 from R4DS\nFor recipes, you can check the fourth, fifth, and seventh recipes under Visualize Data on Posit Cloud\n\n\n\n\n\n\n\n\nTip\n\n\nAlthough challenging, these are the backbone of R and will get easier with practice",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#from-last-time-1",
    "href": "Lectures/04_Isolation/index.html#from-last-time-1",
    "title": "Getting Started with dplyr",
    "section": "From Last Time",
    "text": "From Last Time\n\nAny questions on the reading / primer?\nWe’ve seen the R fundamentals on accession with vectors and functions; now let’s take the next step and work with data frames",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#agenda",
    "href": "Lectures/04_Isolation/index.html#agenda",
    "title": "Getting Started with dplyr",
    "section": "Agenda",
    "text": "Agenda\n\n\n\nData frames\nAn introduction to the pipe |&gt;\nData isolation\nTidy evaluation and a teaser on data transformation",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---why-theyre-amazing",
    "href": "Lectures/04_Isolation/index.html#data-frames---why-theyre-amazing",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - Why They’re Amazing",
    "text": "Data Frames - Why They’re Amazing\n\nData frames are the most widely used data storage object within R\nThey are amazing and useful for many reasons:\n\nThey are the default receptacle for any rectangular data\nMost functions in R will readily accept a data frame for their\ndata= argument\nConveniently package related variables together\nRecall, we think of them as vectors we’ve bound column-wise",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---why-theyre-amazing-1",
    "href": "Lectures/04_Isolation/index.html#data-frames---why-theyre-amazing-1",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - Why They’re Amazing",
    "text": "Data Frames - Why They’re Amazing\n\nFunctions can be applied to data frames and their behavior will generally be consistent and uniform\nFiltering on rows will return all columns and vice versa\nColumns can hold vectors of different classes; this is very intuitive\n\nView data frames as having rows as observations and columns are many kind of variables\nOther data storage objects (e.g. matrices) only hold one class\n\nThe packages in the tidyverse extend this and prioritize engaging with data frames via the tibble",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---the-tibble",
    "href": "Lectures/04_Isolation/index.html#data-frames---the-tibble",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - The Tibble",
    "text": "Data Frames - The Tibble\n\nTibbles are data frames, just a special “tidy” flavor\n\n\n\nPrimary distinction between the data frame’s data.frame classand the tibble’s tbl class is with respect to printing to console and when subsetting",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---the-nhanes-data-set",
    "href": "Lectures/04_Isolation/index.html#data-frames---the-nhanes-data-set",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - The NHANES Data Set",
    "text": "Data Frames - The NHANES Data Set\n\n\nProgram of studies designed to assess health and nutritional status in children and adults nationally\nStarted in the 1960’s and became a continuous program in 1999\nIncludes demographic, socioeconmoic, dietary, and health-related questions\n\n\nWhat does all this mean?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---nhanes-is-big-and-messy",
    "href": "Lectures/04_Isolation/index.html#data-frames---nhanes-is-big-and-messy",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - NHANES is Big and Messy",
    "text": "Data Frames - NHANES is Big and Messy\n\n\n# A tibble: 101,316 × 27\n    seqn  exam   psu strata wts_mec_2yr exam_status          age age_group sex  \n * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;\n 1     1  1999     1      5      10983. interview and exam     2 17 and b… Fema…\n 2     2  1999     3      1      28325. interview and exam    77 75 and a… Male \n 3     3  1999     2      7      46192. interview and exam    10 17 and b… Fema…\n 4     4  1999     1      2      10251. interview and exam     1 17 and b… Male \n 5     5  1999     2      8      99445. interview and exam    49 45 to 65  Male \n 6     6  1999     2      2      39657. interview and exam    19 18 to 45  Fema…\n 7     7  1999     2      4      25525. interview and exam    59 45 to 65  Fema…\n 8     8  1999     1      6      31511. interview and exam    13 17 and b… Male \n 9     9  1999     2      9       7576. interview and exam    11 17 and b… Fema…\n10    10  1999     1      7      22446. interview and exam    43 18 to 45  Male \n# ℹ 101,306 more rows\n# ℹ 18 more variables: race_ethnicity &lt;chr&gt;, education &lt;chr&gt;, income_hh &lt;chr&gt;,\n#   pregnant &lt;chr&gt;, bp_sys_mmhg &lt;dbl&gt;, bp_dia_mmhg &lt;dbl&gt;, n_msr_sbp &lt;dbl&gt;,\n#   n_msr_dbp &lt;dbl&gt;, bp_controlled &lt;chr&gt;, acr_mgg &lt;dbl&gt;, albuminuria &lt;chr&gt;,\n#   chol_hdl_mgdl &lt;dbl&gt;, chol_total_mgdl &lt;dbl&gt;, health_insurance &lt;chr&gt;,\n#   bp_high_aware &lt;chr&gt;, bp_meds &lt;chr&gt;, hc_usual_facility &lt;chr&gt;,\n#   hc_visit_1yr &lt;chr&gt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---nhanes-is-big-and-messy-1",
    "href": "Lectures/04_Isolation/index.html#data-frames---nhanes-is-big-and-messy-1",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - NHANES is Big and Messy",
    "text": "Data Frames - NHANES is Big and Messy\n\n\n\nTrying to plot this data will probably work but you won’t be happy with the results\nMost stock summarization functions like mean() or sd() will almost certainly fail\nWe need to clean up the data set into something more tractable\n\n\nBut how?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---well-use-dplyr",
    "href": "Lectures/04_Isolation/index.html#data-frames---well-use-dplyr",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - We’ll Use dplyr",
    "text": "Data Frames - We’ll Use dplyr\n\n\nIgnore the bitter grumblings of your instructor",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#data-frames---a-clean-nhanes",
    "href": "Lectures/04_Isolation/index.html#data-frames---a-clean-nhanes",
    "title": "Getting Started with dplyr",
    "section": "Data Frames - A Clean NHANES",
    "text": "Data Frames - A Clean NHANES\nAfter a bit of work with dplyr we can eventually get this\n\n\n# A tibble: 20 × 6\n    exam   age sex    bp_sys_mmhg n_msr_sbp bp_meds\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  1999    77 Male         101.          3 No     \n 2  1999    49 Male         122           3 Yes    \n 3  2001    39 Male         125.          3 No     \n 4  2001    23 Male         103.          3 No     \n 5  2003    16 Female        98.7         3 No     \n 6  2003    17 Male         103           2 No     \n 7  2005    44 Female       139.          3 Yes    \n 8  2005    70 Male         131.          3 Yes    \n 9  2007    62 Female       123.          3 Yes    \n10  2007    71 Male         145.          3 Yes    \n11  2009    34 Male         113.          3 No     \n12  2009    16 Male         110           3 No     \n13  2011    22 Male         111.          3 No     \n14  2011    44 Female       118           3 No     \n15  2013    69 Male         113.          3 No     \n16  2013    54 Male         157.          3 No     \n17  2015    62 Male         123.          3 No     \n18  2015    53 Male         140           3 No     \n19  2017    66 Female       200           2 Yes    \n20  2017    18 Male         111.          3 No",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---program-a-story",
    "href": "Lectures/04_Isolation/index.html#workflows---program-a-story",
    "title": "Getting Started with dplyr",
    "section": "Workflows - Program a Story",
    "text": "Workflows - Program a Story\nHere is the legendary tale of Little Bunny Foo Foo\n\nLittle bunny Foo Foo  Went hopping through the forest  Scooping up the field mice  And bopping them on the head\n\n\nHow would we go about programming this in R?\n\n\n\n# Assign little_bunny() to foo_foo\nfoo_foo &lt;- little_bunny()\n\n\nNow foo_foo can be modified…but how?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---making-new-objects",
    "href": "Lectures/04_Isolation/index.html#workflows---making-new-objects",
    "title": "Getting Started with dplyr",
    "section": "Workflows - Making New Objects",
    "text": "Workflows - Making New Objects\nWe could save each intermediate step as a new object:\n\n# Little bunny Foo Foo\nfoo_foo &lt;- little_bunny()\n\n# Went hopping through the forest\nfoo_foo_1 &lt;- hop(foo_foo, through = forest) \n\n# Scooping up the field mice\nfoo_foo_2 &lt;- scoop(foo_foo_1, up = field_mice) \n\n# And bopping them on the head\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head) \n\n\nProblems:\n\nThe code is cluttered with unimportant names\nYou have to carefully increment the suffix on each line",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---overwrite-the-original-object",
    "href": "Lectures/04_Isolation/index.html#workflows---overwrite-the-original-object",
    "title": "Getting Started with dplyr",
    "section": "Workflows - Overwrite the Original Object",
    "text": "Workflows - Overwrite the Original Object\nWe could overwrite the original object which can reduce typing errors:\n\n # Little bunny Foo Foo\nfoo_foo &lt;- little_bunny()\n\n# Went hopping through the forest\nfoo_foo &lt;- hop(foo_foo, through = forest) \n\n# Scooping up the field mice\nfoo_foo &lt;- scoop(foo_foo, up = field_mice) \n\n# And bopping them on the head\nfoo_foo &lt;- bop(foo_foo, on = head) \n\n\nDebugging is painful and tedious; the pipeline has to be done de novo\nRepetition (7 foo_foos) obfuscates the code making it hard to follow",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---functional-composition-nests",
    "href": "Lectures/04_Isolation/index.html#workflows---functional-composition-nests",
    "title": "Getting Started with dplyr",
    "section": "Workflows - Functional Composition Nests",
    "text": "Workflows - Functional Composition Nests\nAbandon assignment operations and just nest the functions together:\n\nbop(\n  scoop(\n    hop(\n      little_bunny(), # Little bunny Foo Foo\n      through = forest # Went hopping through the forest\n    ),\n    up = field_mice # Scooping up the field mice\n  ), \n  on = head # And bopping them on the head\n)\n\nOr as I would type…\n\n#Make pre-goon foo_foo\nfoo_foo &lt;- bop(scoop(hop(little_bunny(), through=forest), up=field_mice), on=head)\n\nNo one likes to read or type this (except Chad)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---the-pipe",
    "href": "Lectures/04_Isolation/index.html#workflows---the-pipe",
    "title": "Getting Started with dplyr",
    "section": "Workflows - The Pipe |>",
    "text": "Workflows - The Pipe |&gt;\nLast, we could use the pipe operator |&gt;:\n\nfoo_foo &lt;-\n  little_bunny() |&gt;          # Little bunny Foo Foo\n  hop(through = forest) |&gt;   # Went hopping through the forest\n  scoop(up = field_mice) |&gt;  # Scooping up the field mice\n  bop(on = head)             # And bopping them on the head\n\n\nPros\n\nFocuses on the function verbs and not the object nouns\nUnlike the nested composition, this flows as a series of imperative actions: Foo Foo hops, then scoops, then bops",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---the-pipe-1",
    "href": "Lectures/04_Isolation/index.html#workflows---the-pipe-1",
    "title": "Getting Started with dplyr",
    "section": "Workflows - The Pipe |>",
    "text": "Workflows - The Pipe |&gt;\nLast, we could use the pipe operator |&gt;:\n\nfoo_foo &lt;-\n  little_bunny() |&gt;          # Little bunny Foo Foo\n  hop(through = forest) |&gt;   # Went hopping through the forest\n  scoop(up = field_mice) |&gt;  # Scooping up the field mice\n  bop(on = head)             # And bopping them on the head\n\nCons\n\nIf you’ve never seen |&gt; before, you’ll have no idea what this code does\n\nLuckily, its behavior is intuitive which makes it very easy to share and describe to others",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---so-whats-a-pipe",
    "href": "Lectures/04_Isolation/index.html#workflows---so-whats-a-pipe",
    "title": "Getting Started with dplyr",
    "section": "Workflows - So What’s a Pipe?",
    "text": "Workflows - So What’s a Pipe?\n\nSimply, a pipe takes the object on the left hand side and makes it the first argument for the function on the right hand side\n\n\n# Create a series of numbers and assign it to x\nx &lt;- 1:10\n\n# Now take the mean of x\nmean(x)\n\n[1] 5.5\n\n# This is equivalent to the above code\nx |&gt; mean()\n\n[1] 5.5\n\n\n\nWe call |&gt; a “pipe” since it literally pipes whatever is on the left into the first argument on the right",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---so-whats-a-pipe-1",
    "href": "Lectures/04_Isolation/index.html#workflows---so-whats-a-pipe-1",
    "title": "Getting Started with dplyr",
    "section": "Workflows - So What’s a Pipe?",
    "text": "Workflows - So What’s a Pipe?\n\nMore broadly, the pipe makes these two snippets equivalent\n\n\n# Use the function and specify all arguments\nnifty_function(main_arg = xx, other_arg = yy, last_arg = zz)\n\n# Start with xx and pipe it into main_arg before executing the function\nxx |&gt; \n  nifty_function(other_arg = yy, last_arg = zz)\n\n\nNow we don’t need to specify a value for the main_arg argument since |&gt; automatically passes xx for us",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---the-strength-of-the-pipe",
    "href": "Lectures/04_Isolation/index.html#workflows---the-strength-of-the-pipe",
    "title": "Getting Started with dplyr",
    "section": "Workflows - The Strength of the Pipe",
    "text": "Workflows - The Strength of the Pipe\n\nThe value is in making written code more human readable as you apply a series of functions\n\n\n# Using the functions like they're a matryoshka doll\nanother_neat_one(\n  nifty_function(main_arg = xx, other_arg = yy, last_arg = zz),\n  another_arg = ww\n)\n\n\n# Start with xx and then apply the functions in series\nxx |&gt; \n  nifty_function(other_arg = yy, last_arg = zz) |&gt; \n  another_neat_one(another_arg = ww)\n\n# Stylistic tip: end lines at the |&gt; \n\n\nThus avoids clunky temporary objects and densely nested functions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---when-not-to-pipe",
    "href": "Lectures/04_Isolation/index.html#workflows---when-not-to-pipe",
    "title": "Getting Started with dplyr",
    "section": "Workflows - When Not to Pipe",
    "text": "Workflows - When Not to Pipe\n\nIf your pipes are longer than ~5 steps use intermediate R objects with meaningful names\n\nThis will make debugging easier as you can troubleshoot the intermediary objects\nYour code will be more understandable; variable names can help communicate intent",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---when-not-to-pipe-1",
    "href": "Lectures/04_Isolation/index.html#workflows---when-not-to-pipe-1",
    "title": "Getting Started with dplyr",
    "section": "Workflows - When Not to Pipe",
    "text": "Workflows - When Not to Pipe\n\nIf your pipes are longer than ~5 steps use intermediate R objects with meaningful names\nYou have multiple inputs or outputs being manipulated\n\nIf multiple objects are being coalesced, it is better to have parallel workflows that meet at the end\n\n\n\n\n\n\n\n\nWarning\n\n\nPipes can only ever pass one essential from left to right",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---when-not-to-pipe-2",
    "href": "Lectures/04_Isolation/index.html#workflows---when-not-to-pipe-2",
    "title": "Getting Started with dplyr",
    "section": "Workflows - When Not to Pipe",
    "text": "Workflows - When Not to Pipe\n\nIf your pipes are longer than ~5 steps use intermediate R objects with meaningful names\nYou have multiple inputs or outputs being manipulated\nYour workflow has a complex dependency structure\n\nPipes are fundamentally linear and expressing complex relationships with them is generally confusing\nThey can behave very poorly under iterative (repeating) processes",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#workflows---there-are-two-pipes",
    "href": "Lectures/04_Isolation/index.html#workflows---there-are-two-pipes",
    "title": "Getting Started with dplyr",
    "section": "Workflows - There are Two Pipes",
    "text": "Workflows - There are Two Pipes\n\nR introduced |&gt; as a native operator installed with R 4.1 in 2021\nThis was designed to supplant the %&gt;% operator which has been part of the tidyverse since the end of 2013 in the magrittr package\n\n\n\n\nThey are largely functionally identical although |&gt; is more limited than %&gt;%\n%&gt;% is still used and you will almost certainly see it in code\nBoth have R version dependencies:%&gt;% R&gt;=3.5 and |&gt; R&gt;=4.1",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---dplyr-functions",
    "href": "Lectures/04_Isolation/index.html#isolation---dplyr-functions",
    "title": "Getting Started with dplyr",
    "section": "Isolation - dplyr Functions",
    "text": "Isolation - dplyr Functions\n\ndplyr has several functions to make data frame isolation easier\n\nfilter() will subset a data frame by rows\nselect() instead subsets a data frame by columns\narrange() let’s you reorganize a data frame according to row\n\nImportantly, the row functions do not alter your columns and column functions do not alter rows\nAs part of the tidyverse, these dplyr functions will always return the same type of output as their original input e.g. start with a data frame and end with a data frame",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---before-you-subset-your-data",
    "href": "Lectures/04_Isolation/index.html#isolation---before-you-subset-your-data",
    "title": "Getting Started with dplyr",
    "section": "Isolation - Before You Subset Your Data",
    "text": "Isolation - Before You Subset Your Data\n\n\n\n\n\n\n\nImportant\n\n\nWHEN SUBSETTING, ALWAYS MAKE A NEW OBJECT!!NEVER OVERWRITE YOUR SOURCE DATA!!\n\n\n\n\n\nLet’s try to work with the NHANES data set",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---recall-the-reduced-nhanes-data",
    "href": "Lectures/04_Isolation/index.html#isolation---recall-the-reduced-nhanes-data",
    "title": "Getting Started with dplyr",
    "section": "Isolation - Recall the Reduced NHANES Data",
    "text": "Isolation - Recall the Reduced NHANES Data\n\n\n# A tibble: 20 × 6\n    exam   age sex    bp_sys_mmhg n_msr_sbp bp_meds\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  1999    77 Male         101.          3 No     \n 2  1999    49 Male         122           3 Yes    \n 3  2001    39 Male         125.          3 No     \n 4  2001    23 Male         103.          3 No     \n 5  2003    16 Female        98.7         3 No     \n 6  2003    17 Male         103           2 No     \n 7  2005    44 Female       139.          3 Yes    \n 8  2005    70 Male         131.          3 Yes    \n 9  2007    62 Female       123.          3 Yes    \n10  2007    71 Male         145.          3 Yes    \n11  2009    34 Male         113.          3 No     \n12  2009    16 Male         110           3 No     \n13  2011    22 Male         111.          3 No     \n14  2011    44 Female       118           3 No     \n15  2013    69 Male         113.          3 No     \n16  2013    54 Male         157.          3 No     \n17  2015    62 Male         123.          3 No     \n18  2015    53 Male         140           3 No     \n19  2017    66 Female       200           2 Yes    \n20  2017    18 Male         111.          3 No",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---filter",
    "href": "Lectures/04_Isolation/index.html#isolation---filter",
    "title": "Getting Started with dplyr",
    "section": "Isolation - filter()",
    "text": "Isolation - filter()\n\nfilter() keeps rows that match specified conditions\nIt takes a data frame as the first argument followed by an expression that can resolve to a logical vector\nThe logical vector uses common operators like &lt;, &gt;, ==, and !=\nMultiple logical expressions on multiple columns can be used with set operators like &, |, and !\n\nQuestion:In NHANES, how many males were taking medications to lower blood pressure?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---filter-in-nhanes",
    "href": "Lectures/04_Isolation/index.html#isolation---filter-in-nhanes",
    "title": "Getting Started with dplyr",
    "section": "Isolation - filter() in NHANES",
    "text": "Isolation - filter() in NHANES\n\nFirst filter to only males\n\n\nmales &lt;- filter(nhanes, sex == 'Male') #&lt;&lt;\nmales_bp_meds &lt;- filter(males, bp_meds == 'Yes')\nanswer &lt;- nrow(males_bp_meds)\n\n\n\n# A tibble: 15 × 6\n    exam   age sex   bp_sys_mmhg n_msr_sbp bp_meds\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  1999    77 Male         101.         3 No     \n 2  1999    49 Male         122          3 Yes    \n 3  2001    39 Male         125.         3 No     \n 4  2001    23 Male         103.         3 No     \n 5  2003    17 Male         103          2 No     \n 6  2005    70 Male         131.         3 Yes    \n 7  2007    71 Male         145.         3 Yes    \n 8  2009    34 Male         113.         3 No     \n 9  2009    16 Male         110          3 No     \n10  2011    22 Male         111.         3 No     \n11  2013    69 Male         113.         3 No     \n12  2013    54 Male         157.         3 No     \n13  2015    62 Male         123.         3 No     \n14  2015    53 Male         140          3 No     \n15  2017    18 Male         111.         3 No",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---filter-in-nhanes-1",
    "href": "Lectures/04_Isolation/index.html#isolation---filter-in-nhanes-1",
    "title": "Getting Started with dplyr",
    "section": "Isolation - filter() in NHANES",
    "text": "Isolation - filter() in NHANES\n\nThen only those males on BP medication\n\n\nmales &lt;- filter(nhanes, sex == 'Male') \nmales_bp_meds &lt;- filter(males, bp_meds == 'Yes') #&lt;&lt;\nanswer &lt;- nrow(males_bp_meds)\n\n\n\n# A tibble: 3 × 6\n   exam   age sex   bp_sys_mmhg n_msr_sbp bp_meds\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n1  1999    49 Male         122          3 Yes    \n2  2005    70 Male         131.         3 Yes    \n3  2007    71 Male         145.         3 Yes",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---filter-in-nhanes-2",
    "href": "Lectures/04_Isolation/index.html#isolation---filter-in-nhanes-2",
    "title": "Getting Started with dplyr",
    "section": "Isolation - filter() in NHANES",
    "text": "Isolation - filter() in NHANES\n\nUse nrow() to get the number of rows in the filtered set\n\n\nmales &lt;- filter(nhanes, sex == 'Male') \nmales_bp_meds &lt;- filter(males, bp_meds == 'Yes') \nanswer &lt;- nrow(males_bp_meds) #&lt;&lt;\n\n\n\nanswer\n\n[1] 3\n\n\n\nNow let’s clean up the workflow",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---filter-with-a-pipe-solution",
    "href": "Lectures/04_Isolation/index.html#isolation---filter-with-a-pipe-solution",
    "title": "Getting Started with dplyr",
    "section": "Isolation - filter() with a Pipe Solution",
    "text": "Isolation - filter() with a Pipe Solution\n\nanswer &lt;- \n  nhanes |&gt; \n  filter(sex == 'Male' & bp_meds == 'Yes') |&gt; \n  nrow()\n\nanswer\n\n[1] 3\n\n\n\nTo create the answer,\n\nStart with nhanes, THEN\nFilter to contain only males on BP meds, THEN\nCount the number of rows which were left over",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---other-dplyr-functions",
    "href": "Lectures/04_Isolation/index.html#isolation---other-dplyr-functions",
    "title": "Getting Started with dplyr",
    "section": "Isolation - Other dplyr functions",
    "text": "Isolation - Other dplyr functions\n\nselect() extracts columns from a data set; it’s like $ but much more versatile and consistent e.g. it won’t return a vector\narrange() will sort a data frame row-wise by a specified column / variable; can wrap the variable in desc() for descending order\nslice() and its relatives index rows by their location; again like [] but more consistent and versatile\nThe full list of dplyr functions can be found on the package’s help page\n\nNext question:In NHANES, what was the highest systolic blood pressure in males?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males",
    "href": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males",
    "title": "Getting Started with dplyr",
    "section": "Isolation - NHANES Highest BP in Males",
    "text": "Isolation - NHANES Highest BP in Males\nStart with NHANES and begin piping |&gt;\n\nnhanes |&gt; #&lt;&lt;\n  filter(sex == 'Male') |&gt; \n  arrange(desc(bp_sys_mmhg)) |&gt; \n  select(bp_sys_mmhg) |&gt; \n  slice(1) |&gt; \n  as.numeric()\n\n\n\n# A tibble: 20 × 6\n    exam   age sex    bp_sys_mmhg n_msr_sbp bp_meds\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  1999    77 Male         101.          3 No     \n 2  1999    49 Male         122           3 Yes    \n 3  2001    39 Male         125.          3 No     \n 4  2001    23 Male         103.          3 No     \n 5  2003    16 Female        98.7         3 No     \n 6  2003    17 Male         103           2 No     \n 7  2005    44 Female       139.          3 Yes    \n 8  2005    70 Male         131.          3 Yes    \n 9  2007    62 Female       123.          3 Yes    \n10  2007    71 Male         145.          3 Yes    \n11  2009    34 Male         113.          3 No     \n12  2009    16 Male         110           3 No     \n13  2011    22 Male         111.          3 No     \n14  2011    44 Female       118           3 No     \n15  2013    69 Male         113.          3 No     \n16  2013    54 Male         157.          3 No     \n17  2015    62 Male         123.          3 No     \n18  2015    53 Male         140           3 No     \n19  2017    66 Female       200           2 Yes    \n20  2017    18 Male         111.          3 No",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-1",
    "href": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-1",
    "title": "Getting Started with dplyr",
    "section": "Isolation - NHANES Highest BP in Males",
    "text": "Isolation - NHANES Highest BP in Males\nApply filter() on the column sex to return only males\n\nnhanes |&gt; \n  filter(sex == 'Male') |&gt; #&lt;&lt;\n  arrange(desc(bp_sys_mmhg)) |&gt; \n  select(bp_sys_mmhg) |&gt; \n  slice(1) |&gt; \n  as.numeric()\n\n\n\n# A tibble: 15 × 6\n    exam   age sex   bp_sys_mmhg n_msr_sbp bp_meds\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  1999    77 Male         101.         3 No     \n 2  1999    49 Male         122          3 Yes    \n 3  2001    39 Male         125.         3 No     \n 4  2001    23 Male         103.         3 No     \n 5  2003    17 Male         103          2 No     \n 6  2005    70 Male         131.         3 Yes    \n 7  2007    71 Male         145.         3 Yes    \n 8  2009    34 Male         113.         3 No     \n 9  2009    16 Male         110          3 No     \n10  2011    22 Male         111.         3 No     \n11  2013    69 Male         113.         3 No     \n12  2013    54 Male         157.         3 No     \n13  2015    62 Male         123.         3 No     \n14  2015    53 Male         140          3 No     \n15  2017    18 Male         111.         3 No",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-2",
    "href": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-2",
    "title": "Getting Started with dplyr",
    "section": "Isolation - NHANES Highest BP in Males",
    "text": "Isolation - NHANES Highest BP in Males\nUse arrange() to sort the filtered set for descending by systolic BP\n\nnhanes |&gt; \n  filter(sex == 'Male') |&gt; \n  arrange(desc(bp_sys_mmhg)) |&gt; #&lt;&lt;\n  select(bp_sys_mmhg) |&gt; \n  slice(1) |&gt; \n  as.numeric()\n\n\n\n# A tibble: 15 × 6\n    exam   age sex   bp_sys_mmhg n_msr_sbp bp_meds\n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1  2013    54 Male         157.         3 No     \n 2  2007    71 Male         145.         3 Yes    \n 3  2015    53 Male         140          3 No     \n 4  2005    70 Male         131.         3 Yes    \n 5  2001    39 Male         125.         3 No     \n 6  2015    62 Male         123.         3 No     \n 7  1999    49 Male         122          3 Yes    \n 8  2009    34 Male         113.         3 No     \n 9  2013    69 Male         113.         3 No     \n10  2017    18 Male         111.         3 No     \n11  2011    22 Male         111.         3 No     \n12  2009    16 Male         110          3 No     \n13  2001    23 Male         103.         3 No     \n14  2003    17 Male         103          2 No     \n15  1999    77 Male         101.         3 No",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-3",
    "href": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-3",
    "title": "Getting Started with dplyr",
    "section": "Isolation - NHANES Highest BP in Males",
    "text": "Isolation - NHANES Highest BP in Males\nUse select() to extract the bp_sys_mmhg column of interest\n\nnhanes |&gt; \n  filter(sex == 'Male') |&gt; \n  arrange(desc(bp_sys_mmhg)) |&gt; \n  select(bp_sys_mmhg) |&gt; #&lt;&lt;\n  slice(1) |&gt; \n  as.numeric()\n\n\n\n# A tibble: 15 × 1\n   bp_sys_mmhg\n         &lt;dbl&gt;\n 1        157.\n 2        145.\n 3        140 \n 4        131.\n 5        125.\n 6        123.\n 7        122 \n 8        113.\n 9        113.\n10        111.\n11        111.\n12        110 \n13        103.\n14        103 \n15        101.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-4",
    "href": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-4",
    "title": "Getting Started with dplyr",
    "section": "Isolation - NHANES Highest BP in Males",
    "text": "Isolation - NHANES Highest BP in Males\nWith slice() index out the 1st row which is the highest systolic BP\n\nnhanes |&gt; \n  filter(sex == 'Male') |&gt; \n  arrange(desc(bp_sys_mmhg)) |&gt; \n  select(bp_sys_mmhg) |&gt; \n  slice(1) |&gt; #&lt;&lt;\n  as.numeric()\n\n\n\n# A tibble: 1 × 1\n  bp_sys_mmhg\n        &lt;dbl&gt;\n1        157.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-5",
    "href": "Lectures/04_Isolation/index.html#isolation---nhanes-highest-bp-in-males-5",
    "title": "Getting Started with dplyr",
    "section": "Isolation - NHANES Highest BP in Males",
    "text": "Isolation - NHANES Highest BP in Males\nSince the output has remained a consistent tibble, coerce it to numeric\n\nnhanes |&gt;\n  filter(sex == 'Male') |&gt; \n  arrange(desc(bp_sys_mmhg)) |&gt; \n  select(bp_sys_mmhg) |&gt; \n  slice(1) |&gt; \n  as.numeric() #&lt;&lt;\n\n\n\n[1] 157.3333",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#isolation---common-logical-operators-in-r",
    "href": "Lectures/04_Isolation/index.html#isolation---common-logical-operators-in-r",
    "title": "Getting Started with dplyr",
    "section": "Isolation - Common Logical Operators in R",
    "text": "Isolation - Common Logical Operators in R\n\n\n\n\n\n\n\n\n\n\nOperator\nDefinition\nOperator\nDefinition\n\n\n\n\n&lt;\nless than\nx | y\nx OR y\n\n\n&lt;=\nless than or equal to\nis.na(x)\ntest if x is NA\n\n\n&gt;\ngreater than\n!is.na(x)\ntest if x is not NA\n\n\n&gt;=\ngreater than or equal to\nx %in% y\ntest if x is in y\n\n\n==\nexactly equal to\n!(x %in% y)\ntest if x is not in y\n\n\n!=\nnot equal to\n!x\nnot x\n\n\n&\nand\nx & y\nx AND y\n\n\n\n\n%in% is a new, but powerful, operator\nx == \"value1\" | x == \"value2\" is equivalent tox %in% c(\"value1\", \"value2\")",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#tidy-evaluation-1",
    "href": "Lectures/04_Isolation/index.html#tidy-evaluation-1",
    "title": "Getting Started with dplyr",
    "section": "Tidy Evaluation",
    "text": "Tidy Evaluation\n\nThe tidyverse makes extensive use of tidy evaluation which dictates how most functions access variables within a data frame\nThere are two main variants, data masking and tidy selection\nWhen you check tidyverse function documentations you can look for &lt;data-masking&gt; or &lt;tidy-select&gt; to see which flavor you can use",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#tidy-evaluation-2",
    "href": "Lectures/04_Isolation/index.html#tidy-evaluation-2",
    "title": "Getting Started with dplyr",
    "section": "Tidy Evaluation",
    "text": "Tidy Evaluation\n\nData masking - as seen with filter() and arrange(), you can use data frame variable as if they were variables in the global environment\n\nInstead of data_frame$my_var you can use my_var within tidyverse functions as is and without quotes\n\nTidy selection - so far only seen with select() but allows you to choose variables based on position, name, or type, for example…\n\nselect(df, 1) selects the first column (position/indexing)\nselect(df, c(a, b, c)) selects columns a, b, and c\nselect(df, where(is.numeric)) selects all numeric columns",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/04_Isolation/index.html#next-time---more-on-dplyr",
    "href": "Lectures/04_Isolation/index.html#next-time---more-on-dplyr",
    "title": "Getting Started with dplyr",
    "section": "Next Time - More on dplyr",
    "text": "Next Time - More on dplyr\n\nWorking with dplyr functions to organize, transform, summarize, and create new data\n\ngroup_by() to divide a data set into groups\nsummarize() for aggregated measures like sum, mean, etc\nmutate() to transform old columns into new ones\n\nContinuing to build workflows and comments on style and organization\nStill focused on chapter 3 in R4DS\nContinue to go through the recipes under Transform Tables onPosit Cloud",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "04 - Data Isolation"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html",
    "href": "Lectures/02_VizBasics/index.html",
    "title": "Basics of Data Visualization",
    "section": "",
    "text": "Tips on getting help (reprex)\nData frames 101\nExploratory data analysis\nData visualization using ggplot2\nVisualizing Star Wars\nAesthetics\nUpcoming visualization topics",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#agenda",
    "href": "Lectures/02_VizBasics/index.html#agenda",
    "title": "Basics of Data Visualization",
    "section": "Agenda",
    "text": "Agenda\n\nTips on getting help (reprex)\nData frames 101\nExploratory data analysis\nData visualization using ggplot2\nVisualizing Star Wars\nAesthetics\nUpcoming visualization topics",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#what-is-reprex",
    "href": "Lectures/02_VizBasics/index.html#what-is-reprex",
    "title": "Basics of Data Visualization",
    "section": "What is reprex?",
    "text": "What is reprex?\nreprex stands for reproducible example; The reprex R package helps create reproducible examples for posts on GitHub, StackOverflow, etc.\n\n\n\nWhen seeking help for a programming problem…\n\nbreak the problem down to its essential components\nkeep the code minimal, not overwhelming\ndescribe issues concisely but clearly\n\n\n\n\n\n\n\n\n\nFor getting started check out the reprex site or the reprex_example in this project Posit cloud",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-frames---the-basics",
    "href": "Lectures/02_VizBasics/index.html#data-frames---the-basics",
    "title": "Basics of Data Visualization",
    "section": "Data Frames - The Basics",
    "text": "Data Frames - The Basics\n\nLast time we talked about objects in R that store data\n\n\n\nMost frequently we’ll be working with data frames\nSome standard data frame properties in R:\n\nPlace variables in columns\nHave observations as rows\nAre rectangular such that…\n\nall columns are equal length\nall rows are equal length",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-frames---some-definitions",
    "href": "Lectures/02_VizBasics/index.html#data-frames---some-definitions",
    "title": "Basics of Data Visualization",
    "section": "Data Frames - Some Definitions",
    "text": "Data Frames - Some Definitions\n\nA variable is some sort of quality, quantity or property of the data\nVariables are comprised of values which are specific instances or measures of a variable\nAn observation is a set of measurements under similar conditions, it can be thought of as a unique set of values specific to those conditions\nTabular data takes a set of values each associated with a variable and an observation and gives a rectangular structure\nThe tidyverse calls this tabular data tidy when each value is its own cell, each variable is its own column, each observation is its own row",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-frames---tidy-data-example",
    "href": "Lectures/02_VizBasics/index.html#data-frames---tidy-data-example",
    "title": "Basics of Data Visualization",
    "section": "Data Frames - Tidy Data Example",
    "text": "Data Frames - Tidy Data Example\n\n\n\n\n\n\n\nNote\n\n\nTidy data can allow for missing values, you’ll see these as NA or &lt;NA&gt;\n\n\n\nWe’ll talk about accessing this data next week",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#eda---what-is-it",
    "href": "Lectures/02_VizBasics/index.html#eda---what-is-it",
    "title": "Basics of Data Visualization",
    "section": "EDA - What is it?",
    "text": "EDA - What is it?\n\nProcedures to initially investigate data by analyzing and focusing on its main characteristics\n\n\n\nThe easiest point of entry is visualization, our focus of today\n\n\n\n\nSummarization is another method but that will come later since it involves:\n\ndata isolation (coming soon)\ndata transformation (after isolation)\ndownstream data processing (after transformation)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#eda---what-collaborators-think-it-does",
    "href": "Lectures/02_VizBasics/index.html#eda---what-collaborators-think-it-does",
    "title": "Basics of Data Visualization",
    "section": "EDA - What Collaborators Think it Does",
    "text": "EDA - What Collaborators Think it Does",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#eda---what-it-actually-does",
    "href": "Lectures/02_VizBasics/index.html#eda---what-it-actually-does",
    "title": "Basics of Data Visualization",
    "section": "EDA - What it Actually Does",
    "text": "EDA - What it Actually Does\nEDA should always be your first pass at data analysis\n\nGives a basic understanding of structure and organization\nHelps spot anomalies that are both real (outliers) or imaginary (errors)\nChecks basic assumptions that precede formal analysis\nDetermine missingness of key variables\nIt gets you familiar with your data which enhances communication\n\nVisualization is a great form of EDA",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-visualization-1",
    "href": "Lectures/02_VizBasics/index.html#data-visualization-1",
    "title": "Basics of Data Visualization",
    "section": "Data Visualization",
    "text": "Data Visualization\n\n“The simple graph has brought more information to the data analyst’s mind than any other device” — John Tukey”\n\n\nData visualization is the creation and study of some sort of visual representation of data\nThere are many tools for visualizing data, including R\nWithin R there are many approaches/systems for making data visualizations, ggplot2 will be our system of choice",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#about-ggplot2",
    "href": "Lectures/02_VizBasics/index.html#about-ggplot2",
    "title": "Basics of Data Visualization",
    "section": "About ggplot2",
    "text": "About ggplot2\n\nggplot2 is the name of the package and gets loaded with a library call to gain access to its functions\nThe gg in “ggplot2” stands for Grammar of Graphics\nInspired by the book Grammar of Graphics by Leland Wilkinson\nggplot() is the main backbone function in ggplot2 i.e. it gives your blank plot canvas\nGraphic specification and customization is layered in using the plus operator (+) followed by supporting ggplot2 functions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#getting-help-with-ggplot2",
    "href": "Lectures/02_VizBasics/index.html#getting-help-with-ggplot2",
    "title": "Basics of Data Visualization",
    "section": "Getting Help with ggplot2",
    "text": "Getting Help with ggplot2\n\n\nFor help with ggplot2, see http://ggplot2.tidyverse.org/\n\nA cheat sheet can be found right on the front page along with a reference guide\n\nIn R4DS this is covered in chapter 1 as an introduction followed by more in-depth customization in chapters 9 and 11",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-visualization-with-ggplot2",
    "href": "Lectures/02_VizBasics/index.html#data-visualization-with-ggplot2",
    "title": "Basics of Data Visualization",
    "section": "Data Visualization with ggplot2",
    "text": "Data Visualization with ggplot2\nIn its simplest form, code for ggplot has three basic components:\n\n\nA data argument which indicates what dataset is being visualized\nAn aesthetics function using aes() which indicates how variables from the dataset are mapped to your plot\nFor example, you define what variables map to the x-axis and y-axis\nOne or more geoms which define the geometrical objects that graphically represent the data\n\n\n\nAfterwards, additional customizations can be added in as desired\n\n\nAgain, we add in additional customizations (or even extra geoms) using +",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-visualization-with-ggplot2---the-code",
    "href": "Lectures/02_VizBasics/index.html#data-visualization-with-ggplot2---the-code",
    "title": "Basics of Data Visualization",
    "section": "Data Visualization with ggplot2 - The Code",
    "text": "Data Visualization with ggplot2 - The Code\nAltogether, this gives a basic code format that looks like this:\n\n\n#Make a ggplot call and define your dataset\nggplot(data = dataset) +\n  #Define your aesthetics mapping\n  aes(x = x_variable, y = y_variable) +\n  #Define your graphical primitivies aka the geoms\n  geom_xxx() +\n  #Add other ggplot2 functionality as needed\n  other_functions()\n\n\n\n\n\n\n\n\n\nTip\n\n\nThe aes() portion is often placed inside ggplot() or geom_xxx() calls via the mapping argument\n\nggplot2(data = dataset, mapping = aes(x = x_variable, y = y_variable))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-visualization-in-r4ds---palmer-penguins",
    "href": "Lectures/02_VizBasics/index.html#data-visualization-in-r4ds---palmer-penguins",
    "title": "Basics of Data Visualization",
    "section": "Data Visualization in R4DS - Palmer Penguins",
    "text": "Data Visualization in R4DS - Palmer Penguins\nR4DS gives an example ggplot2 build using Palmer Penguins\n\n\n#ggplot() call only\n\nggplot(\n  data = penguins\n  )\n\n\n\n\n\n\n\n\n\n\n1. Beginning with the “blank canvas” of the plot",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-visualization-in-r4ds---palmer-penguins-1",
    "href": "Lectures/02_VizBasics/index.html#data-visualization-in-r4ds---palmer-penguins-1",
    "title": "Basics of Data Visualization",
    "section": "Data Visualization in R4DS - Palmer Penguins",
    "text": "Data Visualization in R4DS - Palmer Penguins\nR4DS gives an example ggplot2 build using Palmer Penguins\n\n\n#Define aes() mapping\n\nggplot(\n  data = penguins,\n  mapping = aes(\n    x = flipper_length_mm, \n    y = body_mass_g)\n  )\n\n\n\n\n\n\n\n\n\n\n2. Adding in the aesthetics mapping for the x and y-axis",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#data-visualization-in-r4ds---palmer-penguins-2",
    "href": "Lectures/02_VizBasics/index.html#data-visualization-in-r4ds---palmer-penguins-2",
    "title": "Basics of Data Visualization",
    "section": "Data Visualization in R4DS - Palmer Penguins",
    "text": "Data Visualization in R4DS - Palmer Penguins\nR4DS gives an example ggplot2 build using Palmer Penguins\n\n\n#Add geom_point()\n\nggplot(\n  data = penguins,\n  mapping = aes(\n    x = flipper_length_mm, \n    y = body_mass_g)\n  ) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n3. Finally defining points as the geometric objects to get a scatterplot",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#eda-on-star-wars",
    "href": "Lectures/02_VizBasics/index.html#eda-on-star-wars",
    "title": "Basics of Data Visualization",
    "section": "EDA on Star Wars",
    "text": "EDA on Star Wars\n\nMany packages have datasets readily available; you can check what’s in base R with data()\nThe dplyr package has one dataset on Star Wars characters\nOnce we load dplyr we have he starwars tibble accessible in our environment",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---begin-by-looking-at-the-data",
    "href": "Lectures/02_VizBasics/index.html#star-wars---begin-by-looking-at-the-data",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Begin by Looking at the Data",
    "text": "Star Wars - Begin by Looking at the Data\n\n\nstarwars is a tibble, a special type of data frame that’s tidy\n\n\n\n#The object starwars is both a \"data.frame\" (data frame) and a \"tbl\" (tibble)\nclass(starwars)\n#&gt; [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nPrinting a tibble to the console gives expanded dataset information\n\n\n\n\n# A tibble: 87 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n# ℹ 82 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---whats-in-the-data-set",
    "href": "Lectures/02_VizBasics/index.html#star-wars---whats-in-the-data-set",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - What’s in the Data Set?",
    "text": "Star Wars - What’s in the Data Set?\n\n\n\n\n\n\n\nWhat does each row represent?   What does each column represent?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---luke-skywalker-observation-1",
    "href": "Lectures/02_VizBasics/index.html#star-wars---luke-skywalker-observation-1",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Luke Skywalker, Observation 1",
    "text": "Star Wars - Luke Skywalker, Observation 1",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---other-ways-to-investigate",
    "href": "Lectures/02_VizBasics/index.html#star-wars---other-ways-to-investigate",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Other Ways to Investigate",
    "text": "Star Wars - Other Ways to Investigate\n\nThe dplyr package also has the glimpse() function\n\n\n\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---other-ways-to-investigate-1",
    "href": "Lectures/02_VizBasics/index.html#star-wars---other-ways-to-investigate-1",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Other Ways to Investigate",
    "text": "Star Wars - Other Ways to Investigate\n\n\nRun ?starwars in the Console to view the help documentation\n\n#Check the help for the starwars object\n?starwars\n\n#Search help for the term \"starwars\"\n??\"starwars\"\n\nQuestion: How many rows and columns does this dataset have?\nMake a prediction: What relationship do you expect to see between height and mass?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---mass-vs.-height",
    "href": "Lectures/02_VizBasics/index.html#star-wars---mass-vs.-height",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Mass vs. Height",
    "text": "Star Wars - Mass vs. Height\n\nggplot(data = starwars) +\n  aes(x = height, y = mass) +\n  geom_point()\n\nWarning: Removed 28 rows containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---whats-that-warning",
    "href": "Lectures/02_VizBasics/index.html#star-wars---whats-that-warning",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - What’s that Warning?",
    "text": "Star Wars - What’s that Warning?\n\nNot all characters have height and mass data, so 28 aren’t plotted\n\n\n## Warning: Removed 28 rows containing missing values (geom_point).\n\n\n\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Arvel Cr…     NA    NA brown      fair       brown             NA male  mascu…\n2 Finn          NA    NA black      dark       dark              NA male  mascu…\n3 Rey           NA    NA brown      light      hazel             NA fema… femin…\n4 Poe Dame…     NA    NA brown      light      brown             NA male  mascu…\n5 BB8           NA    NA none       none       black             NA none  mascu…\n6 Captain …     NA    NA none       none       unknown           NA fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\n\n\n\n\n\nImportant\n\n\nWe’ll suppress the warning to save room but take note ggplot2 is telling you about missingness",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---mass-vs.-height---data-anomalies",
    "href": "Lectures/02_VizBasics/index.html#star-wars---mass-vs.-height---data-anomalies",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Mass vs. Height - Data Anomalies",
    "text": "Star Wars - Mass vs. Height - Data Anomalies\n\nHow would you describe this relationship?\nWho is the not so tall but really chonky character?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#star-wars---jabba-the-plott",
    "href": "Lectures/02_VizBasics/index.html#star-wars---jabba-the-plott",
    "title": "Basics of Data Visualization",
    "section": "Star Wars - Jabba the Plott",
    "text": "Star Wars - Jabba the Plott",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#aesthetics-options",
    "href": "Lectures/02_VizBasics/index.html#aesthetics-options",
    "title": "Basics of Data Visualization",
    "section": "Aesthetics Options",
    "text": "Aesthetics Options\nWe’ve already seen aesthetics with x-axis and y-axis mapping\nAesthetics are visual characteristics that can be mapped to data to aid understanding\nThese are geom specific, examples from geom_point()\n\ncolor\nsize\nshape\nalpha (transparency)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#aesthetics---adding-gender-to-mass-vs.-height",
    "href": "Lectures/02_VizBasics/index.html#aesthetics---adding-gender-to-mass-vs.-height",
    "title": "Basics of Data Visualization",
    "section": "Aesthetics - Adding Gender to Mass vs. Height",
    "text": "Aesthetics - Adding Gender to Mass vs. Height",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#aesthetics---some-aesthetics-of-other-geoms",
    "href": "Lectures/02_VizBasics/index.html#aesthetics---some-aesthetics-of-other-geoms",
    "title": "Basics of Data Visualization",
    "section": "Aesthetics - Some Aesthetics of Other Geoms",
    "text": "Aesthetics - Some Aesthetics of Other Geoms\n\ngeom_line() also has “linetype” for solid or dashed lines\ngeom_bar() uses “fill” for the body of the bar instead of “color”",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#aesthetics---mappings-are-data-type-dependent",
    "href": "Lectures/02_VizBasics/index.html#aesthetics---mappings-are-data-type-dependent",
    "title": "Basics of Data Visualization",
    "section": "Aesthetics - Mappings Are Data Type Dependent",
    "text": "Aesthetics - Mappings Are Data Type Dependent\n\nCategorical variables are measured (often counted) on a discrete scale\n\n\n\n\n\n\n\n\n\nAesthetics\nDiscrete\n\n\n\n\ncolor\ndifferent color for each category\n\n\nsize\ndiscrete steps in sizes\n\n\nshape\ndifferent shapes for each category\n\n\n\n\n\n\n\n\nContinuous variable are measured on a continuous scale\n\n\n\n\n\n\n\n\n\nAesthetics\nContinuous\n\n\n\n\ncolor\ncolor gradient\n\n\nsize\nlinear mapping between radius and value\n\n\nshape\nshouldn't (and doesn't) work",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#looking-ahead---further-customization",
    "href": "Lectures/02_VizBasics/index.html#looking-ahead---further-customization",
    "title": "Basics of Data Visualization",
    "section": "Looking Ahead - Further Customization",
    "text": "Looking Ahead - Further Customization\nWhen we return to plotting in a couple of weeks we’ll discuss:\n\nPlotting with other geoms for line charts, box plots, histograms / density plots, tile plots, and many more\nAdvanced aesthetics and greater customization control\nPlotting summary values e.g. means and error bars\nLabelling and emphasizing datapoints of interest",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "Lectures/02_VizBasics/index.html#looking-ahead---todays-exercise",
    "href": "Lectures/02_VizBasics/index.html#looking-ahead---todays-exercise",
    "title": "Basics of Data Visualization",
    "section": "Looking Ahead - Today’s Exercise",
    "text": "Looking Ahead - Today’s Exercise\nFor the exercise today we’ll be working with the gapminder dataset and adding in some additional concepts\n\nMultiple geoms - line of fit over scatterplots\nWorking with x-axis and y-axis scales e.g. log transformations\nLabelling axis and titles\n\nThis is also going to force you to start to work with the help menu, cheat sheets, and Posit Cloud recipes to start to answer your own questions\nRachel and I are here to help but also ask each other!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "html_files/06_Adv_Visual/exercise_solutions.html",
    "href": "html_files/06_Adv_Visual/exercise_solutions.html",
    "title": "Data visualization tools",
    "section": "",
    "text": "The supermarket data are synthetic but realistic observations of customer interactions in various counties. The exercises in this document are based on a tutorial written on the UC Business Analytics blog\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\n\n\nReview this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of Super Market data\n\n\nVariable name\nVariable description\n\n\n\n\nTransaction\ntransaction number\n\n\nPurchase Date\ndate of purchase\n\n\nCustomer ID\ncustomer identification\n\n\nGender\n--\n\n\nMarital Status\n--\n\n\nHomeowner\n--\n\n\nChildren\nnumber of kids at home\n\n\nAnnual Income\nincome of customer\n\n\nCity\n--\n\n\nState or Province\n--\n\n\nCountry\nCanada, Mexico, or USA\n\n\nProduct Family\ndrink, food, or non-consumable\n\n\nProduct Department\nthe item's department\n\n\nProduct Category\nthe item's type\n\n\nUnits Sold\nnumber of items sold\n\n\nRevenue\nmoney generated by the transaction",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "html_files/06_Adv_Visual/exercise_solutions.html#import",
    "href": "html_files/06_Adv_Visual/exercise_solutions.html#import",
    "title": "Data visualization tools",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "html_files/06_Adv_Visual/exercise_solutions.html#data-dictionary",
    "href": "html_files/06_Adv_Visual/exercise_solutions.html#data-dictionary",
    "title": "Data visualization tools",
    "section": "",
    "text": "Review this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of Super Market data\n\n\nVariable name\nVariable description\n\n\n\n\nTransaction\ntransaction number\n\n\nPurchase Date\ndate of purchase\n\n\nCustomer ID\ncustomer identification\n\n\nGender\n--\n\n\nMarital Status\n--\n\n\nHomeowner\n--\n\n\nChildren\nnumber of kids at home\n\n\nAnnual Income\nincome of customer\n\n\nCity\n--\n\n\nState or Province\n--\n\n\nCountry\nCanada, Mexico, or USA\n\n\nProduct Family\ndrink, food, or non-consumable\n\n\nProduct Department\nthe item's department\n\n\nProduct Category\nthe item's type\n\n\nUnits Sold\nnumber of items sold\n\n\nRevenue\nmoney generated by the transaction",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "html_files/05_Transform/exercise_solutions.html",
    "href": "html_files/05_Transform/exercise_solutions.html",
    "title": "Derive information with dplyr",
    "section": "",
    "text": "NHANES (The National Health and Nutrition Examination Survey) was designed to assess the health and nutritional status of the US population and is conducted by the National Center for Health Statistics of the Centers for Disease Control and Prevention. Since 1999-2000, NHANES has been conducted in two-year cycles. For each cycle, potential participants are identified through stratified, multistage probability sampling of the non-institutionalized US population. In this set of exercises, we will use the ten cycles conducted from 1999-2000 through 2017-2018.\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n  \n\n\n\n\n\n\nReview this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/05_Transform/exercise_solutions.html#import",
    "href": "html_files/05_Transform/exercise_solutions.html#import",
    "title": "Derive information with dplyr",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/05_Transform/exercise_solutions.html#data-dictionary",
    "href": "html_files/05_Transform/exercise_solutions.html#data-dictionary",
    "title": "Derive information with dplyr",
    "section": "",
    "text": "Review this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/06_Adv_Visual/class_exercises.html",
    "href": "html_files/06_Adv_Visual/class_exercises.html",
    "title": "Data visualization tools",
    "section": "",
    "text": "The supermarket data are synthetic but realistic observations of customer interactions in various counties. The exercises in this document are based on a tutorial written on the UC Business Analytics blog\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\n\n\nReview this briefly and use it as a reference to engage with the exercises below.\n\nsupermarket_descr &lt;-\n  c(\n    \"Transaction\"        = \"transaction number\",\n    \"Purchase Date\"      = \"date of purchase\",\n    \"Customer ID\"        = \"customer identification\",\n    \"Gender\"             = \"--\",\n    \"Marital Status\"     = \"--\",\n    \"Homeowner\"          = \"--\",\n    \"Children\"           = \"number of kids at home\",\n    \"Annual Income\"      = \"income of customer\",\n    \"City\"               = \"--\",\n    \"State or Province\"  = \"--\",\n    \"Country\"            = \"Canada, Mexico, or USA\",\n    \"Product Family\"     = \"drink, food, or non-consumable\",\n    \"Product Department\" = \"the item's department\",\n    \"Product Category\"   = \"the item's type\",\n    \"Units Sold\"         = \"number of items sold\",\n    \"Revenue\"            = \"money generated by the transaction\"\n  )\n\n# the enframe function transforms a vector into a tibble,\nenframe(supermarket_descr) |&gt; \n  gt(rowname_col = \"name\") |&gt;\n  tab_stubhead(label = 'Variable name') |&gt; \n  cols_label(value = 'Variable description') |&gt;\n  cols_align('right') |&gt;\n  tab_header(title = 'Description of Super Market data')\n\n\n\n\n\n\n\nDescription of Super Market data\n\n\nVariable name\nVariable description\n\n\n\n\nTransaction\ntransaction number\n\n\nPurchase Date\ndate of purchase\n\n\nCustomer ID\ncustomer identification\n\n\nGender\n--\n\n\nMarital Status\n--\n\n\nHomeowner\n--\n\n\nChildren\nnumber of kids at home\n\n\nAnnual Income\nincome of customer\n\n\nCity\n--\n\n\nState or Province\n--\n\n\nCountry\nCanada, Mexico, or USA\n\n\nProduct Family\ndrink, food, or non-consumable\n\n\nProduct Department\nthe item's department\n\n\nProduct Category\nthe item's type\n\n\nUnits Sold\nnumber of items sold\n\n\nRevenue\nmoney generated by the transaction",
    "crumbs": [
      "Home",
      "Assignments",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "html_files/06_Adv_Visual/class_exercises.html#import",
    "href": "html_files/06_Adv_Visual/class_exercises.html#import",
    "title": "Data visualization tools",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test",
    "crumbs": [
      "Home",
      "Assignments",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "html_files/06_Adv_Visual/class_exercises.html#data-dictionary",
    "href": "html_files/06_Adv_Visual/class_exercises.html#data-dictionary",
    "title": "Data visualization tools",
    "section": "",
    "text": "Review this briefly and use it as a reference to engage with the exercises below.\n\nsupermarket_descr &lt;-\n  c(\n    \"Transaction\"        = \"transaction number\",\n    \"Purchase Date\"      = \"date of purchase\",\n    \"Customer ID\"        = \"customer identification\",\n    \"Gender\"             = \"--\",\n    \"Marital Status\"     = \"--\",\n    \"Homeowner\"          = \"--\",\n    \"Children\"           = \"number of kids at home\",\n    \"Annual Income\"      = \"income of customer\",\n    \"City\"               = \"--\",\n    \"State or Province\"  = \"--\",\n    \"Country\"            = \"Canada, Mexico, or USA\",\n    \"Product Family\"     = \"drink, food, or non-consumable\",\n    \"Product Department\" = \"the item's department\",\n    \"Product Category\"   = \"the item's type\",\n    \"Units Sold\"         = \"number of items sold\",\n    \"Revenue\"            = \"money generated by the transaction\"\n  )\n\n# the enframe function transforms a vector into a tibble,\nenframe(supermarket_descr) |&gt; \n  gt(rowname_col = \"name\") |&gt;\n  tab_stubhead(label = 'Variable name') |&gt; \n  cols_label(value = 'Variable description') |&gt;\n  cols_align('right') |&gt;\n  tab_header(title = 'Description of Super Market data')\n\n\n\n\n\n\n\nDescription of Super Market data\n\n\nVariable name\nVariable description\n\n\n\n\nTransaction\ntransaction number\n\n\nPurchase Date\ndate of purchase\n\n\nCustomer ID\ncustomer identification\n\n\nGender\n--\n\n\nMarital Status\n--\n\n\nHomeowner\n--\n\n\nChildren\nnumber of kids at home\n\n\nAnnual Income\nincome of customer\n\n\nCity\n--\n\n\nState or Province\n--\n\n\nCountry\nCanada, Mexico, or USA\n\n\nProduct Family\ndrink, food, or non-consumable\n\n\nProduct Department\nthe item's department\n\n\nProduct Category\nthe item's type\n\n\nUnits Sold\nnumber of items sold\n\n\nRevenue\nmoney generated by the transaction",
    "crumbs": [
      "Home",
      "Assignments",
      "06 - Advanced Visualization"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html",
    "href": "Lectures/01_Tools/index.html",
    "title": "Introducing your Tools",
    "section": "",
    "text": "Introductions\nA brief introduction to R\nRStudio Desktop and Posit Cloud\nWorking with Quarto and R Markdown\nVersion control and collaboration with git and GitHub",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#agenda",
    "href": "Lectures/01_Tools/index.html#agenda",
    "title": "Introducing your Tools",
    "section": "Agenda",
    "text": "Agenda\n\nIntroductions\nA brief introduction to R\nRStudio Desktop and Posit Cloud\nWorking with Quarto and R Markdown\nVersion control and collaboration with git and GitHub",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#bst-680",
    "href": "Lectures/01_Tools/index.html#bst-680",
    "title": "Introducing your Tools",
    "section": "BST 680",
    "text": "BST 680\nThe goal of this course is to familiarize you with using R for data engagements\n\nHow R is structured in vectors, dataframes, and lists\nWorking with different classes of data in R like logicals, characters, and dates\nBasics of visualization with ggplot2 (which we’ll just call ggplot)\nData wrangling with the tidyverse\nSome basics on functional programming and iteration",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#bst-680-1",
    "href": "Lectures/01_Tools/index.html#bst-680-1",
    "title": "Introducing your Tools",
    "section": "BST 680",
    "text": "BST 680\nWe will do this using RStudio Desktop and Posit Cloud\n\nHow the RStudio IDE is organized\nChanging options and layouts to support your needs\nWorking with Projects and building your own workflows and coding styles\nUsing markdown languages to unify code, results and output for sharing\nUsing other tools to support reproducibility and sharing\n\n\nWhat this course will NOT do is use any statistical testing",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#by-now-you-should-have",
    "href": "Lectures/01_Tools/index.html#by-now-you-should-have",
    "title": "Introducing your Tools",
    "section": "By now you should have",
    "text": "By now you should have\n\n\n\nSigned up for a Posit Cloud account\nInstalled R and RStudio Desktop locally\nStarted a GitHub account (this will come into play later)\nGotten a copy of R for Data Science (2e)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#introductions",
    "href": "Lectures/01_Tools/index.html#introductions",
    "title": "Introducing your Tools",
    "section": "Introductions",
    "text": "Introductions\n\n\n\nName\nDepartment\nDegree program\nHow did you most recently use statistical software for work or pleasure (R, Python, SAS, Prism, Excel, etc)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#working-with-r",
    "href": "Lectures/01_Tools/index.html#working-with-r",
    "title": "Introducing your Tools",
    "section": "Working with R",
    "text": "Working with R\nWho here…\n\n\nhas used R in any capacity?\nmade a plot using the ggplot2 “grammar of graphics”?\nmade a formatted table using a package like gt, kable, or something similar?\nknows how to use the tidyverse for data wrangling? (e.g. how does tidyr differ from dplyr)\nhas written their own function in R?\nknows why NA == NA does not return TRUE?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio-and-its-extensions",
    "href": "Lectures/01_Tools/index.html#rstudio-and-its-extensions",
    "title": "Introducing your Tools",
    "section": "RStudio and its extensions",
    "text": "RStudio and its extensions\nWho here…\n\n\nknows why it’s important to use Projects in RStudio?\ncan describe the difference between a .rds file and a .RData file?\nhas used markdown (R, Quarto, or otherwise) to make a sharable document?\ndeveloped a Shiny application in R?\nhas contributed to a third-party GitHub repository?\nknows why enquosures often fail inside of datamasks?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#an-overview-of-the-model",
    "href": "Lectures/01_Tools/index.html#an-overview-of-the-model",
    "title": "Introducing your Tools",
    "section": "An Overview of the Model",
    "text": "An Overview of the Model\nThe workflow as described by Wickham et. al. in R4DS\n\n\nWickham H, Cetinkaya-Rundel M, Grolemund G. (2023) R for Data Science, 2nd Edition. Sebastopol, CA: O’Reilly Media.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#an-overview-of-the-model-1",
    "href": "Lectures/01_Tools/index.html#an-overview-of-the-model-1",
    "title": "Introducing your Tools",
    "section": "An Overview of the Model",
    "text": "An Overview of the Model\n\nImporting - loading data into R (API, direct load, etc)\nTidying - getting your data into a consistent state for downstream use\nWrangling - modifying tidy data for better engagement e.g. new variable, summarizations, filtering\nVisualizing / Tabulation - organizing wrangled data into a format to assist understanding\nModelling - evaluating how aspects of the data relate to each other\nCommunication - letting others know about your results",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#our-toolkit",
    "href": "Lectures/01_Tools/index.html#our-toolkit",
    "title": "Introducing your Tools",
    "section": "Our Toolkit",
    "text": "Our Toolkit\n\n\n\n\n\nR \\(\\rightarrow\\) Pure scriptability for data engagement\nRStudio/Posit \\(\\rightarrow\\) Cohesive wrangling of code bases\nQuarto \\(\\rightarrow\\) Literate scripts combining code, narrative, and output in one\nGit / GitHub / renv \\(\\rightarrow\\) Version and environmental control for reproducible consistency",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#so-what-is-r",
    "href": "Lectures/01_Tools/index.html#so-what-is-r",
    "title": "Introducing your Tools",
    "section": "So what is R?",
    "text": "So what is R?\n\nA (functional) programming language\nThe environment in which the programming language is run\nDomain-specific language emphasizing data management and statistical analysis\nIt is NOT a general purpose language (although you can con it into behaving like one)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#r-essentials---a-very-short-list",
    "href": "Lectures/01_Tools/index.html#r-essentials---a-very-short-list",
    "title": "Introducing your Tools",
    "section": "R essentials - A VERY Short List",
    "text": "R essentials - A VERY Short List\n\nR begins with objects which store some sort of information, a string, series of numbers, complex data structure, etc.; these are the “nouns of the language\nFor storing data, we’ll often think of vectors, data frames, and lists\n\n\n\n#A vector\nc(vector_item1, vector_item2, vector_item3)\n\n#A dataframe, specficially having a column being accessed\ndata_frame$vcol_name\n\n#Accessing the element of a list\nsome_list[[list_entry]]",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#r-essentials---a-very-short-list-1",
    "href": "Lectures/01_Tools/index.html#r-essentials---a-very-short-list-1",
    "title": "Introducing your Tools",
    "section": "R essentials - A VERY Short List",
    "text": "R essentials - A VERY Short List\n\nR does its heavy lifting via functions which are the “verbs” is the language\nThese are comprised of the function() followed by a series of arguments which the function is applied to\n\n\n\n#Using the do_this() function to make something_new\nsomething_new &lt;- do_this(to_this)\n\n#Then using do_that() on something_new with some argumentns\ndo_that(something_new, also_that, using_these)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#r-essentials---a-very-short-list-2",
    "href": "Lectures/01_Tools/index.html#r-essentials---a-very-short-list-2",
    "title": "Introducing your Tools",
    "section": "R essentials - A VERY Short List",
    "text": "R essentials - A VERY Short List\n\nBut base R only has so many functions; thus most support comes from community-developed packages\nThose approved and hosted by CRAN can be installed using install.packages()\nOther options include BioConductor which focuses on Omics and other large datasets or GitHub for more developmental packages\nAll packages get loaded via the library() command to gain access to their functions but only once per session\n\n\n\n#Installing and loading the package_name library\ninstall.packages(\"package_name\")\nlibrary(package_name)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#the-r-console",
    "href": "Lectures/01_Tools/index.html#the-r-console",
    "title": "Introducing your Tools",
    "section": "The R Console",
    "text": "The R Console\n\nWe start with the R console but we will never use it directly (ever)\n\n\n\nOnly use this is you want to punish yourself",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio",
    "href": "Lectures/01_Tools/index.html#rstudio",
    "title": "Introducing your Tools",
    "section": "RStudio",
    "text": "RStudio\n\nInstead, we use the RStudio (more formally the RStudio Desktop) which is an IDE (Integrated Development Environment)\n\nUnifies the R console with code, environment, and viewing\nOrganizes code files, saved R objects, and external data into Projects\nMany other quality-of-life features will get into\n\nThis is common practice for ANY programming language\nOther examples would be Jupyter or IDLE (frequently used for Python) or Google Collab Notebooks",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#whats-a-posit",
    "href": "Lectures/01_Tools/index.html#whats-a-posit",
    "title": "Introducing your Tools",
    "section": "What’s a Posit?",
    "text": "What’s a Posit?\n\n\n\n\nIn mid-2022 RStudio (the company) changed their name to Posit to reflect a wider data science space than just R\nIn particular, the work very well with other programming languages like Python and Julia (which we won’t cover here)\n.e.g. RStudio integrates very will with Python code via the reticulate() package\nThey still refer to the local desktop IDE as “RStudio” although many other tools go by “Posit” now\nI will often refer to both of them interchangeably",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#what-is-posit-cloud",
    "href": "Lectures/01_Tools/index.html#what-is-posit-cloud",
    "title": "Introducing your Tools",
    "section": "What is Posit Cloud?",
    "text": "What is Posit Cloud?\n\n\n\n\n\n\nA hosted version of RStudio Desktop in the cloud that makes it easy to collaborate using Posit’s supported languages, primarily R and Python\nThis makes it an excellent way to teach and learn about data science using R, which is what we’ll be doing",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#lets-take-a-tour---rstudio-basics",
    "href": "Lectures/01_Tools/index.html#lets-take-a-tour---rstudio-basics",
    "title": "Introducing your Tools",
    "section": "Let’s Take a Tour - RStudio Basics",
    "text": "Let’s Take a Tour - RStudio Basics\nConcepts introduced:\n\nThe Panes - Console, Source, Environments, Output\nWorking in the console (like a barbarian)\nThe Environment - Projects and objects and files\nEngaging with data objects outside the console\nSource - R functions and working with them\nPersonalizing your RStudio experience\nMuch of this can be found in the RStudio User Guide",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-panes",
    "href": "Lectures/01_Tools/index.html#rstudio---the-panes",
    "title": "Introducing your Tools",
    "section": "RStudio - The Panes",
    "text": "RStudio - The Panes\n\nVisual display is comprised of four panes\n\nSource: Edit and save your scripts or other IDE documents like Quarto .qmd files\nConsole: Execute codes, directly or from the Source; access a Unix-esque Terminal for CLI tasks like git or quarto commands\nEnvironment: Controlling local R objects and other low-level session aspects\nOutput: Display created R outputs like plots/tables/HTML or other high-level controls (packages, files)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-panes-1",
    "href": "Lectures/01_Tools/index.html#rstudio---the-panes-1",
    "title": "Introducing your Tools",
    "section": "RStudio - The Panes",
    "text": "RStudio - The Panes\n\n\nhttps://docs.posit.co/ide/user/ide/get-started/#rstudio-panes",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-console",
    "href": "Lectures/01_Tools/index.html#rstudio---the-console",
    "title": "Introducing your Tools",
    "section": "RStudio - The Console",
    "text": "RStudio - The Console\n\nThe console allows for interactivity with R code and code execution\nIncludes several QoL improvements like code completion, fuzzy matching for functions, and linking to help documentation\nCan easily navigate previous commands from the console using the up arrow Up for single commands Ctrl+Up or Cmd+Up to access a list of prior commands\nAlso includes tabs for the Terminal (which we’ll discuss with Git)\nAlso displays your current working directory",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment",
    "text": "RStudio - The Environment\n\nThe environment powers “scoping” i.e. where and how data is stored locally for the current session\n\n\n\n\nFor our purposes, we’ll be a bit broader and think about the environment for…\n\nObjects - data structures made in the current session\nProjects - an organized association of files specific to a context\nFiles - R objects saved to files",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment---objects",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment---objects",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment - Objects",
    "text": "RStudio - The Environment - Objects\n\nAn Object is any locally created “thing” saved within the current session\nYou can see (most) objects listed in the Environment tab which provide a lot of additional information",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment---projects",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment---projects",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment - Projects",
    "text": "RStudio - The Environment - Projects\n\nProjects let you associate everything related to a single contextual task together:\n\nInput data\nScripts\nSaved outputs like results, figures, or R objects\nFolder structures\n\nThis also lets you divide your work so each task has it’s own working directory, workspace, history, and source documentation\nFor example, each of these lectures is it’s own project",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment---projects-1",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment---projects-1",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment - Projects",
    "text": "RStudio - The Environment - Projects\n\nProjects are controlled by .RProj files and contain all project-specific options, metadata and temporary files\nProject can be easily created/navigated and you can overwrite global options in RStudio based on project specific needs",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment---files",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment---files",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment - Files",
    "text": "RStudio - The Environment - Files\n\nWithin a project, you can have many indivdual Files\nThis can be raw input data in common file formats like delimited files (.csv, .tsv, .txt, etc) or something more elaborate like Excel workbooks\n\nThese are designed to be read into the current local environment for the current session\n\nSimilar output formats can be saved as those file types, individual image files in many formats, or compiled reports generation from Quarto or R Markdown\n\nFolder structure in your project helps with organizing input/output",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment---files-1",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment---files-1",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment - Files",
    "text": "RStudio - The Environment - Files\nThere are also R and RStudio specific files we can use\n\n.R - source scripts, ways to store the code you write\n.rds - individual data objects written to and read from file\n\n\n#Make something\ni_made_an_object &lt;- c(\"it\", \"has\", \"stuff\")\n\n#Save it to file\nsaveRDS(i_made_an_object, file = \"and_i_want_to_save_it.rds\")\n\n#And get it back as needed\nnow_i_need_it_back &lt;- readRDS(\"and_i_want_to_save_it.rds\")\n\n\n.RData - An entire workspace consisting of multiple objects / .rds files\n.qmd / .rmd - Markdown files used to generate sharable formats",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-environment---files-2",
    "href": "Lectures/01_Tools/index.html#rstudio---the-environment---files-2",
    "title": "Introducing your Tools",
    "section": "RStudio - The Environment - Files",
    "text": "RStudio - The Environment - Files\n\nYou can easily navigate your files and folder structures (as well as other things) in the Output pane",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---viewing-objects",
    "href": "Lectures/01_Tools/index.html#rstudio---viewing-objects",
    "title": "Introducing your Tools",
    "section": "RStudio - Viewing Objects",
    "text": "RStudio - Viewing Objects\n\n\n\nWe’ll spend a lot of time engaging with objects programatically, but sometimes you want to just play with a data object\nFor this we can use the Data Viewer using either the View() command or from the Environment tab\nIt does have some limitations, you can learn more from the RStudio User’s Guide",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-source-panel",
    "href": "Lectures/01_Tools/index.html#rstudio---the-source-panel",
    "title": "Introducing your Tools",
    "section": "RStudio - The Source Panel",
    "text": "RStudio - The Source Panel\n\nMost of what your active engagement will take place in the source panel where you will write and execute code\nMuch of what you see and do is context dependent according to the type of file you’re working on e.g. .R scripts vs .qmd Markdown",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---the-source-panel-1",
    "href": "Lectures/01_Tools/index.html#rstudio---the-source-panel-1",
    "title": "Introducing your Tools",
    "section": "RStudio - The Source Panel",
    "text": "RStudio - The Source Panel\n\nExecuting code from the Source can be done in a myriad of ways\n\nOne line a time using Ctrl+Enter or the Run button on the toolbar\nMultiple lines at once by highlighting several lines before using Ctrl+Enter or Run\nRunning the whole document via Ctrl+Shift+Enter or the Source toolbar button\n\n\n\n\nRunning code is similar for Quarto markdown or other computational documents although we work with code chunks instead",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---personalizing-the-experience",
    "href": "Lectures/01_Tools/index.html#rstudio---personalizing-the-experience",
    "title": "Introducing your Tools",
    "section": "RStudio - Personalizing the Experience",
    "text": "RStudio - Personalizing the Experience\n\nMany aspects of RStudio and Posit Cloud can be modified by going to Tools &gt; Options menu or RStudio &gt; Peferences on a Mac",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---personalizing-the-experience-1",
    "href": "Lectures/01_Tools/index.html#rstudio---personalizing-the-experience-1",
    "title": "Introducing your Tools",
    "section": "RStudio - Personalizing the Experience",
    "text": "RStudio - Personalizing the Experience\n\n\n\nAn older (September 2023) guide can be found on the Posit website\nSome additional components not discussed there include options for the Console, R Markdown, Python, and Git’s Copilot\nYou can do very well with the defaults but play around a bit to see what works for you; most aesthetic choices are in the Pane Layout and Appearance tabs",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---personalizing-the-experience-2",
    "href": "Lectures/01_Tools/index.html#rstudio---personalizing-the-experience-2",
    "title": "Introducing your Tools",
    "section": "RStudio - Personalizing the Experience",
    "text": "RStudio - Personalizing the Experience\n\nSo set it up as you’d like but I have some quick recommendations\n\nUnder General R Options uncheck the first two options for R Sessions so you don’t automatically open the previous project or source documentation each time\nFor Workspace, uncheck the restoration of .RData into your workspace and set Save Workspace to “Never”\nUnder Code enable the native pipe operator |&gt; which we’ll use in place of the previous pipe of magrittr (%&gt;%)\nSpend some time with the Pane Layout as well as relative positioning\n\n1 and 2 in particular are best practice for memory considerations",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#rstudio---some-final-tips",
    "href": "Lectures/01_Tools/index.html#rstudio---some-final-tips",
    "title": "Introducing your Tools",
    "section": "RStudio - Some Final Tips",
    "text": "RStudio - Some Final Tips\n\nKeyboard Shortcuts!! Alt+Shift+K or Alt+Shift+K or Tools menu\n\n\n\nCheatsheets!! Posit has many, many cheat sheets you can find on their website including concise PDFs",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#posit-cloud---key-points",
    "href": "Lectures/01_Tools/index.html#posit-cloud---key-points",
    "title": "Introducing your Tools",
    "section": "Posit Cloud - Key Points",
    "text": "Posit Cloud - Key Points\n\nThe Posit IDE is no different from what you see in RStudio Desktop, this includes customizations\nNavigation between workspaces and help is done via the sidebar\nSpend some time with the Learn section which includes\n\nGuide - basic user guide for Posit Cloud\nRecipes - vignettes and code snippets\nCheatsheets - another link to the Posit cheatsheets\n\nWe also add another layer of organization with Spaces",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#posit-cloud---spaces",
    "href": "Lectures/01_Tools/index.html#posit-cloud---spaces",
    "title": "Introducing your Tools",
    "section": "Posit Cloud - Spaces",
    "text": "Posit Cloud - Spaces\n\nSpaces or Workspaces are essentially collections of Projects we share on the Cloud\nBST 680 has its own Space with each Project in the space containing everything needed for a lecture topic:\n\nLectures, exercises, tutorials, support files, etc\n\nSince this is a shared space, make sure you save a copy of each project to your own space\nOnly you and the instructors can access these saved projects\nYou can also export your projects to a local system for later use; although the Workspace shouldn’t be going away",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#what-is-the-tidyverse",
    "href": "Lectures/01_Tools/index.html#what-is-the-tidyverse",
    "title": "Introducing your Tools",
    "section": "What is the Tidyverse?",
    "text": "What is the Tidyverse?\n\n\n\n\ntidyverse.org\n\n\nThe tidyverse is an opinionated collection of R packages designed for data science.\nAll packages share an underlying philosophy and a common syntax.\n\n\n\nThe tidyverse is central to our text and we will work with it extensively along with many base R functions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#the-tidyverse---a-quick-introduction",
    "href": "Lectures/01_Tools/index.html#the-tidyverse---a-quick-introduction",
    "title": "Introducing your Tools",
    "section": "The Tidyverse - a quick introduction",
    "text": "The Tidyverse - a quick introduction\n\nggplot2 - Creating visualizations using the “grammar of graphics”\ndplyr - Modifying and manipulating data\ntidyr - Making datasets consistent aka “tidy”\nstringr - Interacting with strings, including text matching\nforcats - Working with factor class variables\nlubridate - Making working with date data easier\npurrr - Simplifying iteration\nreadr - A high-level way to read (most) file types",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#the-tidyverse---the-soapbox",
    "href": "Lectures/01_Tools/index.html#the-tidyverse---the-soapbox",
    "title": "Introducing your Tools",
    "section": "The Tidyverse - The Soapbox",
    "text": "The Tidyverse - The Soapbox",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#quarto-as-markdown",
    "href": "Lectures/01_Tools/index.html#quarto-as-markdown",
    "title": "Introducing your Tools",
    "section": "Quarto as Markdown",
    "text": "Quarto as Markdown\n\nQuarto is a markdown implementation that helps you communicate results\n\nMarkdown simply is a way to “mark up” otherwise simple text\n\nProvides dynamically updated or reproducible reports - each time you knit the code base will be run de novo\nThe literate programming allows for formatting of simple text but also let’s you interact with code\nCode goes in chunks, defined by three backticks, narrative goes outside of chunks",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#lets-take-a-tour---quarto",
    "href": "Lectures/01_Tools/index.html#lets-take-a-tour---quarto",
    "title": "Introducing your Tools",
    "section": "Let’s take a tour - Quarto",
    "text": "Let’s take a tour - Quarto\nCheckout the intro_to_Quarto.qmd (and rendered .html) file to get an introduction to:\n\nLiterate programming - ntergrating code, text and output\nRendering output\nHigh-level control via the YAML headers and themes\nTabulating data with gt",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#quarto-tips",
    "href": "Lectures/01_Tools/index.html#quarto-tips",
    "title": "Introducing your Tools",
    "section": "Quarto tips",
    "text": "Quarto tips\n\nThe Quarto site (https://quarto.org) is a great place for getting started or getting other Guidance\nYou can check out the Quarto cheatsheet here\nYou can also check the Markdown Quick Reference in RStudio in the Help menu\n\n\n\n\n\n\n\nImportant\n\n\nThe workspace of your Quarto document is separate from whatever is loaded in your environment",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#how-will-we-use-quarto",
    "href": "Lectures/01_Tools/index.html#how-will-we-use-quarto",
    "title": "Introducing your Tools",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEverything we do, exercise / assignment / project / etc., is a Quarto document.\nYou’ll always have a template Quarto document to start with\nMost of what you do early on, will simply be adding relevant code to get the desired output\nWe’ll do a deeper dive into Quarto customization at the end of the course",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#r-markdown-vs-quarto",
    "href": "Lectures/01_Tools/index.html#r-markdown-vs-quarto",
    "title": "Introducing your Tools",
    "section": "R Markdown vs Quarto",
    "text": "R Markdown vs Quarto\n\nIf you’ve used R Markdown you’ll notice some similarities with Quarto, so why Quarto?\nQuarto provides a couple of benefits over what R Markdown down has done up to this point\n\nMuch of the functionality of the R Markdown ecosystem is now unified\nNative support has been extended to other programming languages\nBehavior of niche applications (e.g. xaringan) is now consistent\n\nStill, for R Markdown specifically, you can always check the R Markdown cheat sheet",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#git-and-github---how-we-collaborate",
    "href": "Lectures/01_Tools/index.html#git-and-github---how-we-collaborate",
    "title": "Introducing your Tools",
    "section": "Git and GitHub - How we collaborate",
    "text": "Git and GitHub - How we collaborate\n\nThe statistical programming language we use is R\nThe software we use to interface with R is RStudio or Posit\n\nBut…\n\n\nHow do I get you the materials for your assignments?\nWhat happens if I need to update those materials?\nHow do I pull my updates into Posit Cloud?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#git-and-github---version-control",
    "href": "Lectures/01_Tools/index.html#git-and-github---version-control",
    "title": "Introducing your Tools",
    "section": "Git and GitHub - Version control",
    "text": "Git and GitHub - Version control\n\nEarly on, we will only require GitHub use as a platform for collaboration\n\n\n\nBut it’s actually designed for version control which we’ll discuss alongside support packages like renv and targets for supporting:\n\nRigor\nReproducibility\nData sharing",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#versioning---bare-bones",
    "href": "Lectures/01_Tools/index.html#versioning---bare-bones",
    "title": "Introducing your Tools",
    "section": "Versioning - Bare Bones",
    "text": "Versioning - Bare Bones\nVersioning lets us track our progress (and go back!)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#versioning---with-commits",
    "href": "Lectures/01_Tools/index.html#versioning---with-commits",
    "title": "Introducing your Tools",
    "section": "Versioning - With Commits",
    "text": "Versioning - With Commits\nWe can go further by using “commit” messages to show our progress",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#why-do-we-need-version-control",
    "href": "Lectures/01_Tools/index.html#why-do-we-need-version-control",
    "title": "Introducing your Tools",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\nPhD Comics - https://phdcomics.com/comics/archive.php?comicid=1531",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#git-vs-github",
    "href": "Lectures/01_Tools/index.html#git-vs-github",
    "title": "Introducing your Tools",
    "section": "Git vs GitHub",
    "text": "Git vs GitHub\n\n\n\nGit is a version control system, like track changes but much, much better\nGitHub is the home for your git-based projects (a.k.a. repositories) online, like OneDrive but much, much better",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#git-and-github---final-thoughts",
    "href": "Lectures/01_Tools/index.html#git-and-github---final-thoughts",
    "title": "Introducing your Tools",
    "section": "Git and GitHub - Final Thoughts",
    "text": "Git and GitHub - Final Thoughts\n\nThere are a tremendous number of git commands, most of which we will never use; instead, most of your utilization will be to use git to add, commit, push, and pull\nOur formal interaction will be limited, but we will be installing git locally and I encourage you to get used to using it in practice\nStill, if you’re feeling ambitious, everyone can benefit from learning more about git and engaging with GitHub\nThere is a great resource for working with git and R: happygitwithr.com",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/01_Tools/index.html#recap-and-next-time",
    "href": "Lectures/01_Tools/index.html#recap-and-next-time",
    "title": "Introducing your Tools",
    "section": "Recap and Next Time",
    "text": "Recap and Next Time\nCan you answer these questions?\n\nWhat is R vs RStudio vs Posit?\nWhat is Quarto and why does it matter?\nWhat is git vs GitHub and do I need to care)?\nWhat is version control and why do we care?\n\nNext time\n\nSome actual coding and getting started with visualization",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "01 - Introducing Your Tools"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html",
    "href": "Lectures/03_Programming/index.html",
    "title": "Programming Basics",
    "section": "",
    "text": "Any questions on basics of visualization from last time?\n\nFor review, see chapter 2 from R4DS\nFor recipes, you can check the first, second, and eighth recipes under Visualize Data on Posit Cloud\n\nAny questions on the reading / primer?\n\nYou’ve gotten some experience running R code with visualization but now we need to dive into the fundamentals",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#catch-up",
    "href": "Lectures/03_Programming/index.html#catch-up",
    "title": "Programming Basics",
    "section": "Catch Up",
    "text": "Catch Up\n\nAny questions on basics of visualization from last time?\n\nFor review, see chapter 2 from R4DS\nFor recipes, you can check the first, second, and eighth recipes under Visualize Data on Posit Cloud\n\nAny questions on the reading / primer?\n\nYou’ve gotten some experience running R code with visualization but now we need to dive into the fundamentals",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#agenda",
    "href": "Lectures/03_Programming/index.html#agenda",
    "title": "Programming Basics",
    "section": "Agenda",
    "text": "Agenda\n\n\n\n\nFunctions\nAccessing Data\nVectors\n\nFull disclosure:\n\nThese topics are extremely important\nThey will also seem boringly useless…",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#review---coding-basics",
    "href": "Lectures/03_Programming/index.html#review---coding-basics",
    "title": "Programming Basics",
    "section": "Review - Coding Basics",
    "text": "Review - Coding Basics\n\nWe already know R can serve as a calculator\n\n\n7 + 3 * 5\n#&gt; [1] 22\n\n\nWe also know we can take data and assign it to the R essentials using the assignment operator &lt;-\n\n\nxx &lt;- 7 + 3 * 5\nxx\n#&gt; [1] 22 \n\n\nFinally, we write comments using # to tell others about our code\n\n\n#I assigned a value to xx\nxx &lt;- 7 + 3 * 5",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#review---the-r-essentials-short-list",
    "href": "Lectures/03_Programming/index.html#review---the-r-essentials-short-list",
    "title": "Programming Basics",
    "section": "Review - The R Essentials Short List",
    "text": "Review - The R Essentials Short List\nWe’re already touched on the “nouns” and “verbs” as the R Essentials\n\n\nThe nouns are objects which store some sort of data or information\n\nThese are the vectors, data frames, and lists\nBut most R processes make objects e.g. your plots from last time were also objects\n\n\n\n\n\nThe verbs are functions which do work on objects using arguments\n\n\nfunction_name(argument1 = value1, argument2 = value2, ...)\n\n\nLet’s dive a bit deeper into functions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---a-basic-example",
    "href": "Lectures/03_Programming/index.html#functions---a-basic-example",
    "title": "Programming Basics",
    "section": "Functions - A Basic Example",
    "text": "Functions - A Basic Example\nBroadly, a function starts with inputs, applies a process, and finally returns one or more outputs\n\nFunctions are everywhere and not just in programming, for example…\n\ninputs: eggs, chocolate chips, flour, sugar, butter\nprocess: preheat oven, mix ingredients, bake, let cool\noutputs: delicious chocolate chip cookies\n\n\nIt’s worth mentioning an algorithm is the high-level “recipe” (a procedural series of steps) while the function is the actual implementation, whether in code or otherwise",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---functions-in-r",
    "href": "Lectures/03_Programming/index.html#functions---functions-in-r",
    "title": "Programming Basics",
    "section": "Functions - Functions in R",
    "text": "Functions - Functions in R\nIn R, the function output is usually assigned to a new variable\n\ncookie_batch &lt;- make_cookies(batch_size = 12)\n\n\nWorking with our R Essentials list:\n\nmake_cookies() is the function\nbatch_size is the (only listed) argument\n12 is the value we provide for the batch_size argument\ncookie_batch is the object which we assign the output\nfrom make_cookies() to",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---functions-in-r-1",
    "href": "Lectures/03_Programming/index.html#functions---functions-in-r-1",
    "title": "Programming Basics",
    "section": "Functions - Functions in R",
    "text": "Functions - Functions in R\nIn R, the function output is usually assigned to a new variable\n\ncookie_batch &lt;- make_cookies(batch_size = 12)\n\n\nA command like this creates a new object in the global environment that can now be accessed using subsequent commands\n\n\nfull_chad &lt;- shove_food_in_face(to = chad, what = cookie_batch)\n\n\nRather than create full_chad we can also modify the original chad\n\n\nchad &lt;- shove_food_in_face(to = chad, what = cookie_batch)\n\n\nNote, both the to argument and output of shove_food_in_face() operate on chad",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---working-with-arguments",
    "href": "Lectures/03_Programming/index.html#functions---working-with-arguments",
    "title": "Programming Basics",
    "section": "Functions - Working with Arguments",
    "text": "Functions - Working with Arguments\n\nArguments are the parameters we pass to a function and all arguments must be specified\nHowever, many arguments have default values\n\nThese values are used when a value is not specified\nHowever, they can be changed if desired when calling the function\n\nArguments without default values MUST be specified\nFinally, all argument values that are specified must* exist in the global environment when the function is called",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---winning-the-argument",
    "href": "Lectures/03_Programming/index.html#functions---winning-the-argument",
    "title": "Programming Basics",
    "section": "Functions - Winning the Argument",
    "text": "Functions - Winning the Argument\n\nLet’s look at the help page for mean() and check the default method\n\n\n\nWe see x does not have defaults but trim and na.rm do",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---winning-the-argument-1",
    "href": "Lectures/03_Programming/index.html#functions---winning-the-argument-1",
    "title": "Programming Basics",
    "section": "Functions - Winning the argument",
    "text": "Functions - Winning the argument\n\nSo x must be specified and must exist otherwise we get an errors\n\n\n#Specify a vector\nxx &lt;- c(1,2,3,4,5)\n\n#Get the mean\nmean(xx)\n\n[1] 3\n\n#But if we don't specify a value for x we get an error\nmean()\n\nError in mean.default(): argument \"x\" is missing, with no default\n\n#Furthermore, it must exist\nmean(yy)\n\nError in eval(expr, envir, enclos): object 'yy' not found",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---winning-the-argument-2",
    "href": "Lectures/03_Programming/index.html#functions---winning-the-argument-2",
    "title": "Programming Basics",
    "section": "Functions - Winning the argument",
    "text": "Functions - Winning the argument\n\nYou don’t have to specify defaults but you can modify them\n\n\n#Specify a vector with an NA\nxx &lt;- c(1,2,3,4,5,NA)\n\n#By default, na.rm is set to false so NA is returned\nmean(xx)\n\n[1] NA\n\n#But we can modify na.rm to TRUE to drop NA's from x\nmean(xx, na.rm = TRUE)\n\n[1] 3\n\n\n\nWhen reading the help menu for a function, be sure to check the arguments to see what they do and which ones have defaults you may (or may not) want to modify",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---back-to-the-environment",
    "href": "Lectures/03_Programming/index.html#functions---back-to-the-environment",
    "title": "Programming Basics",
    "section": "Functions - Back to the Environment",
    "text": "Functions - Back to the Environment\n\nWe previously discussed environments as the container where things created in R are “stored”\n\n\n\n\nThe current local session / workspace is the global environment where objects we create are stored by default\nBut we also talked about “scoping” which dictates how we access the R essentials we make\n\n\nRStudio’s Environment Pane",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---scoping-and-local-environments",
    "href": "Lectures/03_Programming/index.html#functions---scoping-and-local-environments",
    "title": "Programming Basics",
    "section": "Functions - Scoping and Local Environments",
    "text": "Functions - Scoping and Local Environments\n\nOur workspace is the global environment so when we make an assignment this is where things usually get accessed\n\n\nx &lt;- 1:5\n\n\nBut dataframes and lists also create their own internal environments\n\n\ndf &lt;- tibble(x = c('a','b','c','d','e'))\n\n\nImportantly, we now have two x’s\n\n\n\nThe vector of numbers in our global environment\nThe variable/column of letters which exists inside the df tibble",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#functions---scoping-and-local-environments-1",
    "href": "Lectures/03_Programming/index.html#functions---scoping-and-local-environments-1",
    "title": "Programming Basics",
    "section": "Functions - Scoping and Local Environments",
    "text": "Functions - Scoping and Local Environments\n\nGetting to the vector x is easy, it exists in the global environment\n\n\n\nx\n\n[1] 1 2 3 4 5\n\n\n\n\n\n\n\nBut what about the variable inside of df?\nIt exists within df but the tibble is what’s inside the global environment\n\n\n\ndf\n\n# A tibble: 5 × 1\n  x    \n  &lt;chr&gt;\n1 a    \n2 b    \n3 c    \n4 d    \n5 e    \n\n\nSo how do we access the x in df?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#accessing-data---tibbles-and-data-frames",
    "href": "Lectures/03_Programming/index.html#accessing-data---tibbles-and-data-frames",
    "title": "Programming Basics",
    "section": "Accessing Data - Tibbles and Data Frames",
    "text": "Accessing Data - Tibbles and Data Frames\nLet’s build on df and call it dummy_data\n\ndummy_data &lt;- tibble(char_var = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                     num_var = c(1, 2, 3, 4, 5))\ndummy_data\n\n# A tibble: 5 × 2\n  char_var num_var\n  &lt;chr&gt;      &lt;dbl&gt;\n1 A              1\n2 B              2\n3 C              3\n4 D              4\n5 E              5\n\n\n\nSo dummy_data exists in the global environment while char_var and num_var exist in dummy_data’s local environment",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#accessing-data---accessing-by-position",
    "href": "Lectures/03_Programming/index.html#accessing-data---accessing-by-position",
    "title": "Programming Basics",
    "section": "Accessing Data - Accessing by Position",
    "text": "Accessing Data - Accessing by Position\n\nAs mentioned previously, all data frames and tibbles are rectangular using rows and columns with well defined positions\nIn R, we can access data with elements in well defined positions by using bracket notation []; this is indexing\nIn the case of rectangular data sets, a value by the ith row and jth column position using square brackets dummy_data[i,j]\n\n\n#Getting the value at the 2nd row and 1st column\ndummy_data[2,1]\n\n#&gt; \"A\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#accessing-data---accessing-by-position-1",
    "href": "Lectures/03_Programming/index.html#accessing-data---accessing-by-position-1",
    "title": "Programming Basics",
    "section": "Accessing Data - Accessing by Position",
    "text": "Accessing Data - Accessing by Position\n\nWe can also extract entire ith row (whole observations) or a set of rows by leaving the column index blank\n\n\n\n#Getting the entire third observation\ndummy_data[3,]\n#&gt; # A tibble: 1 × 2\n#&gt;   Char_var Num_var\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 C              3\n\n#Getting the 3rd and 5th observations \ndummy_data[c(3,5),]\n#&gt; # A tibble: 2 × 2\n#&gt;   Num_var Char_var\n#&gt; &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 C              3\n#&gt; 2 E              5\n\n\n\n\nColumns (whole sets of variable values) can be accessed similarly but…",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#accessing-data---accessing-variables",
    "href": "Lectures/03_Programming/index.html#accessing-data---accessing-variables",
    "title": "Programming Basics",
    "section": "Accessing Data - Accessing Variables",
    "text": "Accessing Data - Accessing Variables\n\nData frames can also have an individual column accessed by the column/variable name\nYou’ll frequently see this using the $ operator\n\n\n#Pulling num_var using a $\ndummy_data$num_var\n\n#&gt; [1] 1 2 3 4 5\n\n\n\nDouble brackets [[]] can also pass the column name as a character\n\n\n#Getting char_var as a string\ndummy_data[[\"char_var\"]]\n\n#&gt; [1] \"A\" \"B\" \"C\" \"D\" \"E\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#use-caution-when-accessing-data-frame-variables",
    "href": "Lectures/03_Programming/index.html#use-caution-when-accessing-data-frame-variables",
    "title": "Programming Basics",
    "section": "Use Caution When Accessing Data Frame Variables",
    "text": "Use Caution When Accessing Data Frame Variables\n\n\n\n\n\n\nImportant\n\n\nWhen using $ or [[]] to access a data frame or tibble variable, you get back a vector NOT a data frame\n\n\n\n\nis.data.frame(dummy_data$num_var)\n#&gt; FALSE\n\nis.vector(dummy_data$num_var)\n#&gt; TRUE  \n\nclass(dummy_data$num_var)\n#&gt; [1] \"numeric\"\n\n\n\nThe object class matter a lot as we’ll be discussing soon with vectors",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#accessing-data---scoping-in-the-tidyverse",
    "href": "Lectures/03_Programming/index.html#accessing-data---scoping-in-the-tidyverse",
    "title": "Programming Basics",
    "section": "Accessing Data - Scoping in the tidyverse",
    "text": "Accessing Data - Scoping in the tidyverse\n\nThe tidyverse has its own ways of accessing column variables called tidy evaluation\nFunctions in the tidyverse try to behave consistently and intuitively by letting you work with variable names directly and returning outputs similar to your inputs (e.g. get a tibble when you operate on a tibble)\nWe’ll see this in action next time when we start to work with functions in the dplyr package, for example\n\n\ndplyr::select(dummy_data, num_var)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---the-basics",
    "href": "Lectures/03_Programming/index.html#vectors---the-basics",
    "title": "Programming Basics",
    "section": "Vectors - The Basics",
    "text": "Vectors - The Basics\n\nAlthough we mainly deal in data frames, the vector is the garden variety R object\nWe make vectors using the c() command which means combine,  concatonate, or coerce\nAny given vector will always be the same “type” of data, or class\ne.g. we saw num_var in dummy_data was the “numeric” class\n\n\nclass(dummy_data$num_var)\n\n[1] \"numeric\"\n\n\n\nData frames are just a set of equal length vectors as columns, each with their own class",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---back-to-class",
    "href": "Lectures/03_Programming/index.html#vectors---back-to-class",
    "title": "Programming Basics",
    "section": "Vectors - Back to Class",
    "text": "Vectors - Back to Class\n\nSome of the most common data classes include:\n\n\n\nClass\nExamples\n\n\n\n\nlogical\nTRUE, FALSE\n\n\ninteger\n1, 357, -25, 0, etc\n\n\nnumeric\n6, 1.24, 5.00001, pi, etc\n\n\ncharacter\n“a”, “words with spaces”, “1”, etc\n\n\ndate\n2024-06-15",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---back-to-class-1",
    "href": "Lectures/03_Programming/index.html#vectors---back-to-class-1",
    "title": "Programming Basics",
    "section": "Vectors - Back to Class",
    "text": "Vectors - Back to Class\n\nWe can create either atomic vectors in the global environment or as part of a data frame using c()\n\n\n# Atomic vector examples -- # full name - abbreviation\nlgl_var &lt;- c(TRUE, FALSE)   # logical   = lgl\nint_var &lt;- c(1L, 6L, 10L)   # integer   = int\ndbl_var &lt;- c(1, 2.5, 4.5)   # double    = dbl\nchr_var &lt;- c(\"a\", \"b\", \"c\") # character = chr\n\n#We also use c() when adding a vector to a dataframe\ndf &lt;- data.frame(xx = c(1,2,3),\n                 yy = c(\"a\",\"b\",\"c\"))",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---logicals",
    "href": "Lectures/03_Programming/index.html#vectors---logicals",
    "title": "Programming Basics",
    "section": "Vectors - Logicals",
    "text": "Vectors - Logicals\n\nLogical values must be either TRUE or FALSE although they have convenient properties\nTRUE is equivalent to 1 and FALSE is 0\n\n\n\nTRUE + TRUE\n\n[1] 2\n\n\n\n\nBut R can evaluate logicals with some convenient operators\n\n\n\n& - AND\n| - OR\n! - NOT\n\n\n\nWe’ll see these come up a lot along with the equality operator ==",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---logical-sets",
    "href": "Lectures/03_Programming/index.html#vectors---logical-sets",
    "title": "Programming Basics",
    "section": "Vectors - Logical Sets",
    "text": "Vectors - Logical Sets",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---logical-and",
    "href": "Lectures/03_Programming/index.html#vectors---logical-and",
    "title": "Programming Basics",
    "section": "Vectors - Logical AND",
    "text": "Vectors - Logical AND\n\nx &lt;- TRUE; y &lt;- FALSE\n\n# Both are true\nx & y\n\n[1] FALSE",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---logical-or",
    "href": "Lectures/03_Programming/index.html#vectors---logical-or",
    "title": "Programming Basics",
    "section": "Vectors - Logical OR",
    "text": "Vectors - Logical OR\n\nx &lt;- TRUE; y &lt;- FALSE\n\n# Either is true\nx | y\n\n[1] TRUE",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---logical-xor",
    "href": "Lectures/03_Programming/index.html#vectors---logical-xor",
    "title": "Programming Basics",
    "section": "Vectors - Logical XOR",
    "text": "Vectors - Logical XOR\n\nx &lt;- TRUE; y &lt;- FALSE\n\n# Exactly one is true\nxor(x, y)\n\n[1] TRUE\n\n\n\nYou’ll get lots of practice using these BOO-lean operators",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---integer-and-double-vectors",
    "href": "Lectures/03_Programming/index.html#vectors---integer-and-double-vectors",
    "title": "Programming Basics",
    "section": "Vectors - Integer and Double Vectors",
    "text": "Vectors - Integer and Double Vectors\n\nThese two types are collectively called numeric vectors; double means “double precision” and is important for programming\nWhen you attempt to combine different data types into a single vector R will attempt to coerce a vector to its most generalizable class\n\n\n#Make a vector with logicals, integers (2L), and doubles\nvec &lt;- c(TRUE, FALSE, 2L, pi)\n\n#This gives a numeric vector\nclass(vec)\n\n[1] \"numeric\"\n\n\n\nAll logicals are integers and all integers are numerics but not vice versa",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---characters-and-strings",
    "href": "Lectures/03_Programming/index.html#vectors---characters-and-strings",
    "title": "Programming Basics",
    "section": "Vectors - Characters and Strings",
    "text": "Vectors - Characters and Strings\n\nCharacter values in R represent strings and are the most general class\nAll characters are surrounded by quotes, either double \" (\"hi\") or single ' ('bye')\nBest practice recommends using \" to create strings and then using ' if you have a quote inside of the string\n\n\nstring1 &lt;- \"a string\"\nstring1\n\n[1] \"a string\"\n\n\n\nstring2 &lt;- \"a 'string' value\"\nstring2\n\n[1] \"a 'string' value\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---dates",
    "href": "Lectures/03_Programming/index.html#vectors---dates",
    "title": "Programming Basics",
    "section": "Vectors - Dates",
    "text": "Vectors - Dates\n\nWe’ll discuss these in depth later with the lubridate package\nCalendar and time math is tricky, for now it’s enough to know these special classes exist\n\n\n#Get today's date\ntoday &lt;- Sys.Date()\ntoday\n\n[1] \"2024-07-12\"\n\n\n\n#Get today's class\nclass(today)\n\n[1] \"Date\"\n\n\n\n#Today's date as a \"POSIX\"\nas.POSIXct(today)\n\n[1] \"2024-07-12 UTC\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---indexing",
    "href": "Lectures/03_Programming/index.html#vectors---indexing",
    "title": "Programming Basics",
    "section": "Vectors - Indexing",
    "text": "Vectors - Indexing\n\nJust like data frames, vectors can be indexed using square brackets []\n\n\n#Make a vector\nx &lt;- c(0, 5, 10)\n\n#Then get the first value\nx[1]\n\n[1] 0\n\n\n\nTo get more than one value, index a vector by another vector\n\n\n#Get the 2nd and 3rd values\nx[c(2,3)]\n\n[1]  5 10",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---indexing-1",
    "href": "Lectures/03_Programming/index.html#vectors---indexing-1",
    "title": "Programming Basics",
    "section": "Vectors - Indexing",
    "text": "Vectors - Indexing\n\nYou can even index by an object that’s had a vector assigned to it\n\n\n#Make a new vector y\ny &lt;- c(2,3)\n\n#Use y to get the 2nd and 3rd values\nx[y]\n\n[1]  5 10\n\n\n\nThis is exceptionally powerful in programming",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---indexing-with-logicals",
    "href": "Lectures/03_Programming/index.html#vectors---indexing-with-logicals",
    "title": "Programming Basics",
    "section": "Vectors - Indexing with Logicals",
    "text": "Vectors - Indexing with Logicals\n\nLogical values can also be used to subset vectors\n\n\n#This is the same as x[1]\nx[c(TRUE, FALSE, FALSE)]\n\n[1] 0\n\n#This is equivalent to x[c(2,3)]\nx[c(FALSE, TRUE, TRUE)]\n\n[1]  5 10\n\n\n\n\n\n\n\n\nImportant\n\n\nThese boolean vectors need to be the same length as the vector you’re subsetting",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---indexing-with-logicals-1",
    "href": "Lectures/03_Programming/index.html#vectors---indexing-with-logicals-1",
    "title": "Programming Basics",
    "section": "Vectors - Indexing with Logicals",
    "text": "Vectors - Indexing with Logicals\nSince logicals can subset vectors we can do some clever subsetting\n\n#First, see which values are less than 6\nx &lt; 6\n\n[1]  TRUE  TRUE FALSE\n\n#Since this is a logical vector, we can use it to index x\n#i.e. return all values of x &lt; 6\nx[x &lt; 6] \n\n[1] 0 5\n\n#As always, we can also assign the boolean vector to an object\ny &lt;- (x &gt;= 5)\n#Now y will return all values of x &gt;= 5\nx[y]\n\n[1]  5 10\n\n\n\nWe’ll see this in action when we isolate data frames next time as well",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#vectors---summarizing-functions",
    "href": "Lectures/03_Programming/index.html#vectors---summarizing-functions",
    "title": "Programming Basics",
    "section": "Vectors - Summarizing Functions",
    "text": "Vectors - Summarizing Functions\n\nmean(), median(), min(), max(), sum(), and table() are all useful summary functions for vectors\nmean and sum in particular can be useful for computing proportions and counts of TRUE conditions, for example:\n\n\n#The number of x values greater than 0\nsum(x &gt; 0)\n\n[1] 2\n\n#The proportion of x values greater than 0\nmean(x &gt; 0)\n\n[1] 0.6666667",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/03_Programming/index.html#next-time",
    "href": "Lectures/03_Programming/index.html#next-time",
    "title": "Programming Basics",
    "section": "Next Time",
    "text": "Next Time\n\nHow to use these programming fundamentals to manipulate data frames\nWorking with the dplyr package for isolation to filter rows and select columns\nMaking new variables with mutate() and building a workflow with pipes |&gt;\nBe familiar with chapter 4 in R4DS",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html",
    "href": "Lectures/05_Transform/index.html",
    "title": "Transforming data with dplyr",
    "section": "",
    "text": "Brief Review\nTransformations with dplyr\nFactors in R\nGroups and Summarization",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#agenda",
    "href": "Lectures/05_Transform/index.html#agenda",
    "title": "Transforming data with dplyr",
    "section": "Agenda",
    "text": "Agenda\n\n\n\nBrief Review\nTransformations with dplyr\nFactors in R\nGroups and Summarization",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#brief-review---workflows-with-the-pipe",
    "href": "Lectures/05_Transform/index.html#brief-review---workflows-with-the-pipe",
    "title": "Transforming data with dplyr",
    "section": "Brief Review - Workflows with the Pipe",
    "text": "Brief Review - Workflows with the Pipe\n\nConsider the following sequence of actions\n\nFind key\nUnlock car\nStart car\nDrive to school\nPark",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#brief-review---workflows-with-the-pipe-1",
    "href": "Lectures/05_Transform/index.html#brief-review---workflows-with-the-pipe-1",
    "title": "Transforming data with dplyr",
    "section": "Brief Review - Workflows with the Pipe",
    "text": "Brief Review - Workflows with the Pipe\n\nExpressed as a set of nested functions in R:\n\n\npark(drive(start_car(find(\"keys\")), to = \"campus\"))\n\n\nWriting it out using pipes gives a human intuitive structure:\n\n\nfind(\"keys\") |&gt;\n  start_car() |&gt;\n  drive(to = \"campus\") |&gt;\n  park()\n\n\n\n\n\n\n\nTip\n\n\nWrite data for computers but write code for humans",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#brief-review---piping-to-other-arguments",
    "href": "Lectures/05_Transform/index.html#brief-review---piping-to-other-arguments",
    "title": "Transforming data with dplyr",
    "section": "Brief Review - Piping to Other Arguments",
    "text": "Brief Review - Piping to Other Arguments\n\nTo send results to a function argument other than first one or to use the previous result for multiple arguments use _\n\n\nnhanes |&gt;\n  filter(sex == \"Female\") |&gt;\n  lm(bp_sys_mmhg ~ age, data = _) #&lt;&lt;\n\n\nCall:\nlm(formula = bp_sys_mmhg ~ age, data = filter(nhanes, sex == \n    \"Female\"))\n\nCoefficients:\n(Intercept)          age  \n    92.7765       0.6337",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#brief-review---piping-to-other-arguments-1",
    "href": "Lectures/05_Transform/index.html#brief-review---piping-to-other-arguments-1",
    "title": "Transforming data with dplyr",
    "section": "Brief Review - Piping to Other Arguments",
    "text": "Brief Review - Piping to Other Arguments\n\nIf using %&gt;% from magrittr, you use .\n\n\nnhanes %&gt;%\n  filter(sex == \"Female\") %&gt;%\n  lm(bp_sys_mmhg ~ age, data = .) #&lt;&lt;\n\n\nCall:\nlm(formula = bp_sys_mmhg ~ age, data = .)\n\nCoefficients:\n(Intercept)          age  \n    92.7765       0.6337  \n\n\n\n. can be passed to multiple arguments in the same function unlike |&gt;\nFor more details on magrittr’s pipes check this 2021 blog and this post by Hadley comparing |&gt; and %&gt;%",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#brief-review---last-time-on-dplyr",
    "href": "Lectures/05_Transform/index.html#brief-review---last-time-on-dplyr",
    "title": "Transforming data with dplyr",
    "section": "Brief Review - Last Time on dplyr",
    "text": "Brief Review - Last Time on dplyr",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#brief-review---last-time-on-dplyr-1",
    "href": "Lectures/05_Transform/index.html#brief-review---last-time-on-dplyr-1",
    "title": "Transforming data with dplyr",
    "section": "Brief Review - Last Time on dplyr",
    "text": "Brief Review - Last Time on dplyr\n\nFirst was isolation to focus on data of interest\n\nfilter() keeps rows that match specified conditions by resolving the variable to a logical vector\nselect() extracts columns from a data set like $ but more consistent and verstatile (i.e. better)\narrange() will sort a data frame row-wise by a specified column / variable; can wrap the variable in desc() for descending order\nslice() and its relatives index rows by location; like [] but better\n\nOther dplyr utility includes transformation and summarization",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---nhanes-data",
    "href": "Lectures/05_Transform/index.html#transformation---nhanes-data",
    "title": "Transforming data with dplyr",
    "section": "Transformation - NHANES Data",
    "text": "Transformation - NHANES Data\nWith NHANES, today we have the full set of 51761 observations\n\nglimpse(nhanes, width = 60)\n\nRows: 51,761\nColumns: 14\n$ seqn            &lt;dbl&gt; 2, 5, 6, 7, 10, 12, 13, 14, 15, 16…\n$ exam            &lt;fct&gt; 1999, 1999, 1999, 1999, 1999, 1999…\n$ age             &lt;dbl&gt; 77, 49, 19, 59, 43, 37, 70, 81, 38…\n$ sex             &lt;fct&gt; Male, Male, Female, Female, Male, …\n$ race_ethnicity  &lt;fct&gt; Non-Hispanic White, Non-Hispanic W…\n$ education       &lt;fct&gt; College graduate, College graduate…\n$ bp_sys_mmhg     &lt;dbl&gt; 100.6667, 122.0000, 114.6667, 125.…\n$ bp_dia_mmhg     &lt;dbl&gt; 56.66667, 82.66667, 68.00000, 80.0…\n$ bp_controlled   &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ bp_high_aware   &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0…\n$ bp_meds         &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Ye…\n$ acr_mgg         &lt;dbl&gt; 6.275862, 3.546512, 4.032258, 5.23…\n$ chol_hdl_mgdl   &lt;dbl&gt; 54, 42, 61, 105, 51, 38, 49, 40, 5…\n$ chol_total_mgdl &lt;dbl&gt; 215, 279, 153, 245, 140, 156, 314,…",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---dplyrs-rules",
    "href": "Lectures/05_Transform/index.html#transformation---dplyrs-rules",
    "title": "Transforming data with dplyr",
    "section": "Transformation - dplyr’s rules",
    "text": "Transformation - dplyr’s rules\n\ndplyr has the usual tidyverse conventions\n\nFirst argument is always a data frame\nSubsequent arguments say what to do with that data frame\nAlways return a data frame\n\n\n\n\nIt also follows standard R conventions (unlike some other packages)\n\nDoesntn’t modify in place i.e. makes copies when assigning\nConducts lazy evaluation i.e. objects are only evaluated when called",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---more-of-dplyrs-functions",
    "href": "Lectures/05_Transform/index.html#transformation---more-of-dplyrs-functions",
    "title": "Transforming data with dplyr",
    "section": "Transformation - More of dplyr’s Functions",
    "text": "Transformation - More of dplyr’s Functions\n\nA non-comprehensive list of dplyr’s single-table functions\n\nselect, rename: select / rename specific columns by name\npull: extract a data frame column as a vector\nfilter: pick rows matching criteria\nslice: pick rows using location indexing\narrange: reorder rows by variables\nmutate: add new variables based on existing variables\nsummarise: reduce variables to aggregate measures\ncount: special case of summarise that computes frequencies.\nMany more!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---using-mutate",
    "href": "Lectures/05_Transform/index.html#transformation---using-mutate",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Using mutate()",
    "text": "Transformation - Using mutate()\n\nmutate() defines and inserts a new variable into a data frameor tibble\nThe new variable is derived from columns that already exist in the data frame via data masking\nOther arguments control includes where the new variable is inserted\nAn important optional argument is .by which we’ll discuss soon",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---mutate-for-numerics",
    "href": "Lectures/05_Transform/index.html#transformation---mutate-for-numerics",
    "title": "Transforming data with dplyr",
    "section": "Transformation - mutate() for Numerics",
    "text": "Transformation - mutate() for Numerics\n\nmutate() is useful for algebraic manipulation\nFor example, let’s make LDL cholesterol from total andHDL cholesterol\n\n\nnhanes &lt;- \n  nhanes |&gt;\n    mutate(chol_ldl_mgdl = chol_total_mgdl - chol_hdl_mgdl,\n           .before = chol_total_mgdl\n    )\n\n\nNote the use of data masking",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---always-check-your-work",
    "href": "Lectures/05_Transform/index.html#transformation---always-check-your-work",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Always Check Your Work",
    "text": "Transformation - Always Check Your Work\n\nglimpse(nhanes, width = 60)\n\nRows: 51,761\nColumns: 15\n$ seqn            &lt;dbl&gt; 2, 5, 6, 7, 10, 12, 13, 14, 15, 16…\n$ exam            &lt;fct&gt; 1999, 1999, 1999, 1999, 1999, 1999…\n$ age             &lt;dbl&gt; 77, 49, 19, 59, 43, 37, 70, 81, 38…\n$ sex             &lt;fct&gt; Male, Male, Female, Female, Male, …\n$ race_ethnicity  &lt;fct&gt; Non-Hispanic White, Non-Hispanic W…\n$ education       &lt;fct&gt; College graduate, College graduate…\n$ bp_sys_mmhg     &lt;dbl&gt; 100.6667, 122.0000, 114.6667, 125.…\n$ bp_dia_mmhg     &lt;dbl&gt; 56.66667, 82.66667, 68.00000, 80.0…\n$ bp_controlled   &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ bp_high_aware   &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0…\n$ bp_meds         &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Ye…\n$ acr_mgg         &lt;dbl&gt; 6.275862, 3.546512, 4.032258, 5.23…\n$ chol_hdl_mgdl   &lt;dbl&gt; 54, 42, 61, 105, 51, 38, 49, 40, 5…\n$ chol_ldl_mgdl   &lt;dbl&gt; 161, 237, 92, 140, 89, 118, 265, 1…\n$ chol_total_mgdl &lt;dbl&gt; 215, 279, 153, 245, 140, 156, 314,…",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---conditional-variables",
    "href": "Lectures/05_Transform/index.html#transformation---conditional-variables",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Conditional Variables",
    "text": "Transformation - Conditional Variables\n\nBut what about non-numeric outputs e.g. these in NHANES\n\n\nalbuminuria:\n\n‘Yes’ if ACR &gt; 30 mg / g\n‘No’ otherwise.\n\nbp_cat:\n\n‘Normotensive’ if SBP &lt; 130 and DBP &lt; 80 mm Hg\n‘Hypertension’ if SBP is 130 to &lt; 140 or DBP is 80 to &lt; 90 mm Hg\n‘Uncontrolled’ if SBP is &gt; 140 or DBP is &gt; 90 mm Hg",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---mutate-conditionally",
    "href": "Lectures/05_Transform/index.html#transformation---mutate-conditionally",
    "title": "Transforming data with dplyr",
    "section": "Transformation - mutate() Conditionally",
    "text": "Transformation - mutate() Conditionally\n\n\nmutate() can also be used to create conditional variableswhere one state is for condition x and another is for condition y\nInstead of numeric expressions, we can generate vectors of logicals which inform how the new variables are created\ndplyr provides two main functions for making conditional changes driven by logical vectors\n\nif_else() for variables with 2 categories where one condition evaluates to TRUE and the other evaluates to FALSE\ncase_when() for variables with &gt;2 categories which is more flexible but more complex to code",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---mutate-with-if_else",
    "href": "Lectures/05_Transform/index.html#transformation---mutate-with-if_else",
    "title": "Transforming data with dplyr",
    "section": "Transformation - mutate() with if_else()",
    "text": "Transformation - mutate() with if_else()\n\nalbuminuria using if_else():\n\n‘Yes’ if ACR &gt; 30 mg / g\n‘No’ otherwise.\n\n\n\nnhanes &lt;- nhanes |&gt; \n  mutate(\n    albuminuria = if_else(\n      condition = acr_mgg &gt; 30,\n      true = 'Yes', \n      false = 'No'\n    )\n  )\n\n\nif_else() relies on the boolean vector from condition followed by the true and false results",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---always-check-your-work-1",
    "href": "Lectures/05_Transform/index.html#transformation---always-check-your-work-1",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Always Check Your Work",
    "text": "Transformation - Always Check Your Work\n\n\n\nYes, this will slow you down in the short term\nYes, it is very much worth it.\n\n\ntable(nhanes$albuminuria, nhanes$acr_mgg &gt; 30)\n\n     \n      FALSE  TRUE\n  No  44460     0\n  Yes     0  6263",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---using-case_when",
    "href": "Lectures/05_Transform/index.html#transformation---using-case_when",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Using case_when()",
    "text": "Transformation - Using case_when()\n\nbp_cat using case_when():\n\n‘Normotensive’ if SBP &lt; 130 and DBP &lt; 80 mm Hg\n‘Hypertension’ if SBP is 130 to &lt; 140 or DBP is 80 to &lt; 90 mm Hg\n‘Uncontrolled’ if SBP is &gt; 140 or DBP is &gt; 90 mm Hg\n\n\n\nnhanes &lt;- nhanes |&gt; \n  mutate(\n    bp_cat = case_when(\n      bp_sys_mmhg  &lt; 130 & bp_dia_mmhg  &lt; 80 ~ \"Normotensive\",\n      bp_sys_mmhg  &lt; 140 & bp_dia_mmhg  &lt; 90 ~ \"Hypertension\",\n      bp_sys_mmhg &gt;= 140 | bp_dia_mmhg &gt;= 90 ~ \"Uncontrolled\",\n      TRUE ~ NA_character_ # added for clarity\n    )\n  )",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---always-check-your-work-2",
    "href": "Lectures/05_Transform/index.html#transformation---always-check-your-work-2",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Always Check your Work!",
    "text": "Transformation - Always Check your Work!\n\nGet creative depending on what your output is\n\n\nggplot(nhanes) + \n  aes(x = bp_sys_mmhg, y = bp_dia_mmhg, col = bp_cat) + \n  geom_point()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#transformation---question",
    "href": "Lectures/05_Transform/index.html#transformation---question",
    "title": "Transforming data with dplyr",
    "section": "Transformation - Question",
    "text": "Transformation - Question\n\nWhat kind of variables do you think albuminura and bp_cat are?\n\n\n\nnhanes |&gt; select(c(albuminuria, bp_cat))\n\n# A tibble: 51,761 × 2\n   albuminuria bp_cat      \n   &lt;chr&gt;       &lt;chr&gt;       \n 1 No          Normotensive\n 2 No          Hypertension\n 3 No          Normotensive\n 4 No          Hypertension\n 5 No          Uncontrolled\n 6 Yes         Uncontrolled\n 7 Yes         Hypertension\n 8 No          Hypertension\n 9 No          Normotensive\n10 No          Uncontrolled\n# ℹ 51,751 more rows\n\n\n\nThey’re characters but we want them as categorical variables",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---under-the-hood-in-r",
    "href": "Lectures/05_Transform/index.html#factors---under-the-hood-in-r",
    "title": "Transforming data with dplyr",
    "section": "Factors - Under the Hood in R",
    "text": "Factors - Under the Hood in R\n\nFactors are how we store true categorical information\nCategorical variables have a fixed set of finite and pre-definedvalues called levels\n\n\nfctr &lt;- factor(\n  x = c(1, 2, 2, 3),\n  levels = c(1,2,3),\n  labels = c(\"A\", \"B\", \"C\")\n)\n\nfctr\n\n[1] A B B C\nLevels: A B C\n\n\n\nBut under the hood, R is really storing these as integers 1, 2, 3, etc.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---their-behavior-can-beconfusing",
    "href": "Lectures/05_Transform/index.html#factors---their-behavior-can-beconfusing",
    "title": "Transforming data with dplyr",
    "section": "Factors - Their Behavior Can Be…Confusing",
    "text": "Factors - Their Behavior Can Be…Confusing\n\n\n\n#Make a factor\nx1 &lt;- factor(c(\"Dec\", \"Apr\", \"May\", \"Jan\"))\nx1\n\n[1] Dec Apr May Jan\nLevels: Apr Dec Jan May\n\n#Now sort it\nsort(x1)\n\n[1] Apr Dec Jan May\nLevels: Apr Dec Jan May\n\n#Now let's add \"Mar\" to it\nc(x1, \"Mar\")\n\n[1] \"2\"   \"1\"   \"4\"   \"3\"   \"Mar\"\n\n#Instead lets replace May with Mar\nx1[3] &lt;- \"Mar\"\nx1\n\n[1] Dec  Apr  &lt;NA&gt; Jan \nLevels: Apr Dec Jan May",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor",
    "href": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor",
    "title": "Transforming data with dplyr",
    "section": "Factors - When to Convert to a Factor",
    "text": "Factors - When to Convert to a Factor\n\nConvert character/numeric vectors to factors if:\n\nYou want to impose an ordering that is not alphabetical\n\n\n\ncount(nhanes, bp_cat)\n\n# A tibble: 3 × 2\n  bp_cat           n\n  &lt;chr&gt;        &lt;int&gt;\n1 Hypertension 10325\n2 Normotensive 31075\n3 Uncontrolled 10361",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor-1",
    "href": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor-1",
    "title": "Transforming data with dplyr",
    "section": "Factors - When to Convert to a Factor",
    "text": "Factors - When to Convert to a Factor\n\nConvert character/numeric vectors to factors if:\n\nYou want to impose an ordering that is not alphabetical\n\n\n\nnhanes &lt;- nhanes |&gt; \n  mutate(\n    bp_cat = factor(\n      x = bp_cat, \n      levels = c('Normotensive', 'Hypertension', 'Uncontrolled')\n    )\n  )\n\ncount(nhanes, bp_cat)\n\n# A tibble: 3 × 2\n  bp_cat           n\n  &lt;fct&gt;        &lt;int&gt;\n1 Normotensive 31075\n2 Hypertension 10325\n3 Uncontrolled 10361",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor-2",
    "href": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor-2",
    "title": "Transforming data with dplyr",
    "section": "Factors - When to Convert to a Factor",
    "text": "Factors - When to Convert to a Factor\n\nConvert character/numeric vectors to factors if:\n\nYou have a numeric variable that should be categorical or groups\n\n\n\ncount(nhanes, bp_high_aware)\n\n# A tibble: 2 × 2\n  bp_high_aware     n\n          &lt;dbl&gt; &lt;int&gt;\n1             0 34514\n2             1 17247",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor-3",
    "href": "Lectures/05_Transform/index.html#factors---when-to-convert-to-a-factor-3",
    "title": "Transforming data with dplyr",
    "section": "Factors - When to Convert to a Factor",
    "text": "Factors - When to Convert to a Factor\n\nConvert character/numeric vectors to factors if:\n\nYou have a numeric variable that should be categorical or groups\n\n\n\nnhanes &lt;- nhanes |&gt; \n  mutate(\n    bp_high_aware = factor(\n      x = bp_high_aware, \n      levels = c(0, 1),\n      labels = c(\"No\", \"Yes\")\n    )\n  )\n\ncount(nhanes, bp_high_aware)\n\n# A tibble: 2 × 2\n  bp_high_aware     n\n  &lt;fct&gt;         &lt;int&gt;\n1 No            34514\n2 Yes           17247",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---additional-utility-with-forcats",
    "href": "Lectures/05_Transform/index.html#factors---additional-utility-with-forcats",
    "title": "Transforming data with dplyr",
    "section": "Factors - Additional Utility with forcats",
    "text": "Factors - Additional Utility with forcats\n\nBase R has very few functions to meaningfully engage withfactors, instead we’ll use the forcats package\nNearly every function begins with fct_\nMuch of the confusing factor behavior with factors we discussed can be avoided by using forcats",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---relevel-factors",
    "href": "Lectures/05_Transform/index.html#factors---relevel-factors",
    "title": "Transforming data with dplyr",
    "section": "Factors - Relevel Factors",
    "text": "Factors - Relevel Factors\n\nRelevel factors (change their order) with fct_relevel\n\n\nlibrary(forcats)\n\nnhanes |&gt; \n  mutate(\n    bp_cat = fct_relevel(\n      bp_cat, 'Uncontrolled', 'Hypertension'\n    )\n  ) |&gt; \n  count(bp_cat)\n\n# A tibble: 3 × 2\n  bp_cat           n\n  &lt;fct&gt;        &lt;int&gt;\n1 Uncontrolled 10361\n2 Hypertension 10325\n3 Normotensive 31075\n\n\n\nfct_reorder() uses numeric/variable reordering e.g. by frequency",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---coding-na-to-its-own-level",
    "href": "Lectures/05_Transform/index.html#factors---coding-na-to-its-own-level",
    "title": "Transforming data with dplyr",
    "section": "Factors - Coding NA to its Own Level",
    "text": "Factors - Coding NA to its Own Level\n\nfct_na_value_to_level() sets factors with missing values (i.e. NA) levels to their own category\n\n\ncount(nhanes, education)\n\n# A tibble: 4 × 2\n  education                    n\n  &lt;fct&gt;                    &lt;int&gt;\n1 Less than high school    14389\n2 High school/some college 26076\n3 College graduate         10344\n4 &lt;NA&gt;                       952",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---coding-na-to-its-own-level-1",
    "href": "Lectures/05_Transform/index.html#factors---coding-na-to-its-own-level-1",
    "title": "Transforming data with dplyr",
    "section": "Factors - Coding NA to its Own Level",
    "text": "Factors - Coding NA to its Own Level\n\n\nnhanes &lt;- nhanes |&gt; \n  mutate(\n    education = fct_na_value_to_level(\n      f = education,\n      level = 'Missing' \n    )\n  )\n\ncount(nhanes, education)\n\n# A tibble: 4 × 2\n  education                    n\n  &lt;fct&gt;                    &lt;int&gt;\n1 Less than high school    14389\n2 High school/some college 26076\n3 College graduate         10344\n4 Missing                    952\n\n\n\n\nCan do the reverse and convert levels to NA with fct_na_level_value()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---add-additional-levels",
    "href": "Lectures/05_Transform/index.html#factors---add-additional-levels",
    "title": "Transforming data with dplyr",
    "section": "Factors - Add Additional Levels",
    "text": "Factors - Add Additional Levels\n\nAdd levels to a factor with fct_expand()\n\n\nnhanes &lt;- nhanes |&gt;\n  mutate(\n    education = fct_expand(\n      f = education,\n      \"Graduate Degree\"\n    )\n  )\n\ncount(nhanes, education, .drop = FALSE)\n\n# A tibble: 5 × 2\n  education                    n\n  &lt;fct&gt;                    &lt;int&gt;\n1 Less than high school    14389\n2 High school/some college 26076\n3 College graduate         10344\n4 Missing                    952\n5 Graduate Degree              0",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---dropping-unused-levels",
    "href": "Lectures/05_Transform/index.html#factors---dropping-unused-levels",
    "title": "Transforming data with dplyr",
    "section": "Factors - Dropping Unused Levels",
    "text": "Factors - Dropping Unused Levels\n\nDrop unused levels with fct_drop()\n\n\nnhanes &lt;- nhanes |&gt;\n  mutate(\n    education = fct_drop(\n      f = education\n    )\n  )\n\ncount(nhanes, education, .drop = FALSE)\n\n# A tibble: 4 × 2\n  education                    n\n  &lt;fct&gt;                    &lt;int&gt;\n1 Less than high school    14389\n2 High school/some college 26076\n3 College graduate         10344\n4 Missing                    952",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---collaps-levels-together",
    "href": "Lectures/05_Transform/index.html#factors---collaps-levels-together",
    "title": "Transforming data with dplyr",
    "section": "Factors - Collaps Levels Together",
    "text": "Factors - Collaps Levels Together\n\nCollapse factors (lump categories) with fct_collapse()\n\n\nnhanes |&gt; \n  mutate(\n    bp_cat = fct_collapse(\n      bp_cat, \n      \"Hypertensive\" = c(\"Hypertension\", \"Uncontrolled\")\n    )\n  ) |&gt; \n  count(bp_cat)\n\n# A tibble: 2 × 2\n  bp_cat           n\n  &lt;fct&gt;        &lt;int&gt;\n1 Normotensive 31075\n2 Hypertensive 20686\n\n\n\nfct_recode() is a more explicit but more powerful recoding tool",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#factors---collaps-levels-together-1",
    "href": "Lectures/05_Transform/index.html#factors---collaps-levels-together-1",
    "title": "Transforming data with dplyr",
    "section": "Factors - Collaps Levels Together",
    "text": "Factors - Collaps Levels Together\n\nExplicitly recode levels manually with fct_recode()\n\n\nnhanes |&gt; \n  mutate(\n    education = fct_recode(\n      education,\n      # new level = old level\n      'less_than_hs' = 'Less than high school',\n      'hs_some_college' = 'High school/some college',\n      'college_grad' = 'College graduate'        \n    )\n  ) |&gt; \n  count(education)\n\n# A tibble: 4 × 2\n  education           n\n  &lt;fct&gt;           &lt;int&gt;\n1 less_than_hs    14389\n2 hs_some_college 26076\n3 college_grad    10344\n4 Missing           952",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#summarization---aggregation-with-dplyr",
    "href": "Lectures/05_Transform/index.html#summarization---aggregation-with-dplyr",
    "title": "Transforming data with dplyr",
    "section": "Summarization - Aggregation with dplyr",
    "text": "Summarization - Aggregation with dplyr\n\nIn dplyr you can use summarise() to summarize your data\nAs expected, using summarise() on a data frame returns a data frame\n\n\nnhanes |&gt;\n  summarise(\n    mean_sbp = mean(bp_sys_mmhg),\n    mean_dbp = mean(bp_dia_mmhg),\n    prevalence_alb = mean(albuminuria == 'Yes', na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  mean_sbp mean_dbp prevalence_alb\n     &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n1     124.     70.5          0.123\n\n\n\nOther aggregations like sum(), count(), n(), etc work as well",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#summarization---using-.by",
    "href": "Lectures/05_Transform/index.html#summarization---using-.by",
    "title": "Transforming data with dplyr",
    "section": "Summarization - Using .by",
    "text": "Summarization - Using .by\n\nA very powerful argument is .by which lets you select columns to group by for the summarise operations\n\n\nnhanes |&gt;\n  summarise(\n    mean_sbp = mean(bp_sys_mmhg),\n    prevalence_alb = mean(albuminuria == 'Yes', na.rm = TRUE),\n    .by = sex)\n\n# A tibble: 2 × 3\n  sex    mean_sbp prevalence_alb\n  &lt;fct&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n1 Male       126.          0.121\n2 Female     123.          0.126",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#grouping---using-group_by",
    "href": "Lectures/05_Transform/index.html#grouping---using-group_by",
    "title": "Transforming data with dplyr",
    "section": "Grouping - Using group_by()",
    "text": "Grouping - Using group_by()\n\nThe group_by() function gives the same functionality\n\n\nnhanes |&gt;\n  group_by(sex) |&gt; \n  summarise(mean_sbp = mean(bp_sys_mmhg),\n    prevalence_alb = mean(albuminuria == 'Yes', na.rm = TRUE))\n\n# A tibble: 2 × 3\n  sex    mean_sbp prevalence_alb\n  &lt;fct&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n1 Female     123.          0.126\n2 Male       126.          0.121\n\n\n\nBoth mutate() and summarise() honor groups; mutate() on groups is useful when applying values such as the first() observation or summary measures",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#grouping---using-group_by-1",
    "href": "Lectures/05_Transform/index.html#grouping---using-group_by-1",
    "title": "Transforming data with dplyr",
    "section": "Grouping - Using group_by()",
    "text": "Grouping - Using group_by()\n\ngroup_by() can accept multiple variables for functions applied to categorical combinations\n\n\nnhanes |&gt;\n  group_by(sex, education) |&gt; \n  summarise(mean_sbp = mean(bp_sys_mmhg),\n    prevalence_alb = mean(albuminuria == 'Yes', na.rm = TRUE))\n\n# A tibble: 8 × 4\n# Groups:   sex [2]\n  sex    education                mean_sbp prevalence_alb\n  &lt;fct&gt;  &lt;fct&gt;                       &lt;dbl&gt;          &lt;dbl&gt;\n1 Female Less than high school        127.         0.172 \n2 Female High school/some college     123.         0.120 \n3 Female College graduate             119.         0.0797\n4 Female Missing                      111.         0.126 \n5 Male   Less than high school        127.         0.156 \n6 Male   High school/some college     126.         0.114 \n7 Male   College graduate             124.         0.0919\n8 Male   Missing                      117.         0.0633",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#grouping---using-ungroup",
    "href": "Lectures/05_Transform/index.html#grouping---using-ungroup",
    "title": "Transforming data with dplyr",
    "section": "Grouping - Using ungroup()",
    "text": "Grouping - Using ungroup()\n\nNote, sex was still applied as a group to the NHANES summary\nA grouped data frame or tibble is structurally the same as an ungrouped, the distinction is how downstream functions are applied\ngroup_by() “unwraps” as functions are applied to the grouped data frame, eventually returning you to your original ungrouped dataframe\nWhen using nested grouping, you may need to use ungroup() to get back to your original data frame or tibble\nAlways check your work!!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "Lectures/05_Transform/index.html#learning-more",
    "href": "Lectures/05_Transform/index.html#learning-more",
    "title": "Transforming data with dplyr",
    "section": "Learning More",
    "text": "Learning More\n\nAs always, cheatsheets available on the tidyverse website(https://rstudio.cloud/learn/cheat-sheets){.external target=“_blank”}\nPackage websites:\n\ndplyr: https://dplyr.tidyverse.org/index.html\nforcats: https://forcats.tidyverse.org/\n\ndplyr has MANY functions we didn’t discuss that can be very useful for isolation, transformation, and summarization",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/01_Intro/exercise_solutions.html",
    "href": "html_files/01_Intro/exercise_solutions.html",
    "title": "Table Exercise",
    "section": "",
    "text": "Get some practice working with gt\nUse what you learned in the intro to markdown file to create the table below:\n\nHints:\n\nNote, we’re using rows 1, 2, 3, 51, 52, 53, 101, 102, and 103 of the iris dataset\nThe iris dataset is already loaded in your R environment, no need to import it\n\n\nlibrary(gt)\n\n#Pull the rows\nirisx &lt;- iris[c(1:3,51:53,101:103),]\n\n#Set the species to sentence case\nirisx$Species &lt;- stringr::str_to_sentence(irisx$Species)\n\n#Initialize gt and define the grouping column\ngt_tbl_1 &lt;- gt(data = irisx, groupname_col = \"Species\")\n\n#Make the group stubhead\ngt_tbl_2 &lt;- tab_stubhead(gt_tbl_1, label=\"Species\")\n\n#Define the title and subtitle with md()\ngt_tbl_3 &lt;- tab_header(\n  data = gt_tbl_2,\n  title = md(\"__Iris dataset__\"),\n  subtitle = \"The first three rows for each species are presented\"\n)\n\n#Add the footer source notation\ngt_tbl_4 &lt;- tab_source_note(\n  data = gt_tbl_3,\n  source_note = md(\"__Fisher, R. A__. (1936) The use of multiple measurements in taxonomic problems _Annals of Eugenics_, 7, Part II, 179–188.\")\n) |&gt;\n  tab_source_note(\n    source_note = md(\"The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, _Bulletin of the American Iris Society_, 59, 2–5.\")\n  ) |&gt;\n  tab_source_note(\n    source_note = md(\"All table values are in __centimeters__.\"))\n\n#Make the species bold\ngt_tbl_5 &lt;- tab_style(\n  data = gt_tbl_4,\n  locations = cells_row_groups(), \n  style = cell_text(weight = 'bold')\n)\n\n#Use a regex to clean up the colnames for proper labels\nlabels_curr &lt;- gsub(\"\\\\.\", \" \", colnames(iris)[1:4])\nnames(labels_curr) &lt;- colnames(iris)[1:4]\n\n#Use labels_curr to add table labels\ngt_tbl_6 &lt;- cols_label(\n  .data = gt_tbl_5,\n  .list = as.list(labels_curr)\n)\n\n#cols_align centers everything\ngt_tbl_7 &lt;- cols_align(\n  data = gt_tbl_6,\n  align = \"center\"\n)\n\n#Set the font to Georgia (common for manuscripts)\ngt_tbl_8 &lt;- opt_table_font(\n  data=gt_tbl_7,\n  font = c(\"Georgia\")\n)\n\n#Quarto makes strips by default so suppress them here\ngt_tbl_9 &lt;- tab_options(\n  data=gt_tbl_8,\n  quarto.disable_processing = TRUE\n)\n\n\ngt_tbl_9\n\n\n\n\n  \n    \n      Iris dataset\n    \n    \n      The first three rows for each species are presented\n    \n    \n      Sepal Length\n      Sepal Width\n      Petal Length\n      Petal Width\n    \n  \n  \n    \n      Setosa\n    \n    5.1\n3.5\n1.4\n0.2\n    4.9\n3.0\n1.4\n0.2\n    4.7\n3.2\n1.3\n0.2\n    \n      Versicolor\n    \n    7.0\n3.2\n4.7\n1.4\n    6.4\n3.2\n4.5\n1.5\n    6.9\n3.1\n4.9\n1.5\n    \n      Virginica\n    \n    6.3\n3.3\n6.0\n2.5\n    5.8\n2.7\n5.1\n1.9\n    7.1\n3.0\n5.9\n2.1\n  \n  \n    \n      Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems Annals of Eugenics, 7, Part II, 179–188.\n    \n    \n      The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5.\n    \n    \n      All table values are in centimeters.\n    \n  \n  \n\n\n\n\n\n\nThere are a couple of things not discussed in the vignette that are applied here, not necessary but if you’re feeling ambitious…\n\nProper case on the species names\nHint - Not a gt function, do this early\nCenter aligning the columns\nHint - Use the col_align() function\nUsing Georgia as the table font\nHint - There are many opt_ functions in gt, maybe there’s one for table fonts?\nRemoving bootstrap striping\n\n\n\n\n\n\n\nCaution\n\n\n\n#4 will take some digging in Quarto, good luck!",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "01 - Working with Tables"
    ]
  },
  {
    "objectID": "html_files/01_Intro/exercise_solutions.html#problem-1",
    "href": "html_files/01_Intro/exercise_solutions.html#problem-1",
    "title": "Table Exercise",
    "section": "",
    "text": "Get some practice working with gt\nUse what you learned in the intro to markdown file to create the table below:\n\nHints:\n\nNote, we’re using rows 1, 2, 3, 51, 52, 53, 101, 102, and 103 of the iris dataset\nThe iris dataset is already loaded in your R environment, no need to import it\n\n\nlibrary(gt)\n\n#Pull the rows\nirisx &lt;- iris[c(1:3,51:53,101:103),]\n\n#Set the species to sentence case\nirisx$Species &lt;- stringr::str_to_sentence(irisx$Species)\n\n#Initialize gt and define the grouping column\ngt_tbl_1 &lt;- gt(data = irisx, groupname_col = \"Species\")\n\n#Make the group stubhead\ngt_tbl_2 &lt;- tab_stubhead(gt_tbl_1, label=\"Species\")\n\n#Define the title and subtitle with md()\ngt_tbl_3 &lt;- tab_header(\n  data = gt_tbl_2,\n  title = md(\"__Iris dataset__\"),\n  subtitle = \"The first three rows for each species are presented\"\n)\n\n#Add the footer source notation\ngt_tbl_4 &lt;- tab_source_note(\n  data = gt_tbl_3,\n  source_note = md(\"__Fisher, R. A__. (1936) The use of multiple measurements in taxonomic problems _Annals of Eugenics_, 7, Part II, 179–188.\")\n) |&gt;\n  tab_source_note(\n    source_note = md(\"The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, _Bulletin of the American Iris Society_, 59, 2–5.\")\n  ) |&gt;\n  tab_source_note(\n    source_note = md(\"All table values are in __centimeters__.\"))\n\n#Make the species bold\ngt_tbl_5 &lt;- tab_style(\n  data = gt_tbl_4,\n  locations = cells_row_groups(), \n  style = cell_text(weight = 'bold')\n)\n\n#Use a regex to clean up the colnames for proper labels\nlabels_curr &lt;- gsub(\"\\\\.\", \" \", colnames(iris)[1:4])\nnames(labels_curr) &lt;- colnames(iris)[1:4]\n\n#Use labels_curr to add table labels\ngt_tbl_6 &lt;- cols_label(\n  .data = gt_tbl_5,\n  .list = as.list(labels_curr)\n)\n\n#cols_align centers everything\ngt_tbl_7 &lt;- cols_align(\n  data = gt_tbl_6,\n  align = \"center\"\n)\n\n#Set the font to Georgia (common for manuscripts)\ngt_tbl_8 &lt;- opt_table_font(\n  data=gt_tbl_7,\n  font = c(\"Georgia\")\n)\n\n#Quarto makes strips by default so suppress them here\ngt_tbl_9 &lt;- tab_options(\n  data=gt_tbl_8,\n  quarto.disable_processing = TRUE\n)\n\n\ngt_tbl_9\n\n\n\n\n  \n    \n      Iris dataset\n    \n    \n      The first three rows for each species are presented\n    \n    \n      Sepal Length\n      Sepal Width\n      Petal Length\n      Petal Width\n    \n  \n  \n    \n      Setosa\n    \n    5.1\n3.5\n1.4\n0.2\n    4.9\n3.0\n1.4\n0.2\n    4.7\n3.2\n1.3\n0.2\n    \n      Versicolor\n    \n    7.0\n3.2\n4.7\n1.4\n    6.4\n3.2\n4.5\n1.5\n    6.9\n3.1\n4.9\n1.5\n    \n      Virginica\n    \n    6.3\n3.3\n6.0\n2.5\n    5.8\n2.7\n5.1\n1.9\n    7.1\n3.0\n5.9\n2.1\n  \n  \n    \n      Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems Annals of Eugenics, 7, Part II, 179–188.\n    \n    \n      The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5.\n    \n    \n      All table values are in centimeters.\n    \n  \n  \n\n\n\n\n\n\nThere are a couple of things not discussed in the vignette that are applied here, not necessary but if you’re feeling ambitious…\n\nProper case on the species names\nHint - Not a gt function, do this early\nCenter aligning the columns\nHint - Use the col_align() function\nUsing Georgia as the table font\nHint - There are many opt_ functions in gt, maybe there’s one for table fonts?\nRemoving bootstrap striping\n\n\n\n\n\n\n\nCaution\n\n\n\n#4 will take some digging in Quarto, good luck!",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "01 - Working with Tables"
    ]
  },
  {
    "objectID": "html_files/02_Visual/exercise_solutions.html",
    "href": "html_files/02_Visual/exercise_solutions.html",
    "title": "Data Visualization Basics",
    "section": "",
    "text": "Overview\nThe gapminder data are related to a famous TED talk given by Hans Rosling. In his talk, Dr. Rosling shows an animated visualization depicting the relationship between life expectancy and average income levels by country. Our goal in this module is to reproduce Dr. Rosling’s visualization.\nWe will access the gapminder data from the gapminder R package. This package contains a dataset (technically, a tibble) called gapminder with 6 variables:\n\n\n\nvariable\nmeaning\n\n\n\n\ncountry\ncountry\n\n\ncontinent\ncontinent\n\n\nyear\nyear\n\n\nlifeExp\nlife expectancy at birth\n\n\npop\ntotal population\n\n\ngdpPercap\nper-capita GDP\n\n\n\nPer-capita GDP (Gross domestic product) is given in units of international dollars, “a hypothetical unit of currency that has the same purchasing power parity that the U.S. dollar had in the United States at a given point in time” – 2005, in this case.\nNote: the gapminder R package exists for the purpose of teaching and making code examples. It is an excerpt of data found in specific spreadsheets on Gapminder.org circa 2010. It is not a definitive source of socioeconomic data.\n\n\nPackages\nLoad the tidyverse and gapminder packages. We are using tidyverse to access the ggplot2 package and using gapminder to access the data.\n\nlibrary(gapminder)\nlibrary(tidyverse)\n\n\n\nInspect your data\nIn gapminder, each country has 12 rows distinguished by year.\n\n# View gapminder data\n  # can also use View(gapminder)\n\n# to set a dataframe:\ngapminder\n\n\n  \n\n\n\n\n\nExercise 1\nCreate a scatter plot using gdpPercap as the x-variable and lifeExp as the y-variable:\nSolution for Exercise 1:\nWe will use the package ggplot2 and the ggplot function. We want to use the gdpPercap as the x-variable and lifeExp as the y-variable. We then want to add the points to the graph using geom_point.\n\nplot1 &lt;- ggplot(\n  data=gapminder,\n  aes(x=gdpPercap, y=lifeExp)) + \n  geom_point()\n\nplot1\n\n\n\n\n\n\n\n\n\n\nExercise 2\nModify your figure from exercise 1: transform the scale of your x-axis to be in log base 10 units. (See ?scale_x_log10)\nSolution for Exercise 2:\nNow we will change the x-sclare to log base 10 and remove the numeric labels from the x-axis. Thus we add scale_x_log10(labels=NULL).\n\nplot2 &lt;- plot1 + \n  scale_x_log10(labels=NULL) \n \nplot2\n\n\n\n\n\n\n\n\n\n\nExercise 3\nAdd x- and y-axis labels to your figure from exercise 2.\nSolution for Exercise 3: We now add the x-axis and y-axis labels using the labs() function.\n\nplot3 &lt;- plot2 +\n  labs(y=\"Life expectancy, years\", \n       x=\"Log income\")\n \nplot3\n\n\n\n\n\n\n\n\n\n\nExercise 4\nAdd a smoothed curve to your plot, showing the overall population trend. (See ?geom_smooth)\nSolution for Exercise 4: Now we add a fitted line to our plot given the provided information, method = ‘gam’ and formula ‘y ~ s(x, bs = “cs”)’geom_smooth() using method = ‘gam’ and formula ‘y ~ s(x, bs = “cs”)’.\n\nplot4 &lt;- plot3 +\n  geom_smooth(method='gam', formula = y ~ s(x, bs = \"cs\")) \n\nplot4\n\n\n\n\n\n\n\n# notes on geom_smooth\n# using gam to fit the non-linear trend line\n# s function stands for spline\n# bs basis-spline\n\n\n\nExercise 5\nAdjust the points in your graph:\n\nSet their shape to be 21\nSet their color to be 'black'\nSet their fill to be 'grey'\n\nAdjust the overall population trend as well:\n\nSet the line’s color to be 'red'\nRemove the standard errors (shaded region around the line) from the plot.\n\nSolution for Exercise 5:\n\nAdding (shape=21, color=“black”, fill=“grey”) to geom_point().\nWe also add color=“red”, se= FALSE to geom_smooth(). se=FALSE indicates to remove the standard errors on the plot.\n\n\nplot5 &lt;- ggplot(\n  data=gapminder,\n    aes(x=gdpPercap, \n        y=lifeExp)) + \n  geom_point(shape=21,  \n             color=\"black\", \n             fill=\"grey\") +\n  scale_x_log10(labels=NULL ) +\n  labs(y=\"Life expectancy, years\", \n       x=\"Log income\") +\n  geom_smooth(method='gam', \n              formula = y ~ s(x, bs = \"cs\"), \n              color=\"red\", \n              se= FALSE) \n\nplot5\n\n\n\n\n\n\n\n\n\n\nExercise 6\nGo to the ggplot2 theme() reference page and scroll through the pictures that show some of the built-in ggplot2 themes. Pick a theme that you like and add it to the figure you created in exercise 5.\nSolution for Exercise 6: We add the theme theme_classic() to change the plot background appearance.\n\nplot6 &lt;- plot5 +\n  theme_classic()\n\nplot6\n\n\n\n\n\n\n\n\n\n\nExercise 7\nThere is something happening in the upper levels of income. The population trend between income and life expectancy changes direction. There is an R package called plotly that can help you explore ggplot figures interactively. Converting a ggplot2 figure into a plotly figure is straightforward:\nYou can tell by hovering your mouse over the far right points in the figure that the higher income but lower life expectancy country is Kuwait. Now, re-create this figure, but use year as a label instead of country, and identify the years that account for these points.\nOnce you’ve seen the year values associated with the points in the upper-income but lower than expected life expectancy, formulate a hypothesis explaining your data. After you’ve written your hypothesis down, go to Wikipedia’s Kuwait page and read about their modern history. Was your hypothesis correct?\nSolution for Exercise 7:\n\nlibrary(plotly, warn.conflicts = FALSE)\n\n# first create the primary data set ggFigureEx7\nggfigure7 &lt;- ggplot(data=gapminder, \n                    aes(x=gdpPercap, y=lifeExp)) +\n  geom_point(shape=21,  \n             color=\"black\", \n             fill=\"grey\") +\n  scale_x_log10(labels=NULL) +\n  labs(y=\"Life expectancy, years\", \n       x=\"Log income\") +\n  geom_smooth(method='gam', \n              formula = y ~ s(x, bs = \"cs\"), \n              color=\"red\", \n              se= FALSE) +\n  theme_classic()\n\nggplotly(ggfigure7)\n\n\n\n\n#now create ggfigure7Yr with added label=year\nggfigureYr &lt;- ggfigure7 +  aes(label = year)\n\nggplotly(ggfigureYr)\n\n\n\n\n#create ggfigure7C with added label=country\nggfigureC &lt;- ggfigure7 +  aes(label = country)\n\nggplotly(ggfigureC)\n\n\n\n\n#an altertive method by adding group=country in the geom_point statement\n#allows to have labels for both country and year in plotyly\nggfigureAlt &lt;- ggplot(data=gapminder,\n                      aes(x=gdpPercap, y=lifeExp)) +\n  geom_point(aes(group = country), \n             shape=21,  color=\"black\", \n             fill=\"grey\") +\n  scale_x_log10(labels=NULL) +\n  labs (y=\"Life expectancy, years\", \n        x=\"Log income\") +\n  geom_smooth(method='gam', \n              formula = y ~ s(x, bs = \"cs\"), \n              color=\"red\", \n              se= FALSE) +\n  theme_classic() +\n  aes(label = year)\n\n\nggplotly(ggfigureAlt)\n\n\n\n\n\nAll of the points are in the range of the years 1952 and 1977. There appears to be upper-income but lower than expected life expectancy in Kuwait during these years.\nHypothesis: wealth was concentrated in a smaller group of people as compared to the general population.\nFrom Wikipedia: “90 per cent Of the capital generated from oil for investment abroad was concentrated in the hands of eighteen families.”\nSo there was an uneven distribution of weath in Kuwait during the span of years 1952 to 1977 that explain what the general life expectancy was lower as compared to the GDP.",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "html_files/03_Program/exercise_solutions.html",
    "href": "html_files/03_Program/exercise_solutions.html",
    "title": "Programming basics - Solutions",
    "section": "",
    "text": "These exercises will help you practice what you have learned about functions and vectors.",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "html_files/03_Program/exercise_solutions.html#overview",
    "href": "html_files/03_Program/exercise_solutions.html#overview",
    "title": "Programming basics - Solutions",
    "section": "",
    "text": "These exercises will help you practice what you have learned about functions and vectors.",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "html_files/04_Isolate/exercise_solutions.html",
    "href": "html_files/04_Isolate/exercise_solutions.html",
    "title": "Isolating data with dplyr",
    "section": "",
    "text": "NHANES (The National Health and Nutrition Examination Survey) was designed to assess the health and nutritional status of the US population and is conducted by the National Center for Health Statistics of the Centers for Disease Control and Prevention. Since 1999-2000, NHANES has been conducted in two-year cycles. For each cycle, potential participants are identified through stratified, multistage probability sampling of the non-institutionalized US population. In this set of exercises, we will use the ten cycles conducted from 1999-2000 through 2017-2018.\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n  \n\n\n\n\n\n\nReview this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nexam_status\nHow did SP engage with exam?\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\npregnant\nwas SP pregnant at time of exam?\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nn_msr_sbp\nNumber of valid systolic BP readings\n\n\nn_msr_dbp\nNumber of valid diastolic BP readings\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "04 - Isolation with dplyr"
    ]
  },
  {
    "objectID": "html_files/04_Isolate/exercise_solutions.html#import",
    "href": "html_files/04_Isolate/exercise_solutions.html#import",
    "title": "Isolating data with dplyr",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "04 - Isolation with dplyr"
    ]
  },
  {
    "objectID": "html_files/04_Isolate/exercise_solutions.html#data-dictionary",
    "href": "html_files/04_Isolate/exercise_solutions.html#data-dictionary",
    "title": "Isolating data with dplyr",
    "section": "",
    "text": "Review this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nexam_status\nHow did SP engage with exam?\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\npregnant\nwas SP pregnant at time of exam?\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nn_msr_sbp\nNumber of valid systolic BP readings\n\n\nn_msr_dbp\nNumber of valid diastolic BP readings\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "04 - Isolation with dplyr"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html",
    "href": "html_files/Midterm/midterm_start_here.html",
    "title": "BST680 Midterm",
    "section": "",
    "text": "This midterm is comprised of two portions:\n\nA visualization using a curated variation of the gapminder dataset\nA data manipulation and summarisation exercise emphasizing gt output\n\nFor each question, provide your code in order to create the requested output and comment your code either within the code block or by adding annotations directly to the Quarto document. I’m less interested in the specific code you used than I am understanding your thought process in order to get to the solution. Your comments are critical and should be provided as if to direct someone who has never seen your code to be able to reproduce it easily and know why you settled on these options.\n\n\n\n\n\n\nWarning\n\n\n\nTo best accomplish these coding tasks, you’ll need to work with functions that we may have only briefly discussed in class\nPart of this course is to develop your skill set to discover and use functions you may not have been aware of previously\nAgain, look at the references and cheat sheets, they’re your friends\n\n\nGood luck!\nTo get you started, a zipped file with all the necessary files and folders can be [downloaded here]\n\n\n\n\n\n\nTip\n\n\n\nYou can check your work as you go through the assignment by viewing the midterm html document available online\nConversely you can open “midterm_start_here.html” locally, click on it in the ‘Files’ pane of Rstudio and then select the ‘View in web browser option’\nEvery problem has the answer displayed in this document so you can verify whether you have gotten the expected result",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#prepping-the-data",
    "href": "html_files/Midterm/midterm_start_here.html#prepping-the-data",
    "title": "BST680 Midterm",
    "section": "Prepping the data",
    "text": "Prepping the data\n\nWe will be using a curated version of the gapminder dataset\nFor more details on the Gapminder organization, see https://www.gapminder.org/about-gapminder/\nYou’ll find the modified variation of the gapminder data below called gap_data; you may continue to use this name\n\n\n# Load libraries\nsuppressPackageStartupMessages({\n  #For the main problems\n  library(gapminder)\n  library(tidyverse)\n  library(ggrepel)\n  \n  #For the optional problem\n  library(gganimate)\n  library(gifski)\n})\n\n#Create the gap_data dataset\ngap_data &lt;- gapminder |&gt;\n  \n  #Keep only rows where the year is 2007\n  filter(year == 2007) |&gt; \n  \n  #Label column is computed for each continent, separately\n  #Group data by continent before creating the label column\n  #This column will be used for later questions\n  group_by(continent) |&gt; \n  mutate(\n    #Income is highly skewed; create a log scale variant for ease\n    log_income = log(gdpPercap),\n    \n    #The country_label column is used later\n    country_label = case_when(\n      lifeExp %in% c(min(lifeExp), max(lifeExp)) ~ country\n    )\n  )",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-1",
    "href": "html_files/Midterm/midterm_start_here.html#problem-1",
    "title": "BST680 Midterm",
    "section": "Problem 1",
    "text": "Problem 1\nUsing gap_data, create the following plot, use theme elements such as a different backgrounds or text sizes to personalize your plot; it doesn’t need to match my conventions exactly but be creative\nNotes:\n\nThe x-axis and y-axis labels indicate which columns in gap_data were used to make the data\nYou will want to use geom_point(shape = 21) to set the fill of points later in the assignment",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-2",
    "href": "html_files/Midterm/midterm_start_here.html#problem-2",
    "title": "BST680 Midterm",
    "section": "Problem 2",
    "text": "Problem 2\nMake some adjustments:\n\nUse log_income instead of gdpPercap as the x variable\nMake the countries (i.e. the points) have fills that correspond to the continent which the country belongs to\nMake the size of points proportional to the population of the country",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-3",
    "href": "html_files/Midterm/midterm_start_here.html#problem-3",
    "title": "BST680 Midterm",
    "section": "Problem 3",
    "text": "Problem 3\nMake a few more adjustments:\n\nSet the limits of the x-axis between 6 and 11 (i.e. xlim = c(6, 11))\nSet the limits of the y-axis between 30 and 85 (i.e. ylim = c(30, 85))\nAdd an annotation layer in the center of the plot indicating the year\nClean up the labels for the axes and legends\n\n\n\n\n\n\n\nTip\n\n\n\nThere are multiple ways to to do 3 such as using annotate or geom_text; I would recommend annotate to start but geom_text could prove easier for later questions\nYou might want to consider xlim, ylim and the mean function to help position your label in the exact center of the plot",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-4",
    "href": "html_files/Midterm/midterm_start_here.html#problem-4",
    "title": "BST680 Midterm",
    "section": "Problem 4",
    "text": "Problem 4\nMake some additional adjustments to your plot:\n\nSet the range of point sizes as c(1,20) hint: you’re using size is an aesthetic which means it has a scale_\nRemove the point size portion from the legend guide\nIncrease the size of points in the fill portion of the legend\n\n\n\n\n\n\n\nTip\n\n\n\nFor 2 and 3, you will need to make use of the guides() function from ggplot2\nFor 3 you will be using override.aes as an argument specifically\nSpend some time with the reference manual and cheat sheets if necessary",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-5",
    "href": "html_files/Midterm/midterm_start_here.html#problem-5",
    "title": "BST680 Midterm",
    "section": "Problem 5",
    "text": "Problem 5\nTry arranging gap_data by population size, in descending order, prior to plotting\nThis plot may or may not appear different compared to problem 4\nIn your comments, explain why there is or isn’t a difference in the plot",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-6",
    "href": "html_files/Midterm/midterm_start_here.html#problem-6",
    "title": "BST680 Midterm",
    "section": "Problem 6",
    "text": "Problem 6\nInclude the following label annotations on your plot:\n\nAdd a geom_label_repel layer to the plot that indicates which country in each continent has the highest or lowest life expectancy\nUse show.legend = FALSE to stop the text from being incorporated into the legend;\n\n\n\n\n\n\n\nTip\n\n\n\nMake sure all the labels are the same size and NOT proportional to the population size\nThink about how you want use size and ask “is it an aesthetic or an argument?”",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-7",
    "href": "html_files/Midterm/midterm_start_here.html#problem-7",
    "title": "BST680 Midterm",
    "section": "Problem 7",
    "text": "Problem 7\n\n\n\n\n\n\nImportant\n\n\n\nThis problem is optional and will require the original gapminder dataset\n\n\nGet creative with animations\n\nUse the gganimate package to make a smooth animation to update the background image of the year variable in the plot\nPut a label over one country of your choosing\nFor added challenge, find a way to make the year label in the background smoothly transition without showing decimal places\n\n\n\n\n\n\n\nTip\n\n\n\nYou can find a great gganimate tutorial here: https://github.com/thomasp85/gganimate",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#prepping-the-data-1",
    "href": "html_files/Midterm/midterm_start_here.html#prepping-the-data-1",
    "title": "BST680 Midterm",
    "section": "Prepping the Data",
    "text": "Prepping the Data\n\nsuppressPackageStartupMessages({\n  #For table output\n  library(gt)\n})\ncvd_data &lt;- read_csv(\"data/synthdata_cvd.csv\")\n\n\n\n#This code shows how you can use gt() to make tables in html documents\n#This code can be reused to help you make tables for these problems\n#For details, check out the gt vignette linked below or the Intro file from the first lecture\n#https://gt.rstudio.com/articles/gt.html\n\ncvd_data_dict &lt;- read_rds('data/synthdata_guide.RDS') |&gt; \n  rename(abbreviation = abbr) |&gt;\n  gt() |&gt;\n  \n  #cols_align will not accept vectorized values to align, so each alignment type must be specified\n  #The columns argument can use tidy selection if you want to use things like starts_with() from dplyr\n  cols_align(align = \"left\", columns = c(\"variable\", \"group\", \"label\")) |&gt;\n  cols_align(align = \"center\", columns = c(\"type\", \"unit\", \"abbreviation\")) |&gt;\n\n  #For titles and captions you can wrap the string in html() or md() to use HTML or markdown to format the text\n  #e.g. you can use &lt;br/&gt; to make a new line with html()\n  tab_header(title = html(\"Description of variables in the synthetic cardiovascular disease data\")) |&gt;\n\n  #You can enable html within the table as well, you can specify columns with tidy selection like cols_align\n  #Like the caption, you can also wrap individual cells in html() or md()\n  fmt_markdown(columns = everything()) |&gt;\n\n  #Other stylistic options can be set within the tab_options() function\n  #Here we make the table the full width and make the font size a bit smaller\n  tab_options(table.width = \"100%\",\n              table.font.size = pct(85))\n\n#A final comment, many static options are lost when using either ihtml. arguments within tab_options() or using opt_interactive()\n#I recommend just use static tables for now, there are better packages for dynamic tables\n\nThe synthdata_cvd.csv file contains synthetic data on 10000 participants\nIn this fake study, cardiovascular disease (CVD; stroke or coronary heart disease) events were identified during follow-up with the following two key variables:\n\ntime_chd_strk: The time, in years, from baseline until death, a CVD event, or last contact\nchd_strk: A value of “Yes” indicates that a CVD event occurred at time_chd_strk while a value of “No” indicates that a CVD event did not occur (i.e., death or last contact DID occur) at time_chd_strk\n\nThe other variables in the data are described below:\n\ncvd_data_dict\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescription of variables in the synthetic cardiovascular disease data\n\n\nvariable\ngroup\nlabel\ntype\nunit\nabbreviation\n\n\n\n\nage\nNone\nAge\nnumeric\nyears\nNone\n\n\nsex\nNone\nSex at birth\nfactor\nNone\nNone\n\n\nsbp\nBlood pressure\nSystolic\nnumeric\nmm Hg\nNone\n\n\ndbp\nBlood pressure\nDiastolic\nnumeric\nmm Hg\nNone\n\n\nelev_bp\nBlood pressure\nElevated\nfactor\nNone\nNone\n\n\nalbumin\nKidney function\nUrinary albumin\nnumeric\nmg/24hr\nNone\n\n\ncreatinine\nKidney function\nUrinary creatinine\nnumeric\ng/24hr\nNone\n\n\nalbuminuria\nKidney function\nAlbuminuria\nfactor\nNone\nNone\n\n\nscrcc\nKidney function\nSerum creatinine\nnumeric\nmg/dL\nNone\n\n\ngfr\nKidney function\nestimated GFR\nnumeric\nml/min/1.73 m2\nGFR = glomerular filtration rate\n\n\nlow_gfr\nKidney function\nLow kidney function\nfactor\nNone\nNone\n\n\nbpmeds\nMedication use\nAnti-Hypertensive\nfactor\nNone\nNone\n\n\ndmmeds\nMedication use\nAnti-Diabetic\nfactor\nNone\nNone\n\n\nstatinmeds\nMedication use\nStatin\nfactor\nNone\nNone",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-1-1",
    "href": "html_files/Midterm/midterm_start_here.html#problem-1-1",
    "title": "BST680 Midterm",
    "section": "Problem 1",
    "text": "Problem 1\n\n\n\n\n\n\nTip\n\n\n\nThis will be much easier with some functions we’ve only touched in in lecture\nSpend some time looking at dplyr’s material on colwise operations and scoping using across()\n\n\nStarting with the cvd_data object, select\n\nage (participant age in years)\nsex (participant sex at birth)\nscrcc (serum creatinine)\nsbp (systolic blood pressure)\ndbp (diastolic blood pressure)\nalbumin (urinary albumin)\ncreatinine (urinary creatinine)\nbpmeds (blood pressure medication use)\ndmmeds (anti-diabetic medication use)\nstatinmeds (statin medication use)\ntime_chd_strk (see above)\nchd_strk (see above)\n\nNext, remove participants from the data who were lost to follow up during the first 10 years but be careful not to confuse ‘lost to follow up’ with ‘had a CVD event’\nDetermine the dimensions of your dataset to get the number of rows and columns and compare to the results from the starting HTML file; you have many ways to get to these values\n\n\n[1] 8169   12\n\n\nNow, create a table summarizing the proportion of missing values in each column of the data using the table provided here as reference to check your work\n\n\n\n\n\n\n\n\n\n\n\n\nPercentage of missing values\nfor simulated data variables\n\n\nVariable\nPercent Missing\n\n\n\n\nage\n0.00\n\n\nsex\n0.00\n\n\nscrcc\n1.43\n\n\nsbp\n0.37\n\n\ndbp\n0.37\n\n\nalbumin\n39.75\n\n\ncreatinine\n39.70\n\n\nbpmeds\n0.77\n\n\ndmmeds\n0.81\n\n\nstatinmeds\n0.88\n\n\ntime_chd_strk\n0.00\n\n\nchd_strk\n0.00\n\n\n\n\n\n\n\nLast, remove any row in the data where a participant has a missing value (NA) and print the dimensions of the data now that all rows with at least one missing value are filtered out\n\n\n[1] 4821   12",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-2-1",
    "href": "html_files/Midterm/midterm_start_here.html#problem-2-1",
    "title": "BST680 Midterm",
    "section": "Problem 2",
    "text": "Problem 2\nUsing the data created in problem 1, identify the oldest male and female who are taking both blood pressure lowering medication and anti-diabetes medication\nUsing these two participants’ data, create the table shown in the starting document\n\n\n\n\n\n\n\n\n\n\n\n\nAge of the oldest participants taking both blood pressure lowering medication\nand anti-diabetic medication in male and female groups\n\n\nSex\nAge\n\n\n\n\nMale\n90\n\n\nFemale\n84",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-3-1",
    "href": "html_files/Midterm/midterm_start_here.html#problem-3-1",
    "title": "BST680 Midterm",
    "section": "Problem 3",
    "text": "Problem 3\nCreate the following variables:\n\ncvd10: This variable is ‘Yes’ if participants experienced a CVD event during the first 10 years of follow-up, and ‘No’ otherwise.\nalbuminuria: This variable is ‘Yes’ if a participant’s urinary albumin to creatinine ratio is greater than 30 mg/g, and ‘No’ otherwise.\negfr: (estimated glomerular filtration rate) This variable is computed conditionally for males and females based on serum creatinine (i.e., scrcc).\n\nFor females with scrcc \\(\\leq\\) 0.7, \\[\\texttt{gfr} = 166 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.7}\\right)^{-0.329}.\\]\nFor females with scrcc \\(&gt;\\) 0.7, \\[\\texttt{gfr} = 166 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.7}\\right)^{-1.209}.\\]\nFor males with scrcc \\(\\leq\\) 0.9, \\[\\texttt{gfr} = 163 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.9}\\right)^{-0.411}.\\]\nFor males with scrcc \\(\\geq\\) 0.9, \\[\\texttt{gfr} = 163 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.9}\\right)^{-1.209}.\\]\n\nlow_gfr This variable is Yes if a participant’s estimated glomerular filtration rate is \\(&lt; 60 \\text{ml/min/1.73m}^2\\), and ‘No’ otherwise.\nelev_bp This variable is Yes if any of the following conditions are true:\n\nsystolic blood pressure &gt; 130 mm Hg\ndiastolic blood pressure &gt; 80 mm Hg\nthe participant is currently using blood pressure medications.\n\n\nLast, convert all character (chr) variables into factors (fct)\nApply the glimpse function to your data to show column types and values for all variables\nThis data will be used in all problems that follow and will be referred to as the sample from problem 3\n\n\nRows: 4,821\nColumns: 17\n$ age           &lt;dbl&gt; 50, 43, 69, 33, 40, 67, 61, 54, 59, 65, 36, 77, 80, 56, …\n$ sex           &lt;fct&gt; Female, Female, Female, Female, Male, Female, Female, Fe…\n$ scrcc         &lt;dbl&gt; 0.6637465, 0.8505938, 0.7571701, 0.8505938, 1.2242885, 1…\n$ sbp           &lt;dbl&gt; 132.9989, 110.0764, 124.7468, 123.8299, 112.8271, 144.00…\n$ dbp           &lt;dbl&gt; 78.3681, 62.5962, 66.7467, 67.5768, 80.8584, 67.5768, 78…\n$ albumin       &lt;dbl&gt; 1.81, 1.06, 1.31, 3.70, 0.58, 8.10, 2.15, 6.10, 0.68, 6.…\n$ creatinine    &lt;dbl&gt; 164.0, 156.0, 78.0, 84.0, 153.0, 88.0, 117.0, 223.0, 61.…\n$ bpmeds        &lt;fct&gt; No, No, No, No, No, No, Yes, Yes, Yes, Yes, No, Yes, Yes…\n$ dmmeds        &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ statinmeds    &lt;fct&gt; No, No, No, No, No, No, No, No, No, Yes, No, No, Yes, No…\n$ time_chd_strk &lt;dbl&gt; 11.542779, 12.114990, 11.748118, 11.594798, 11.154004, 2…\n$ chd_strk      &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, Yes, No, No…\n$ cvd10         &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, Yes, No, No…\n$ albuminuria   &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ egfr          &lt;dbl&gt; 118.89649, 96.96503, 92.97899, 104.02139, 84.83699, 58.0…\n$ low_gfr       &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, No, Yes, No…\n$ elev_bp       &lt;fct&gt; Yes, No, No, No, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-4-1",
    "href": "html_files/Midterm/midterm_start_here.html#problem-4-1",
    "title": "BST680 Midterm",
    "section": "Problem 4",
    "text": "Problem 4\nGroup the data from problem 3 by sex, albuminuria, and low_gfr groups and, for each group, compute the incident rate of CVD per 1000 person-years: \\[\\texttt{incident CVD rate per 1000 person years} = 1000 \\cdot \\frac{\\texttt{no. of CVD events}}{\\texttt{no. of years at risk}}\\]\nAfter creating this summary data, use ggplot to create a tiled figure (i.e. geom_tile) that shows the incident CVD rate for all four categories of albuminuria and low_gfr among males and females, separately\nUse geom_label to place the exact rate of incident CVD as text into each tile of the figure",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_start_here.html#problem-5-1",
    "href": "html_files/Midterm/midterm_start_here.html#problem-5-1",
    "title": "BST680 Midterm",
    "section": "Problem 5",
    "text": "Problem 5\nCreate a new column in the data from problem 3 that indicates the various combinations of medications taken by each participant using the bpmeds, dmmeds, and statinmeds binary variables\nOverall, there are 2 x 2 x 2 = 8 possible medication patterns (recall that we removed any rows with missing values)\nUsing this variable you create, identify the four most common medication groups in the dataset\nModify the medication group variable so that any other groups apart from the four most common ones are labeled as ‘Other’\nFor example, this may include:\n\nA group wherein the participant is taking no medication at all\nA group who is taking medication to lower blood pressure only with no other medications\nA category for those taking statins plus medication to lower blood pressure\nA category encompassing all other combinations\n\nOverall, there are 2 x 2 x 2 = 8 possible medication patterns (recall that we removed any rows with missing values)\nPresent the frequency and proportion of observations for each medical profile and stratify your results by sex groups\n\n\n\n\n\n\nTip\n\n\n\nSpend some time with forcats to see how you can make this process easier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTop four medication profiles\nin the data from problem 3\n\n\nMedication Profile\nFemale\nMale\n\n\n\n\nNo Medications\n1355 (44%)\n911 (53%)\n\n\nBP Meds Only\n1006 (32%)\n420 (25%)\n\n\nBP and DM Meds\n254 (8%)\n127 (7%)\n\n\nBP Meds and Statins\n210 (7%)\n115 (7%)\n\n\nOther\n284 (9%)\n139 (8%)\n\n\n\nTable values are frequency (%)",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Details"
    ]
  },
  {
    "objectID": "downloads.html",
    "href": "downloads.html",
    "title": "BST680 Downloads",
    "section": "",
    "text": "All exercises can be downloaded here in both .qmd and .R formats\n\n\nTo properly render Quarto Markdown files, be sure to download the .rds solutions and data files\nSolutions are in a .zip file that should be extracted in the same location as the .qmd file to properly render\n\n\n\nExercises - [.qmd file]\nSolutions folder - [.zip file]\n\n\n\nExercises - [.qmd file]\nSolutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nSolutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]\n\n\n\nExercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#introducing-your-tools",
    "href": "downloads.html#introducing-your-tools",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file]\nSolutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#visualization-basics",
    "href": "downloads.html#visualization-basics",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file]\nSolutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#programming-basics",
    "href": "downloads.html#programming-basics",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nSolutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#data-isolation",
    "href": "downloads.html#data-isolation",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#data-transformation",
    "href": "downloads.html#data-transformation",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#advanced-visualization",
    "href": "downloads.html#advanced-visualization",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "downloads.html#reshaping-data",
    "href": "downloads.html#reshaping-data",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html",
    "href": "Lectures/07_Reshape/index.html",
    "title": "Tidying and Reshaping Data",
    "section": "",
    "text": "Reinforcing tidy data\nLong vs wide data\npivot_ functions for reshaping\nMissingness\nWorking with string columns",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#agenda",
    "href": "Lectures/07_Reshape/index.html#agenda",
    "title": "Tidying and Reshaping Data",
    "section": "",
    "text": "Reinforcing tidy data\nLong vs wide data\npivot_ functions for reshaping\nMissingness\nWorking with string columns",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#tidy-data---recall-our-definitions",
    "href": "Lectures/07_Reshape/index.html#tidy-data---recall-our-definitions",
    "title": "Tidying and Reshaping Data",
    "section": "Tidy Data - Recall Our Definitions",
    "text": "Tidy Data - Recall Our Definitions\n\nA variable is some sort of quality, quantity or property of the data\nVariables are comprised of values which are specific instances or measures of a variable\nAn observation is a set of measurements under similar conditions, it can be thought of as a unique set of values specific to those conditions\nTabular data takes a set of values each associated with a variable and an observation and gives a rectangular structure\nOur goal is to make data tidy wherein each value is its own cell, each variable is its own column, each observation is its own row",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#tidy-data---our-example",
    "href": "Lectures/07_Reshape/index.html#tidy-data---our-example",
    "title": "Tidying and Reshaping Data",
    "section": "Tidy Data - Our Example",
    "text": "Tidy Data - Our Example\n\nWe spend much time coercing our material into tibbles (or data frames) as they enforce tidy-ness\n\n\n\n\n\n\n\nWe also know many ways to access our data including…\n\n. . .\n`$` `[[ ]]` `[ ]` `select()` `pick()`",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#tidy-data---why-it-matters",
    "href": "Lectures/07_Reshape/index.html#tidy-data---why-it-matters",
    "title": "Tidying and Reshaping Data",
    "section": "Tidy Data - Why It Matters",
    "text": "Tidy Data - Why It Matters\n\n\n\n\n\n\n\n\n\n\n\nhttps://allisonhorst.com/other-r-fun",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#tidy-data---why-it-matters-1",
    "href": "Lectures/07_Reshape/index.html#tidy-data---why-it-matters-1",
    "title": "Tidying and Reshaping Data",
    "section": "Tidy Data - Why It Matters",
    "text": "Tidy Data - Why It Matters\n\nFlexibility is good but consistency is better, especially for programming\n\n\n\n\n\n\n\nhttps://allisonhorst.com/other-r-fun",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#tidy-data---why-it-matters-2",
    "href": "Lectures/07_Reshape/index.html#tidy-data---why-it-matters-2",
    "title": "Tidying and Reshaping Data",
    "section": "Tidy Data - Why It Matters",
    "text": "Tidy Data - Why It Matters\n\nThe columns-as-variables lets the vectorized nature of data frames and tibbles in R shine\n\n\n\n\n\n\n\nIt also enables the tidy selection and data masking of the tidyverse (for better or worse)\n\n\nhttps://allisonhorst.com/other-r-fun",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#tidy-data---meanwhile-in-the-real-world",
    "href": "Lectures/07_Reshape/index.html#tidy-data---meanwhile-in-the-real-world",
    "title": "Tidying and Reshaping Data",
    "section": "Tidy Data - Meanwhile in the Real World…",
    "text": "Tidy Data - Meanwhile in the Real World…\n\nData is messy, even messier than what we’ve been working with\n\n\n\n\n\n\n\nIt’s not enough to isolate and transform, we may need to pivot\n\n\nhttps://developer.ibm.com/tutorials/ba-cleanse-process-visualize-data-set-1/",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - Wide Data",
    "text": "Wide vs Long - Wide Data\n\nWide data can be thought of as multiple univariate data sets\n\n\n\n\n\n\n\nhttps://knowledge.dataiku.com/",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data-1",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data-1",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - Wide Data",
    "text": "Wide vs Long - Wide Data\n\nWhich gets very complicated with multivariate data…\n\n\n\n\n\n\n\nhttps://knowledge.dataiku.com/",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data-2",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data-2",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - Wide Data",
    "text": "Wide vs Long - Wide Data\n\n…or time series data like the billboard dataset\n\n\n\n# A tibble: 317 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n# ℹ 312 more rows\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;, …",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data-3",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---wide-data-3",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - Wide Data",
    "text": "Wide vs Long - Wide Data\n\nWide data sets are defined by having actual datain their column names\n\n\n\n\nIn billboard each observation is a song with the first three variables describing the song\nBut the other 76 (!) columns describe the rank with thecolumn names describing theweek it entered",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---long-data",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---long-data",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - Long Data",
    "text": "Wide vs Long - Long Data\n\nLong data instead has no values in column names\n\n\n\n\n\n\n\nhttps://knowledge.dataiku.com/",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---long-data-1",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---long-data-1",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - Long Data",
    "text": "Wide vs Long - Long Data\n\nIt also does a much better job handling missing data\n\n\n\n\n\n\n\nhttps://knowledge.dataiku.com/",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#wide-vs-long---so-why-wide",
    "href": "Lectures/07_Reshape/index.html#wide-vs-long---so-why-wide",
    "title": "Tidying and Reshaping Data",
    "section": "Wide vs Long - So Why Wide?",
    "text": "Wide vs Long - So Why Wide?\n\nR in general prefers long data to wide\n\nBetter for vectorization and formula formattingi.e. yvar ~ xvar_1 + xvar_2 + ...\nMandatory for time series data in longitudinal or survival designs\n\nWide data is still common\n\nWell supported in other stats programs for things like 2-way or repeated measures ANOVA\nIs often more intuitive for data collection . . .\n\nThus it’s up to you to make things tidyr",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---the-tidyr-package",
    "href": "Lectures/07_Reshape/index.html#pivot---the-tidyr-package",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - The tidyr Package",
    "text": "Pivot - The tidyr Package\n\ntidyr is how the tidyverse makes data tidy with 5 categories:\n\nPivoting to convert data between wide and long\nRectangling for dealing with nested lists\nNesting to embed data frames within data frames\nSeparating and uniting character data columns\nDealing with NA as missingness\n\nOur focus is on 1 and 5 and a bit of 4",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---what-it-looks-like",
    "href": "Lectures/07_Reshape/index.html#pivot---what-it-looks-like",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - What it Looks Like",
    "text": "Pivot - What it Looks Like",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---a-history",
    "href": "Lectures/07_Reshape/index.html#pivot---a-history",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - A History",
    "text": "Pivot - A History\n\nOriginally, tidyr had functions called spread() and gather() but…\n\nThe names were unintuitive\nThe arguments were hard to remember\nFunction support for transforming was limited in scope\n\nIn a later update, pivot_wider() and pivot_longer() were added to supersede spread() and gather()\nWhile spread() and gather() still function within tidyr and can be used, our focus is on the pivot_ family",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---some-long-covid-data",
    "href": "Lectures/07_Reshape/index.html#pivot---some-long-covid-data",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Some Long Covid data",
    "text": "Pivot - Some Long Covid data\n\nToday we have some case and and death data on COVID-19 by state and day from the NY times called cv19\n\n\nprint(cv19, n=7)\n\n# A tibble: 61,942 × 4\n  date       state      cases deaths\n  &lt;date&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 2020-01-21 Washington     1      0\n2 2020-01-22 Washington     1      0\n3 2020-01-23 Washington     1      0\n4 2020-01-24 Illinois       1      0\n5 2020-01-24 Washington     1      0\n6 2020-01-25 California     1      0\n7 2020-01-25 Illinois       1      0\n# ℹ 61,935 more rows\n\n\n\nPretty long but could be longer",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---using-pivot_longer",
    "href": "Lectures/07_Reshape/index.html#pivot---using-pivot_longer",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Using pivot_longer()",
    "text": "Pivot - Using pivot_longer()\n\nLet’s get a longer form where:\n\nCases and death values are in the value column\nCases and death indicators in the name column.\n\n\n\ncv19_long &lt;- cv19 |&gt;\n  pivot_longer(cols = c(cases, deaths)) #&lt;&lt;\n\ncv19_long[1:5, ]\n\n# A tibble: 5 × 4\n  date       state      name   value\n  &lt;date&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;\n1 2020-01-21 Washington cases      1\n2 2020-01-21 Washington deaths     0\n3 2020-01-22 Washington cases      1\n4 2020-01-22 Washington deaths     0\n5 2020-01-23 Washington cases      1",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---using-pivot_longer-1",
    "href": "Lectures/07_Reshape/index.html#pivot---using-pivot_longer-1",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Using pivot_longer()",
    "text": "Pivot - Using pivot_longer()\n\nThe cols argument indicates the variables that will be cast to value while the column names populate name; cols also understands tidy selection e.g. starts_with()\nYou can rename the value variable with values_to and rename name with names_to\nCheck the reference for other useful arguments like drop_na\n\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\")",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---r-loves-long-data",
    "href": "Lectures/07_Reshape/index.html#pivot---r-loves-long-data",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - R Loves Long Data",
    "text": "Pivot - R Loves Long Data\n\nLong vectorized data is ideal for packages like ggplot2\n\n\nggplot(cv19_long, aes(x=date, y = value)) +\n  geom_line(aes(group = state)) +\n  labs(title = \"Covid Cases and Deaths\") +\n  facet_wrap(~ name, scales = 'free')",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---using-pivot_wider",
    "href": "Lectures/07_Reshape/index.html#pivot---using-pivot_wider",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Using pivot_wider()",
    "text": "Pivot - Using pivot_wider()\n\npivot_wider() does the inverse, adding columns and reducing rows\nNHANES is a good example since each row is an exam year\n\n\n\n# A tibble: 30 × 4\n# Groups:   exam, sex [6]\n   exam  sex    race_ethnicity     bp_sys_mmhg\n   &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;                    &lt;dbl&gt;\n 1 2013  Female Non-Hispanic White        121.\n 2 2013  Female Non-Hispanic Black        125.\n 3 2013  Female Non-Hispanic Asian        118.\n 4 2013  Female Hispanic                  119.\n 5 2013  Female Other race                119.\n 6 2013  Male   Non-Hispanic White        123.\n 7 2013  Male   Non-Hispanic Black        129.\n 8 2013  Male   Non-Hispanic Asian        123.\n 9 2013  Male   Hispanic                  124.\n10 2013  Male   Other race                123.\n# ℹ 20 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---using-pivot_wider-1",
    "href": "Lectures/07_Reshape/index.html#pivot---using-pivot_wider-1",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Using pivot_wider()",
    "text": "Pivot - Using pivot_wider()\n\npivot_wider() can give sys_bp_mmhg columns for each exam year\n\n\nnhanes_wide &lt;- nhanes_long |&gt;\n  pivot_wider(values_from = bp_sys_mmhg, #&lt;&lt;\n    names_from = exam, names_prefix = \"exam_\") #&lt;&lt;\nnhanes_wide\n\n# A tibble: 10 × 5\n# Groups:   sex [2]\n   sex    race_ethnicity     exam_2013 exam_2015 exam_2017\n   &lt;fct&gt;  &lt;fct&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Female Non-Hispanic White      121.      124.      125.\n 2 Female Non-Hispanic Black      125.      126.      131.\n 3 Female Non-Hispanic Asian      118.      119.      123.\n 4 Female Hispanic                119.      123.      123.\n 5 Female Other race              119.      122.      123.\n 6 Male   Non-Hispanic White      123.      126.      127.\n 7 Male   Non-Hispanic Black      129.      131.      132.\n 8 Male   Non-Hispanic Asian      123.      123.      124.\n 9 Male   Hispanic                124.      127.      126.\n10 Male   Other race              123.      125.      126.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---r-loves-wide-data-too",
    "href": "Lectures/07_Reshape/index.html#pivot---r-loves-wide-data-too",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - R Loves Wide Data Too",
    "text": "Pivot - R Loves Wide Data Too\n\n#gt works well with wide data\n\n#In fact, we want it even wider!\n\ngt(nhanes_wide) |&gt;\n  fmt_number(columns = starts_with(\"exam\"), \n             decimals = 1) |&gt;\n  cols_align(columns = \"race_ethnicity\", \n             align = \"left\")\n\n\n\n\n\n\n\nrace_ethnicity\nexam_2013\nexam_2015\nexam_2017\n\n\n\n\nFemale\n\n\nNon-Hispanic White\n121.2\n123.6\n124.6\n\n\nNon-Hispanic Black\n125.2\n126.4\n131.3\n\n\nNon-Hispanic Asian\n118.0\n119.2\n123.5\n\n\nHispanic\n119.4\n123.2\n122.9\n\n\nOther race\n118.8\n121.7\n122.6\n\n\nMale\n\n\nNon-Hispanic White\n123.4\n125.9\n127.0\n\n\nNon-Hispanic Black\n128.5\n130.5\n131.6\n\n\nNon-Hispanic Asian\n122.7\n122.7\n124.4\n\n\nHispanic\n124.2\n126.7\n126.0\n\n\nOther race\n123.0\n125.0\n125.7",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---arguments-in-pivot_wider",
    "href": "Lectures/07_Reshape/index.html#pivot---arguments-in-pivot_wider",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Arguments in pivot_wider()",
    "text": "Pivot - Arguments in pivot_wider()\n\nArguments follow similar conventions as in pivot_longer()\n\nnames_from defines the columns which provide the name of the output column; use names_prefix to annotate the new columns\nvalues_from indicates the column which gives the cell values\nid_cols defaults to all other columns but is what defines a unique observation in the wide data set\n\nnames_from can also accept vectors for even wider data",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---even-pivot_widerer",
    "href": "Lectures/07_Reshape/index.html#pivot---even-pivot_widerer",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Even pivot_wider()er",
    "text": "Pivot - Even pivot_wider()er\n\nCreate the new wide columns from both sex and exam year\n\n\nnhanes_wider &lt;- nhanes_long |&gt;\n  pivot_wider(names_from = c(sex, exam), names_sort = TRUE,\n              values_from = bp_sys_mmhg)\n\nnhanes_wider\n\n# A tibble: 5 × 7\n  race_ethnicity     Female_2013 Female_2015 Female_2017 Male_2013 Male_2015\n  &lt;fct&gt;                    &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Non-Hispanic White        121.        124.        125.      123.      126.\n2 Non-Hispanic Black        125.        126.        131.      129.      131.\n3 Non-Hispanic Asian        118.        119.        123.      123.      123.\n4 Hispanic                  119.        123.        123.      124.      127.\n5 Other race                119.        122.        123.      123.      125.\n# ℹ 1 more variable: Male_2017 &lt;dbl&gt;\n\n\n\nI’d discourage passing vectors to values_from",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---better-gt-tables-with-wide-data",
    "href": "Lectures/07_Reshape/index.html#pivot---better-gt-tables-with-wide-data",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - Better gt Tables with Wide Data",
    "text": "Pivot - Better gt Tables with Wide Data\n\nWe can use our gt skills to make a great table\n\n\ngt(nhanes_wider, rowname_col = \"race_ethnicity\") |&gt;\n  cols_align(columns = \"race_ethnicity\", \"left\") |&gt;\n  fmt_number(columns = !starts_with('race'), decimals = 1) |&gt;\n  tab_spanner_delim(columns = !starts_with('race'), delim = '_') |&gt;\n  tab_stubhead(\"Race\") \n\n\n\n\n\n\n\nRace\nFemale\nMale\n\n\n2013\n2015\n2017\n2013\n2015\n2017\n\n\n\n\nNon-Hispanic White\n121.2\n123.6\n124.6\n123.4\n125.9\n127.0\n\n\nNon-Hispanic Black\n125.2\n126.4\n131.3\n128.5\n130.5\n131.6\n\n\nNon-Hispanic Asian\n118.0\n119.2\n123.5\n122.7\n122.7\n124.4\n\n\nHispanic\n119.4\n123.2\n122.9\n124.2\n126.7\n126.0\n\n\nOther race\n118.8\n121.7\n122.6\n123.0\n125.0\n125.7",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#pivot---and-back-with-pivot_longer",
    "href": "Lectures/07_Reshape/index.html#pivot---and-back-with-pivot_longer",
    "title": "Tidying and Reshaping Data",
    "section": "Pivot - And Back with pivot_longer()",
    "text": "Pivot - And Back with pivot_longer()\n\nOur wide columns are named [sex value]_[exam value] so use names_sep = \"_\" and combine with tidy selection\n\n\npivot_longer(nhanes_wider, cols = -race_ethnicity, values_to = \"bp_sys_mmhg_once_more\",\n    names_to = c('sex', 'exam'), names_sep = '_')\n\n# A tibble: 30 × 4\n   race_ethnicity     sex    exam  bp_sys_mmhg_once_more\n   &lt;fct&gt;              &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;\n 1 Non-Hispanic White Female 2013                   121.\n 2 Non-Hispanic White Female 2015                   124.\n 3 Non-Hispanic White Female 2017                   125.\n 4 Non-Hispanic White Male   2013                   123.\n 5 Non-Hispanic White Male   2015                   126.\n 6 Non-Hispanic White Male   2017                   127.\n 7 Non-Hispanic Black Female 2013                   125.\n 8 Non-Hispanic Black Female 2015                   126.\n 9 Non-Hispanic Black Female 2017                   131.\n10 Non-Hispanic Black Male   2013                   129.\n# ℹ 20 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---more-than-mutate",
    "href": "Lectures/07_Reshape/index.html#missingness---more-than-mutate",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - More than mutate()",
    "text": "Missingness - More than mutate()\n\n\n\n\n\n\n\n\n\nPreviously, we saw how mutate() can be used on whole columns to assign missingness vector-wise via na_if()\ntidyr offers many additional options for coercing to and from NA values either implicitly or explicitly\nIt can also provide some imputation capacity",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---back-to-the-billboard",
    "href": "Lectures/07_Reshape/index.html#missingness---back-to-the-billboard",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Back to the Billboard",
    "text": "Missingness - Back to the Billboard\n\nbillboard has many missing values; no complete data is found anywhere (caps at 65 weeks)\n\n\nbb_long &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\")\n\n\nThe drop_na argument in pivot_longer() could drop any rows with NA in our new value column…",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---back-to-the-billboard-1",
    "href": "Lectures/07_Reshape/index.html#missingness---back-to-the-billboard-1",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Back to the Billboard",
    "text": "Missingness - Back to the Billboard\n\nOtherwise rank now has a huge number of missing values (&gt;75%)\n\n\n\n# A tibble: 24,092 × 5\n   artist track                   date.entered week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n# ℹ 24,082 more rows\n\n\n\nmean(is.na(bb_long$rank))\n\n[1] 0.7797194",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---dealing-with-explicit-nas",
    "href": "Lectures/07_Reshape/index.html#missingness---dealing-with-explicit-nas",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Dealing with Explicit NAs",
    "text": "Missingness - Dealing with Explicit NAs\n\nWe can replace NA with replace_na(), the inverse of na_if()\n\n\nreplace_na(bb_long, replace = list(rank = -888))\n\n# A tibble: 24,092 × 5\n   artist track                   date.entered week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8    -888\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9    -888\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10   -888\n# ℹ 24,082 more rows\n\n\n\nreplace needs to be a list if data is a data frame",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---dealing-with-explicit-nas-1",
    "href": "Lectures/07_Reshape/index.html#missingness---dealing-with-explicit-nas-1",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Dealing with Explicit NAs",
    "text": "Missingness - Dealing with Explicit NAs\n\nDrop rows with NA post pivot_longer() with drop_na()\n\n\ndrop_na(bb_long, c(rank))\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered week   rank\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87\n10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92\n# ℹ 5,297 more rows\n\n\n\nThese will both prove useful later with joins",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---working-with-implicit-na",
    "href": "Lectures/07_Reshape/index.html#missingness---working-with-implicit-na",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Working with Implicit NA",
    "text": "Missingness - Working with Implicit NA\n\n\n\nUsing drop_na() leads to implicit NAs where the absence of an occurrence implies an NA would otherwise exist\nThe complete() function makes these implicit NAs explicit by completing a data frame with missing combinations of data",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---working-with-implicit-na-1",
    "href": "Lectures/07_Reshape/index.html#missingness---working-with-implicit-na-1",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Working with Implicit NA",
    "text": "Missingness - Working with Implicit NA\n\nThis returns us back (almost) to the original bb_long\n\n\ndrop_na(bb_long, c(rank)) |&gt; complete(nesting(artist, track, date.entered), week) |&gt; arrange(artist, track, week)\n\n# A tibble: 20,605 × 5\n   artist track                   date.entered week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk11     NA\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk12     NA\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk13     NA\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk14     NA\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk15     NA\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk16     NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk17     NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk18     NA\n# ℹ 20,595 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---imputation-with-fill",
    "href": "Lectures/07_Reshape/index.html#missingness---imputation-with-fill",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Imputation with fill()",
    "text": "Missingness - Imputation with fill()\n\nfill() can be used to impute and overwrite NA missing values based on the previous or next entry\n\nUsing the previous entry is Last Observation Carried Forward\nUsing the next value is Next Observation Carried Backward\n\nVery useful when dealing with “jagged” data e.g. common with REDCap\n\n\n\n\n\n\n\nWarning\n\n\n\nUse imputation with caution and consideration!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#missingness---imputation-with-fill-1",
    "href": "Lectures/07_Reshape/index.html#missingness---imputation-with-fill-1",
    "title": "Tidying and Reshaping Data",
    "section": "Missingness - Imputation with fill()",
    "text": "Missingness - Imputation with fill()\n\nUsing .direction = \"down\" to do LOCF\n\n\n\n\nsales &lt;- tibble::tribble(\n  \n  ~quarter, ~year, ~sales,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197,\n  \"Q1\",    2002,    39113,\n  \"Q2\",      NA,    41668,\n  \"Q3\",      NA,    30144,\n  \"Q4\",      NA,    52897\n)\n\n\n\nsales |&gt; fill(year, .direction = \"down\")\n\n# A tibble: 12 × 3\n   quarter  year sales\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Q1       2000 66013\n 2 Q2       2000 69182\n 3 Q3       2000 53175\n 4 Q4       2000 21001\n 5 Q1       2001 46036\n 6 Q2       2001 58842\n 7 Q3       2001 44568\n 8 Q4       2001 50197\n 9 Q1       2002 39113\n10 Q2       2002 41668\n11 Q3       2002 30144\n12 Q4       2002 52897",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---a-brief-intro",
    "href": "Lectures/07_Reshape/index.html#strings---a-brief-intro",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - A Brief Intro",
    "text": "Strings - A Brief Intro\n\nMany packages work with string data, most notably stringrfrom the tidyverse\ntidyr specifically handles vector-wise applications of character data in a data frame\n\nunite() combines multiple character columns into a single\nThe separate_ family splits a single column into multiple columns or rows i.e. too much data is in a single column\n\nDon’t forget about coercion!",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---combine-with-unite",
    "href": "Lectures/07_Reshape/index.html#strings---combine-with-unite",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - Combine with unite()",
    "text": "Strings - Combine with unite()\n\nA convenience function to paste columns together with a sep\n\n\nbb_long |&gt;\n  unite(\"wk_rank\", c(week, rank), sep = \"_\",  #&lt;&lt;\n        remove = FALSE, na.rm = TRUE)\n\n# A tibble: 24,092 × 6\n   artist track                   date.entered wk_rank week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1_87  wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2_82  wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3_72  wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4_77  wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5_87  wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6_94  wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7_99  wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8     wk8      NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9     wk9      NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10    wk10     NA\n# ℹ 24,082 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---combine-with-unite-1",
    "href": "Lectures/07_Reshape/index.html#strings---combine-with-unite-1",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - Combine with unite()",
    "text": "Strings - Combine with unite()\n\nremove drops columns after pasting while na.rm will keep NA\n\n\nbb_long |&gt;\n  unite(\"wk_rank\", c(week, rank), sep = \"_\",\n        remove = TRUE, na.rm = FALSE)   #&lt;&lt; Check the defaults!\n\n# A tibble: 24,092 × 4\n   artist track                   date.entered wk_rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;  \n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1_87 \n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2_82 \n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3_72 \n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4_77 \n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5_87 \n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6_94 \n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7_99 \n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8_NA \n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9_NA \n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10_NA\n# ℹ 24,082 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---separate_-as-the-complement",
    "href": "Lectures/07_Reshape/index.html#strings---separate_-as-the-complement",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - separate_ as the Complement",
    "text": "Strings - separate_ as the Complement\n\nThe separate_ family has many more options\n\nseparate_wider_ splits one column into multiple columns\nseparate_longer_ splits a character column into multiple rows\n\nHow you split also matters\n\nseparate_*_delim() uses delimiters like unite()\nseparate_*_position() splits on fixed positions\n\nseparate_wider_regex() uses regular expressions (next time)\nLike pivot_, these have superseded separate() and extract()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---separate_longer_-is-less-common",
    "href": "Lectures/07_Reshape/index.html#strings---separate_longer_-is-less-common",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - separate_longer_ is Less Common",
    "text": "Strings - separate_longer_ is Less Common\n\n\n\nMost useful when collaborators have multiple uneven observations in a single column\n\n\ndat &lt;- tibble(id = 1:4, dat_col = c(\"x\", \"x y\", \"x y z\", NA))\n\ndat\n\n# A tibble: 4 × 2\n     id dat_col\n  &lt;int&gt; &lt;chr&gt;  \n1     1 x      \n2     2 x y    \n3     3 x y z  \n4     4 &lt;NA&gt;   \n\n\n\n\nUnlike unite()‘s default of’_’, delim must always be specified\n\n\ndat |&gt; \n  separate_longer_delim(cols = dat_col,\n                        delim = \" \")  #&lt;&lt;\n\n# A tibble: 7 × 2\n     id dat_col\n  &lt;int&gt; &lt;chr&gt;  \n1     1 x      \n2     2 x      \n3     2 y      \n4     3 x      \n5     3 y      \n6     3 z      \n7     4 &lt;NA&gt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---separate_wider_",
    "href": "Lectures/07_Reshape/index.html#strings---separate_wider_",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - separate_wider_",
    "text": "Strings - separate_wider_\n\nGreat when multiple variables exist in a single column\n\n\nbb_long |&gt;\n  separate_wider_delim(cols = date.entered, delim = \"-\",\n                       names = c(\"year\", \"month\", \"day\"))\n\n# A tibble: 24,092 × 7\n   artist track                   year  month day   week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk8      NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk9      NA\n10 2 Pac  Baby Don't Cry (Keep... 2000  02    26    wk10     NA\n# ℹ 24,082 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#strings---separate_wider_-1",
    "href": "Lectures/07_Reshape/index.html#strings---separate_wider_-1",
    "title": "Tidying and Reshaping Data",
    "section": "Strings - separate_wider_",
    "text": "Strings - separate_wider_\n\nBut be mindful of coercion if you need to unite() later\n\n\nbb_long |&gt;\n  separate_wider_delim(cols = date.entered, delim = \"-\",\n                       names = c(\"year\", \"month\", \"day\"), cols_remove = FALSE) |&gt;\n  unite(\"new_date\", c(year, month, day), sep = \"-\", remove = FALSE) |&gt; select(-c(artist, track))\n\n# A tibble: 24,092 × 7\n   new_date   year  month day   date.entered week   rank\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2000-02-26 2000  02    26    2000-02-26   wk1      87\n 2 2000-02-26 2000  02    26    2000-02-26   wk2      82\n 3 2000-02-26 2000  02    26    2000-02-26   wk3      72\n 4 2000-02-26 2000  02    26    2000-02-26   wk4      77\n 5 2000-02-26 2000  02    26    2000-02-26   wk5      87\n 6 2000-02-26 2000  02    26    2000-02-26   wk6      94\n 7 2000-02-26 2000  02    26    2000-02-26   wk7      99\n 8 2000-02-26 2000  02    26    2000-02-26   wk8      NA\n 9 2000-02-26 2000  02    26    2000-02-26   wk9      NA\n10 2000-02-26 2000  02    26    2000-02-26   wk10     NA\n# ℹ 24,082 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/07_Reshape/index.html#learning-more",
    "href": "Lectures/07_Reshape/index.html#learning-more",
    "title": "Tidying and Reshaping Data",
    "section": "Learning more",
    "text": "Learning more\n\nAs always, cheatsheets are available on the tidyverse website(https://rstudio.cloud/learn/cheat-sheets){.external target=“_blank”}\nPackage websites:\n\ntidyr: https://tidyr.tidyverse.org/index.html\n\nThis vignette is dedicated to the pivot_wider() and pivot_longer() functions.\nNext time, more on working with characters and extending separate_",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "html_files/07_Reshape/exercise_solutions.html",
    "href": "html_files/07_Reshape/exercise_solutions.html",
    "title": "Reshaping Data",
    "section": "",
    "text": "These exercises will help you practice applying pivot_wider and pivot_longer, and will also require some use of skills you have previously learned. No new data (other than toy examples) will be introduced.\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "html_files/07_Reshape/exercise_solutions.html#setup",
    "href": "html_files/07_Reshape/exercise_solutions.html#setup",
    "title": "Reshaping Data",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Home",
      "Assignment Solutions",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "html_files/07_Reshape/class_exercises.html",
    "href": "html_files/07_Reshape/class_exercises.html",
    "title": "Reshaping Data",
    "section": "",
    "text": "These exercises will help you practice applying pivot_wider and pivot_longer, and will also require some use of skills you have previously learned. No new data (other than toy examples) will be introduced.\n\n\nI am not loading packages this time. You can load your own as you determine what tools are needed",
    "crumbs": [
      "Home",
      "Assignments",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "html_files/07_Reshape/class_exercises.html#setup",
    "href": "html_files/07_Reshape/class_exercises.html#setup",
    "title": "Reshaping Data",
    "section": "",
    "text": "I am not loading packages this time. You can load your own as you determine what tools are needed",
    "crumbs": [
      "Home",
      "Assignments",
      "07 - Reshaping Data"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html",
    "href": "Lectures/08_Strings/index.html",
    "title": "Characters and Dates",
    "section": "",
    "text": "Separate review\nCharacter data outside of data frame\nRegular expressions\nOverview on dates",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#agenda",
    "href": "Lectures/08_Strings/index.html#agenda",
    "title": "Characters and Dates",
    "section": "Agenda",
    "text": "Agenda\n\n\n\nSeparate review\nCharacter data outside of data frame\nRegular expressions\nOverview on dates",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---last-time",
    "href": "Lectures/08_Strings/index.html#separate---last-time",
    "title": "Characters and Dates",
    "section": "Separate - Last Time",
    "text": "Separate - Last Time\n\nWe discussed how to separate columns as an inverse to unite()\nseparate_ gave us many options\n\nseparate_wider_delim() uses delimiters like unite()\nseparate_wider_position() splits on fixed positions\n\nWe also mentioned separate_wider_regex()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---separate_wider_delim",
    "href": "Lectures/08_Strings/index.html#separate---separate_wider_delim",
    "title": "Characters and Dates",
    "section": "Separate - separate_wider_delim()",
    "text": "Separate - separate_wider_delim()\n\nConsider some (messy) ambulator BP data\n\n\nabpm_demo\n\n# A tibble: 2,500 × 2\n      id asr            \n   &lt;int&gt; &lt;glue&gt;         \n 1     1 20_Male_White  \n 2     2 30_Female_White\n 3     3 30_Male_Black  \n 4     4 28_Male_White  \n 5     5 28_Male_White  \n 6     6 19_Male_Black  \n 7     7 29_Female_Black\n 8     8 24_Male_Black  \n 9     9 22_Female_White\n10    10 23_Male_Black  \n# ℹ 2,490 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---separate_wider_delim-1",
    "href": "Lectures/08_Strings/index.html#separate---separate_wider_delim-1",
    "title": "Characters and Dates",
    "section": "Separate - separate_wider_delim()",
    "text": "Separate - separate_wider_delim()\n\nAs seen, great when multiple variables exist in a single column\n\n\nabpm_demo |&gt;\n  separate_wider_delim(col = asr, delim = \"_\",\n                       names = c(\"age\", \"sex\", \"race\"))\n\n# A tibble: 2,500 × 4\n      id age   sex    race \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n 1     1 20    Male   White\n 2     2 30    Female White\n 3     3 30    Male   Black\n 4     4 28    Male   White\n 5     5 28    Male   White\n 6     6 19    Male   Black\n 7     7 29    Female Black\n 8     8 24    Male   Black\n 9     9 22    Female White\n10    10 23    Male   Black\n# ℹ 2,490 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---separate_wider_delim-2",
    "href": "Lectures/08_Strings/index.html#separate---separate_wider_delim-2",
    "title": "Characters and Dates",
    "section": "Separate - separate_wider_delim()",
    "text": "Separate - separate_wider_delim()\n\nBut what if our splitting column is a mess?\n\n\nabpm_demo\n\n# A tibble: 2,500 × 2\n      id asr                     \n   &lt;int&gt; &lt;glue&gt;                  \n 1     1 20_Male.JunkText.White  \n 2     2 30_Female.JunkText.White\n 3     3 30_Male.JunkText.Black  \n 4     4 28_Male.JunkText.White  \n 5     5 28_Male.JunkText.White  \n 6     6 19_Male.JunkText.Black  \n 7     7 29_Female.JunkText.Black\n 8     8 24_Male.JunkText.Black  \n 9     9 22_Female.JunkText.White\n10    10 23_Male.JunkText.Black  \n# ℹ 2,490 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---separate_wider_delim-3",
    "href": "Lectures/08_Strings/index.html#separate---separate_wider_delim-3",
    "title": "Characters and Dates",
    "section": "Separate - separate_wider_delim()",
    "text": "Separate - separate_wider_delim()\n\nIt takes some effort but we can do it in two (or more steps)\n\n\nabpm_demo |&gt; \n  separate_wider_delim(asr, names = c(\"age\", \"to_split_again\"), delim = \"_\")   #&lt;&lt;\n\n# A tibble: 2,500 × 3\n      id age   to_split_again       \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;                \n 1     1 20    Male.JunkText.White  \n 2     2 30    Female.JunkText.White\n 3     3 30    Male.JunkText.Black  \n 4     4 28    Male.JunkText.White  \n 5     5 28    Male.JunkText.White  \n 6     6 19    Male.JunkText.Black  \n 7     7 29    Female.JunkText.Black\n 8     8 24    Male.JunkText.Black  \n 9     9 22    Female.JunkText.White\n10    10 23    Male.JunkText.Black  \n# ℹ 2,490 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---separate_wider_delim-4",
    "href": "Lectures/08_Strings/index.html#separate---separate_wider_delim-4",
    "title": "Characters and Dates",
    "section": "Separate - separate_wider_delim()",
    "text": "Separate - separate_wider_delim()\n\nIt takes some effort but we can do it in two (or more steps)\n\n\nabpm_demo |&gt; \n  separate_wider_delim(asr, names = c(\"age\", \"to_split_again\"), delim = \"_\") |&gt;\n  separate_wider_delim(to_split_again, names = c(\"sex\", \"race\"), delim = \".JunkText.\") #&lt;&lt;\n\n# A tibble: 2,500 × 4\n      id age   sex    race \n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n 1     1 20    Male   White\n 2     2 30    Female White\n 3     3 30    Male   Black\n 4     4 28    Male   White\n 5     5 28    Male   White\n 6     6 19    Male   Black\n 7     7 29    Female Black\n 8     8 24    Male   Black\n 9     9 22    Female White\n10    10 23    Male   Black\n# ℹ 2,490 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---behind-the-curtain-on-delim",
    "href": "Lectures/08_Strings/index.html#separate---behind-the-curtain-on-delim",
    "title": "Characters and Dates",
    "section": "Separate - Behind the Curtain on delim",
    "text": "Separate - Behind the Curtain on delim\n\nSo what is R doing with the delim argument?\n\n\n\nWe see it takes a single fixed string as a separator, thus two steps for asr",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#separate---how-separate-used-to-work",
    "href": "Lectures/08_Strings/index.html#separate---how-separate-used-to-work",
    "title": "Characters and Dates",
    "section": "Separate - How separate() Used to Work",
    "text": "Separate - How separate() Used to Work\n\nInstead of fixed string, it was a fixed pattern\n\n\n\nThis is what’s going to take us to regular expressions later",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---the-stringr-packages",
    "href": "Lectures/08_Strings/index.html#strings---the-stringr-packages",
    "title": "Characters and Dates",
    "section": "Strings - The stringr packages",
    "text": "Strings - The stringr packages\n\nSince tidyr can only manipulate strings in data frames, we use stringr instead\nstringr has four main functions:\n\nCharacter mainpulation individually or in vectors\nWhitespace manipulation tools\nEncoding and localization\nPattern matching\n\nLike fct_ in forcats, nearly all stringr functions start with str_",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---just-characters",
    "href": "Lectures/08_Strings/index.html#strings---just-characters",
    "title": "Characters and Dates",
    "section": "Strings - Just characters",
    "text": "Strings - Just characters\n\nA string is just a set of characters and there are many ways to print them depending on what you hope to do\n\n\nstring &lt;- \"A string for you\"\nwriteLines(string)\n\nA string for you\n\nprint(string)\n\n[1] \"A string for you\"\n\n\n\nNote the difference between writeLines() (or cat()) and print()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---quoting-quotes",
    "href": "Lectures/08_Strings/index.html#strings---quoting-quotes",
    "title": "Characters and Dates",
    "section": "Strings - Quoting quotes",
    "text": "Strings - Quoting quotes\n\nYou can use double \" or single ' quotes\nBest practice usually says double unless quotes are part of the string\n\n\nwriteLines('This works')\n\nThis works\n\nwriteLines(\"This works too!\")\n\nThis works too!\n\nwriteLines('And we can quote \"quote\" with quotes')\n\nAnd we can quote \"quote\" with quotes\n\n\n\nBut what if both quote types are desired?",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---escaping-with",
    "href": "Lectures/08_Strings/index.html#strings---escaping-with",
    "title": "Characters and Dates",
    "section": "Strings - Escaping with \\",
    "text": "Strings - Escaping with \\\n\nTo include a literal \" or ' you can use \\ symbol to escape it\n\n\nstring &lt;- \"A \\\"string\\\" for you\"\nwriteLines(string)\n\nA \"string\" for you\n\n\n\nEscaping works with all encoded text, even \\ by using \"\\\\\"\n\n\nstring &lt;- \"Escaping with \\\\backslash\\\\ works\"\nwriteLines(string)\n\nEscaping with \\backslash\\ works",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---printed-string-vs-rendered-string",
    "href": "Lectures/08_Strings/index.html#strings---printed-string-vs-rendered-string",
    "title": "Characters and Dates",
    "section": "Strings - Printed String vs Rendered String",
    "text": "Strings - Printed String vs Rendered String\n\nThis can get complex though since print() representations to the console give the raw string code\n\n\ndouble_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\"\nbackslash &lt;- \"\\\\\"\n\ngreat_escape &lt;- c(single_quote, double_quote, backslash); great_escape\n\n[1] \"'\"  \"\\\"\" \"\\\\\"\n\n\n\nstringr has a great functions to see the representation str_view()\n\n\nstr_view(great_escape)\n\n[1] │ '\n[2] │ \"\n[3] │ \\",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---special-characters",
    "href": "Lectures/08_Strings/index.html#strings---special-characters",
    "title": "Characters and Dates",
    "section": "Strings - Special Characters",
    "text": "Strings - Special Characters\n\nOur escaped quotes and slashes are special characters including: new lines \\n, tabs \\t and unicode escapes (\\u or \\U) for non-standard text\n\n\nspec_char &lt;- c(\"one\\ntwo\", \"one\\ttwo\", \"\\u00b5\", \"\\U0001f604\")\nspec_char\n\n[1] \"one\\ntwo\" \"one\\ttwo\" \"µ\"        \"😄\"      \n\nstr_view(spec_char)\n\n[1] │ one\n    │ two\n[2] │ one{\\t}two\n[3] │ µ\n[4] │ 😄\n\n\n\nNote the \\t is viewed in curly braces since it’s a class of whitespace; this makes it much easier to see using str_view()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---making-strings",
    "href": "Lectures/08_Strings/index.html#strings---making-strings",
    "title": "Characters and Dates",
    "section": "Strings - Making Strings",
    "text": "Strings - Making Strings\n\nstringr has many functions to make strings that are improvement on base R functions like paste() and paste0()\nstr_c() does vectorized combinations of strings to return a vector\n\n\nstr_c(\"Make\", \"a\", \"single\", \"string\", sep = \" \")  #`sep` gives the pasting character\n\n[1] \"Make a single string\"\n\nstr_c(\"str_c works \", c(\"within\", \"across\"), \" vectors\")\n\n[1] \"str_c works within vectors\" \"str_c works across vectors\"\n\n\n\nWe can see str_c() follows tidyverse conventions which means it could also work with mutate() although beware of NA\nSee section 14.3.1 and 14.3.2 in R4DS for use in a tibble",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---making-strings-1",
    "href": "Lectures/08_Strings/index.html#strings---making-strings-1",
    "title": "Characters and Dates",
    "section": "Strings - Making Strings",
    "text": "Strings - Making Strings\n\nFor summarise(), str_flatten() will reduce vectors to one string\n\n\ndf &lt;- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"mandarin\"\n)\ndf |&gt;\n  group_by(name) |&gt; \n  summarize(fruits = str_flatten(fruit, collapse = \", \", last = \" and \"))\n\n# A tibble: 3 × 2\n  name    fruits                         \n  &lt;chr&gt;   &lt;chr&gt;                          \n1 Carmen  banana and apple               \n2 Marvin  nectarine                      \n3 Terence cantaloupe, papaya and mandarin",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---yes-we-have-no-bananas",
    "href": "Lectures/08_Strings/index.html#strings---yes-we-have-no-bananas",
    "title": "Characters and Dates",
    "section": "Strings - Yes! We Have No Bananas",
    "text": "Strings - Yes! We Have No Bananas\n\nWe’ll use the fruit dataset to play with stringr some more\n\n\n\n\nstringr::fruit\n\n [1] \"apple\"             \"apricot\"           \"avocado\"          \n [4] \"banana\"            \"bell pepper\"       \"bilberry\"         \n [7] \"blackberry\"        \"blackcurrant\"      \"blood orange\"     \n[10] \"blueberry\"         \"boysenberry\"       \"breadfruit\"       \n[13] \"canary melon\"      \"cantaloupe\"        \"cherimoya\"        \n[16] \"cherry\"            \"chili pepper\"      \"clementine\"       \n[19] \"cloudberry\"        \"coconut\"           \"cranberry\"        \n[22] \"cucumber\"          \"currant\"           \"damson\"           \n[25] \"date\"              \"dragonfruit\"       \"durian\"           \n[28] \"eggplant\"          \"elderberry\"        \"feijoa\"           \n[31] \"fig\"               \"goji berry\"        \"gooseberry\"       \n[34] \"grape\"             \"grapefruit\"        \"guava\"            \n[37] \"honeydew\"          \"huckleberry\"       \"jackfruit\"        \n[40] \"jambul\"            \"jujube\"            \"kiwi fruit\"       \n[43] \"kumquat\"           \"lemon\"             \"lime\"             \n[46] \"loquat\"            \"lychee\"            \"mandarine\"        \n[49] \"mango\"             \"mulberry\"          \"nectarine\"        \n[52] \"nut\"               \"olive\"             \"orange\"           \n[55] \"pamelo\"            \"papaya\"            \"passionfruit\"     \n[58] \"peach\"             \"pear\"              \"persimmon\"        \n[61] \"physalis\"          \"pineapple\"         \"plum\"             \n[64] \"pomegranate\"       \"pomelo\"            \"purple mangosteen\"\n[67] \"quince\"            \"raisin\"            \"rambutan\"         \n[70] \"raspberry\"         \"redcurrant\"        \"rock melon\"       \n[73] \"salal berry\"       \"satsuma\"           \"star fruit\"       \n[76] \"strawberry\"        \"tamarillo\"         \"tangerine\"        \n[79] \"ugli fruit\"        \"watermelon\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---splitting-strings",
    "href": "Lectures/08_Strings/index.html#strings---splitting-strings",
    "title": "Characters and Dates",
    "section": "Strings - Splitting Strings",
    "text": "Strings - Splitting Strings\n\ntidyr function like separate_*_delim() are informed by stringr, so we can split…\n\n\nfruit[c(5,9)]\n\n[1] \"bell pepper\"  \"blood orange\"\n\n\n\nOn delimiters with str_split()\n\n\nstr_split(fruit[c(5,9)], pattern = \" \")\n\n[[1]]\n[1] \"bell\"   \"pepper\"\n\n[[2]]\n[1] \"blood\"  \"orange\"\n\n\n\nNote, we get a list since the length may not be fixed",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---splitting-strings-1",
    "href": "Lectures/08_Strings/index.html#strings---splitting-strings-1",
    "title": "Characters and Dates",
    "section": "Strings - Splitting Strings",
    "text": "Strings - Splitting Strings\n\ntidyr function like separate_*_delim() are informed by stringr, so we can split…\n\n\nfruit[c(5,9)]\n\n[1] \"bell pepper\"  \"blood orange\"\n\n\n\nInto character matrices as well with str_split_fixed\n\n\nstr_split_fixed(fruit[c(5,9)], pattern = \" \", n = 2)\n\n     [,1]    [,2]    \n[1,] \"bell\"  \"pepper\"\n[2,] \"blood\" \"orange\"\n\n\n\nThis could then be converted into a data frame as desired",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---words-within-vectors",
    "href": "Lectures/08_Strings/index.html#strings---words-within-vectors",
    "title": "Characters and Dates",
    "section": "Strings - Words Within Vectors",
    "text": "Strings - Words Within Vectors\n\nInstead of splitting our strings, we can use delimiters to extract strings meeting our pattern with str_detect()\n\n\nstr_detect(fruit, pattern = \" \")\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n[13]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE\n[73]  TRUE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\n\n\nThis gives a boolean just like filter() for easy subsetting\n\n\nmy_fruit &lt;- fruit[str_detect(fruit, pattern = \" \")]",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---working-within-a-string",
    "href": "Lectures/08_Strings/index.html#strings---working-within-a-string",
    "title": "Characters and Dates",
    "section": "Strings - Working Within a String",
    "text": "Strings - Working Within a String\n\nWe can use str_length() to get the number of characters\n\n\nstr_length(my_fruit)\n\n [1] 11 12 12 12 10 10 17 10 11 10 10\n\n\n\nThis can inform str_sub() to extract parts of a string\n\n\nstr_sub(my_fruit, start = 1, end = 10)\n\n [1] \"bell peppe\" \"blood oran\" \"canary mel\" \"chili pepp\" \"goji berry\"\n [6] \"kiwi fruit\" \"purple man\" \"rock melon\" \"salal berr\" \"star fruit\"\n[11] \"ugli fruit\"\n\n\n\nIt can also accept vectorized inputs for sliding windows\n\n\nstr_sub(my_fruit, start = c(1:11), end = str_length(my_fruit))\n\n [1] \"bell pepper\" \"lood orange\" \"nary melon\"  \"li pepper\"   \" berry\"     \n [6] \"fruit\"       \" mangosteen\" \"lon\"         \"rry\"         \"t\"          \n[11] \"\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#strings---questions-remain",
    "href": "Lectures/08_Strings/index.html#strings---questions-remain",
    "title": "Characters and Dates",
    "section": "Strings - Questions Remain",
    "text": "Strings - Questions Remain\n\nBut what if we want to extract or process by a pattern?\nUnlike tidyr why are the arguments pattern instead of delim?\nAnd what was up with this?\n\n\n\nFor all this, we need regular expressions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---the-basics",
    "href": "Lectures/08_Strings/index.html#regexes---the-basics",
    "title": "Characters and Dates",
    "section": "Regexes - The Basics",
    "text": "Regexes - The Basics\n\n\n\nRegexes are a standard way to specify patterns in strings\nCombines literal alphanumeric characters with metacharacters\nAllows for character sets, quantification, and alternation\nCan define anchors and boundaries\nLook like absolute gibberish\n\n\n\n\n\n\n\n\n\n@ThePracticalDev",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---exact-matching",
    "href": "Lectures/08_Strings/index.html#regexes---exact-matching",
    "title": "Characters and Dates",
    "section": "Regexes - Exact Matching",
    "text": "Regexes - Exact Matching\n\nSo far with delim and pattern we’ve used exact matching\n\n\nfruit[str_detect(fruit, pattern = \"berry\")]\n\n [1] \"bilberry\"    \"blackberry\"  \"blueberry\"   \"boysenberry\" \"cloudberry\" \n [6] \"cranberry\"   \"elderberry\"  \"goji berry\"  \"gooseberry\"  \"huckleberry\"\n[11] \"mulberry\"    \"raspberry\"   \"salal berry\" \"strawberry\" \n\n\n\nLike with {\\t}, str_view() indicates the matching pattern with &lt;&gt;\n\n\nstr_view(fruit, pattern = \"berry\")[1:5]\n\n [6] │ bil&lt;berry&gt;\n [7] │ black&lt;berry&gt;\n[10] │ blue&lt;berry&gt;\n[11] │ boysen&lt;berry&gt;\n[19] │ cloud&lt;berry&gt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---alternation",
    "href": "Lectures/08_Strings/index.html#regexes---alternation",
    "title": "Characters and Dates",
    "section": "Regexes - Alternation",
    "text": "Regexes - Alternation\n\nThe vertical bar | specifies a match to one or more alternative patterns\nSo if we want melons, nuts, or oranges\n\n\nstr_view(fruit, pattern = \"melon|nut|orange\")\n\n [9] │ blood &lt;orange&gt;\n[13] │ canary &lt;melon&gt;\n[20] │ coco&lt;nut&gt;\n[52] │ &lt;nut&gt;\n[54] │ &lt;orange&gt;\n[72] │ rock &lt;melon&gt;\n[80] │ water&lt;melon&gt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---starting-with-metacharacters",
    "href": "Lectures/08_Strings/index.html#regexes---starting-with-metacharacters",
    "title": "Characters and Dates",
    "section": "Regexes - Starting with Metacharacters",
    "text": "Regexes - Starting with Metacharacters\n\nThe most powerful metacharacter is . which matches ANY SINGLE character except a new line\n\n\nstr_view(fruit, pattern = \"a...e\")\n\n [1] │ &lt;apple&gt;\n [7] │ bl&lt;ackbe&gt;rry\n[48] │ mand&lt;arine&gt;\n[51] │ nect&lt;arine&gt;\n[62] │ pine&lt;apple&gt;\n[64] │ pomegr&lt;anate&gt;\n[70] │ r&lt;aspbe&gt;rry\n[73] │ sal&lt;al be&gt;rry\n\n\n\nThis matches any “a” and “e” that are separated by three other characters, including whitespace characters",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---character-classes",
    "href": "Lectures/08_Strings/index.html#regexes---character-classes",
    "title": "Characters and Dates",
    "section": "Regexes - Character Classes",
    "text": "Regexes - Character Classes\n\nIf . is too broad, we can define character classes using []\nLet’s find all adjacent vowels\n\n\ntwo_vowels &lt;- str_view(fruit, pattern = \"[aeiou][aeiou]\")\nlength(two_vowels)\n\n[1] 25\n\nhead(two_vowels)\n\n [9] │ bl&lt;oo&gt;d orange\n[10] │ bl&lt;ue&gt;berry\n[12] │ br&lt;ea&gt;dfr&lt;ui&gt;t\n[14] │ cantal&lt;ou&gt;pe\n[19] │ cl&lt;ou&gt;dberry\n[26] │ dragonfr&lt;ui&gt;t\n\n\n\nWe can also match ranges e.g. [a-e] is the same as [abcde]",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---character-classes-1",
    "href": "Lectures/08_Strings/index.html#regexes---character-classes-1",
    "title": "Characters and Dates",
    "section": "Regexes - Character Classes",
    "text": "Regexes - Character Classes\n\nWe can negate a character class with ^ right after the left bracket ( [^ )\nLet’s find all s that are preceded by a consonants i.e. NOT a vowel\n\n\nstr_view(fruit, pattern = \"[^aeiou]s\")\n\n[11] │ bo&lt;ys&gt;enberry\n[24] │ da&lt;ms&gt;on\n[57] │ pa&lt;ss&gt;ionfruit\n[60] │ pe&lt;rs&gt;immon\n[61] │ ph&lt;ys&gt;alis\n[74] │ sa&lt;ts&gt;uma\n\n\n\n\n\n\n\n\nImportant\n\n\nRemember, character classes still only count as single characters",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---dedicated-character-classes",
    "href": "Lectures/08_Strings/index.html#regexes---dedicated-character-classes",
    "title": "Characters and Dates",
    "section": "Regexes - Dedicated Character Classes",
    "text": "Regexes - Dedicated Character Classes\n\nSome character classes are common enough to have dedicated metacharacters including:\n\n\\w for any Unicode character i.e. [A-Za-z0-9_]\nNote the implication on capitalization\n\\d for any numeric\n\\s for any whitespace including space, tab, and newline characters\n\\t and \\n will find tabs/newlines respectively\n\nYou can get negation for these by using capitals\n\nIf \\d==[0-9] then \\D==[^0-9]",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---quantifiers",
    "href": "Lectures/08_Strings/index.html#regexes---quantifiers",
    "title": "Characters and Dates",
    "section": "Regexes - Quantifiers",
    "text": "Regexes - Quantifiers\n\nQuantifiers control how many times a pattern can match\nThis can be done explicitly using {} e.g. let’s find fruits with “ss”\n\n\nstr_view(fruit, pattern = \"s{2}\")\n\n[57] │ pa&lt;ss&gt;ionfruit\n\n\n\nFor finer quantification control:\n\n{n} for exactly n\n{n,} for at least n\n{,m} for at most m\n{n,m} for between n and m inclusively",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---dedicated-quantifiers",
    "href": "Lectures/08_Strings/index.html#regexes---dedicated-quantifiers",
    "title": "Characters and Dates",
    "section": "Regexes - Dedicated Quantifiers",
    "text": "Regexes - Dedicated Quantifiers\n\nSome useful quantifiers have their own dedicated characters:\n\n* for 0 or more\n+ for 1 or more\n? for 0 or 1 only\n\nSo for every fruit with a ‘c’ and ‘r’ separated by 0 or more characters\n\n\nhead(str_view(fruit, pattern = \"c.*r\"))\n\n [7] │ bla&lt;ckberr&gt;y\n [8] │ bla&lt;ckcurr&gt;ant\n[13] │ &lt;canar&gt;y melon\n[15] │ &lt;cher&gt;imoya\n[16] │ &lt;cherr&gt;y\n[17] │ &lt;chili pepper&gt;",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---word-boundaries",
    "href": "Lectures/08_Strings/index.html#regexes---word-boundaries",
    "title": "Characters and Dates",
    "section": "Regexes - Word Boundaries",
    "text": "Regexes - Word Boundaries\n\nTo specify a pattern occurrence at the beginning or end of a string use ^ and $ respectively\nWe can find any ‘le’ as you’d expect:\n\n\nstr_view(fruit, \"le\")\n\n [1] │ app&lt;le&gt;\n[18] │ c&lt;le&gt;mentine\n[38] │ huck&lt;le&gt;berry\n[44] │ &lt;le&gt;mon\n[62] │ pineapp&lt;le&gt;\n[66] │ purp&lt;le&gt; mangosteen\n\n\n\nBut we use ^ to only get ‘le’ at the beginning of the string\n\n\nstr_view(fruit, \"^le\")\n\n[44] │ &lt;le&gt;mon",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---escaping",
    "href": "Lectures/08_Strings/index.html#regexes---escaping",
    "title": "Characters and Dates",
    "section": "Regexes - Escaping",
    "text": "Regexes - Escaping\n\nIn order to explicitly look for characters that serve as a metacharacter, you can use \\ to escape just like with quotes\n\n\nstring_curr &lt;- \"Let's match the price for $4.99 using the $ and the numbers\"\n\nmatch &lt;- str_view(string_curr, pattern = \"\\$[0-9]\\.[0-9]{2}\")\n\n\n\nmatch\n\n\n\nError in eval(expr, envir, enclos): '\\$' is an unrecognized escape in character string (&lt;input&gt;:1:18)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---escaping-the-right-way",
    "href": "Lectures/08_Strings/index.html#regexes---escaping-the-right-way",
    "title": "Characters and Dates",
    "section": "Regexes - Escaping the Right Way",
    "text": "Regexes - Escaping the Right Way\n\nWe use the backslash \\ to escape special characters…but \\ is itself a special character used by R (and other languages) for escaping\nSo we need to escape the backslash and use \\\\$ instead\n\nThe first \\ tells R to treat the second backslash as a literal character\nThis means \\$ can then be seen by the regex engine to look for the literal $\n\n\n\nstr_view(string_curr, pattern = \"\\\\$[0-9]\\\\.[0-9]{2}\")\n\n[1] │ Let's match the price for &lt;$4.99&gt; using the $ and numbers",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---grouping",
    "href": "Lectures/08_Strings/index.html#regexes---grouping",
    "title": "Characters and Dates",
    "section": "Regexes - Grouping",
    "text": "Regexes - Grouping\n\nParentheses can capture sub-components of a string during a match\nThey can also be used to overwrite precedence with alternation\nThey do not match anything per se but can be use to identify their encapsulated pattern for later use called back referencing\nThese are referenced using \\1 for the first set of capturing parentheses, \\2 for the second, etc",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---grouping-1",
    "href": "Lectures/08_Strings/index.html#regexes---grouping-1",
    "title": "Characters and Dates",
    "section": "Regexes - Grouping",
    "text": "Regexes - Grouping\n\nFor example, we can find all fruit that has the same repeated consecutive pairs of letters\n\n\nstr_view(fruit, \"(..)\\\\1\")  #Don't forget to escape the backslash!\n\n [4] │ b&lt;anan&gt;a\n[20] │ &lt;coco&gt;nut\n[22] │ &lt;cucu&gt;mber\n[41] │ &lt;juju&gt;be\n[56] │ &lt;papa&gt;ya\n[73] │ s&lt;alal&gt; berry\n\n\n\nParentheses have several uses in regular expression",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions",
    "href": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions",
    "title": "Characters and Dates",
    "section": "Regexes - The Common stringr Functions",
    "text": "Regexes - The Common stringr Functions\n\nAny stringr function that has a pattern argument can use a regular expression\nRecall my_fruit which has all the fruits that have a space character\n\n\nmy_fruit\n\n [1] \"bell pepper\"       \"blood orange\"      \"canary melon\"     \n [4] \"chili pepper\"      \"goji berry\"        \"kiwi fruit\"       \n [7] \"purple mangosteen\" \"rock melon\"        \"salal berry\"      \n[10] \"star fruit\"        \"ugli fruit\"       \n\n\n\nLet’s try out the following pattern (\\w)\\1 to find consecutive pairs of the same letter again",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-1",
    "href": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-1",
    "title": "Characters and Dates",
    "section": "Regexes - The Common stringr Functions",
    "text": "Regexes - The Common stringr Functions\n\nstr_detect() returns a boolean vector indicating whether the string matched the pattern\n\n\nstr_detect(my_fruit, \"(\\\\w)\\\\1\")\n\n [1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE\n\n\n\n\nmy_fruit[str_detect(my_fruit, \"(\\\\w)\\\\1\")]\n\n[1] \"bell pepper\"       \"blood orange\"      \"chili pepper\"     \n[4] \"goji berry\"        \"purple mangosteen\" \"salal berry\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-2",
    "href": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-2",
    "title": "Characters and Dates",
    "section": "Regexes - The Common stringr Functions",
    "text": "Regexes - The Common stringr Functions\n\nstr_count() counts the number of pattern matches within the string\n\n\nstr_count(my_fruit, \"(\\\\w)\\\\1\")\n\n [1] 2 1 0 1 1 0 1 0 1 0 0\n\n\n\n\nstr_view(my_fruit, \"(\\\\w)\\\\1\")\n\n[1] │ be&lt;ll&gt; pe&lt;pp&gt;er\n[2] │ bl&lt;oo&gt;d orange\n[4] │ chili pe&lt;pp&gt;er\n[5] │ goji be&lt;rr&gt;y\n[7] │ purple mangost&lt;ee&gt;n\n[9] │ salal be&lt;rr&gt;y",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-3",
    "href": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-3",
    "title": "Characters and Dates",
    "section": "Regexes - The Common stringr Functions",
    "text": "Regexes - The Common stringr Functions\n\nstr_locate() gives the first position of a pattern\n\n\nstr_locate(my_fruit, \"(\\\\w)\\\\1\")\n\n      start end\n [1,]     3   4\n [2,]     3   4\n [3,]    NA  NA\n [4,]     9  10\n [5,]     8   9\n [6,]    NA  NA\n [7,]    15  16\n [8,]    NA  NA\n [9,]     9  10\n[10,]    NA  NA\n[11,]    NA  NA",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-4",
    "href": "Lectures/08_Strings/index.html#regexes---the-common-stringr-functions-4",
    "title": "Characters and Dates",
    "section": "Regexes - The Common stringr Functions",
    "text": "Regexes - The Common stringr Functions\n\nstr_locate_all() locates all matches\n\n\nstr_locate_all(my_fruit, \"(\\\\w)\\\\1\")\n\n[[1]]\n     start end\n[1,]     3   4\n[2,]     8   9\n\n[[2]]\n     start end\n[1,]     3   4\n\n[[3]]\n     start end\n\n[[4]]\n     start end\n[1,]     9  10\n\n[[5]]\n     start end\n[1,]     8   9\n\n[[6]]\n     start end\n\n[[7]]\n     start end\n[1,]    15  16\n\n[[8]]\n     start end\n\n[[9]]\n     start end\n[1,]     9  10\n\n[[10]]\n     start end\n\n[[11]]\n     start end",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---extraction-functions",
    "href": "Lectures/08_Strings/index.html#regexes---extraction-functions",
    "title": "Characters and Dates",
    "section": "Regexes - Extraction Functions",
    "text": "Regexes - Extraction Functions\n\nSubstring extraction is possible with str_extract() and str_extract_all()\nImagine a collaborator gave you a file with some phone number data\n\n\nmessy_phone &lt;- c(\n  \"219-733-8965\", \n  \"Erroneous text\",\n  \"329 293 8753\", \n  \"Work: 579-499-7527; Home: 543.355.3679\"\n)\n\n\nSet a pattern to pull a 10 digit number with -, ., or a space as delimiters\n\n\nphone_ptrn &lt;- \"([2-9]\\\\d{2})[\\\\-\\\\. ](\\\\d{3})[\\\\-\\\\. ](\\\\d{4})\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---extraction-functions-1",
    "href": "Lectures/08_Strings/index.html#regexes---extraction-functions-1",
    "title": "Characters and Dates",
    "section": "Regexes - Extraction Functions",
    "text": "Regexes - Extraction Functions\n\nstr_extract() gives the first valid pattern match\n\n\nstr_extract(messy_phone, phone_ptrn)\n\n[1] \"219-733-8965\" NA             \"329 293 8753\" \"579-499-7527\"\n\n\n\nstr_extract_all() pulls all matches\n\n\nstr_extract_all(messy_phone, phone_ptrn)\n\n[[1]]\n[1] \"219-733-8965\"\n\n[[2]]\ncharacter(0)\n\n[[3]]\n[1] \"329 293 8753\"\n\n[[4]]\n[1] \"579-499-7527\" \"543.355.3679\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---extraction-functions-2",
    "href": "Lectures/08_Strings/index.html#regexes---extraction-functions-2",
    "title": "Characters and Dates",
    "section": "Regexes - Extraction Functions",
    "text": "Regexes - Extraction Functions\n\nPay attention to when you get a vector, matrix, or list returned\nWe can clean things up to a vector using unlist()\n\n\nmessy_phone_vector &lt;- messy_phone |&gt;\n  str_extract_all(phone_ptrn) |&gt;\n  unlist()\n  \nmessy_phone_vector\n\n[1] \"219-733-8965\" \"329 293 8753\" \"579-499-7527\" \"543.355.3679\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---replacement-functions",
    "href": "Lectures/08_Strings/index.html#regexes---replacement-functions",
    "title": "Characters and Dates",
    "section": "Regexes - Replacement Functions",
    "text": "Regexes - Replacement Functions\n\nA great application of regular expression is replacing matched patterns with another string; in stringr we use str_replace() with a new replacement argument to support the pattern argument\n\n\n\n\nLet’s make our messy phone vector cleaner so all outnumbers are separated by -\n\n\n\nstr_replace(messy_phone_vector,\n            pattern = \" |\\\\.\",\n            replacement = \"-\")\n\n[1] \"219-733-8965\" \"329-293 8753\" \"579-499-7527\" \"543-355.3679\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---replacement-functions-1",
    "href": "Lectures/08_Strings/index.html#regexes---replacement-functions-1",
    "title": "Characters and Dates",
    "section": "Regexes - Replacement Functions",
    "text": "Regexes - Replacement Functions\n\nAs expected, use str_replace_all to replace all occurrences of the pattern in the string elements of the vector\n\n\nclean_phone_vector &lt;- messy_phone_vector |&gt;\n  str_replace_all(pattern = \" |\\\\.\",\n                  replacement = \"-\")\n\nstr_view(clean_phone_vector)\n\n[1] │ 219-733-8965\n[2] │ 329-293-8753\n[3] │ 579-499-7527\n[4] │ 543-355-3679",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---back-to-tidyr",
    "href": "Lectures/08_Strings/index.html#regexes---back-to-tidyr",
    "title": "Characters and Dates",
    "section": "Regexes - Back to tidyr",
    "text": "Regexes - Back to tidyr\n\nFinally, we can return to separate_wider_regex()\nThe patterns argument is a named vector of pattern matches for the output variables and separating delimiters\n\n\nseparate_wider_regex(abpm_demo, cols = asr, \n                     patterns = c(age = \"\\\\d+\", \"_\", \n                                  sex = \"[A-Za-z]+\", \"\\\\.JunkText\\\\.\", \n                                  race = \".*\")) |&gt; slice(1:5)\n\n# A tibble: 5 × 4\n     id age   sex    race \n  &lt;int&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n1     1 20    Male   White\n2     2 30    Female White\n3     3 30    Male   Black\n4     4 28    Male   White\n5     5 28    Male   White",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---yes-theres-more",
    "href": "Lectures/08_Strings/index.html#regexes---yes-theres-more",
    "title": "Characters and Dates",
    "section": "Regexes - Yes, There’s More",
    "text": "Regexes - Yes, There’s More\n\nThere are several more aspects we didn’t touch on including\n\nUsing back references in replacement\nLook ahead and look behind assertions\nLazy vs greedy evaluation\nComparison to base R versions like grep() and gsub()\n\nFor some more details check out https://www.regular-expressions.info/ or the stringr vignette on regular expressions",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#regexes---powerful-but-confusing",
    "href": "Lectures/08_Strings/index.html#regexes---powerful-but-confusing",
    "title": "Characters and Dates",
    "section": "Regexes - Powerful but Confusing",
    "text": "Regexes - Powerful but Confusing\n\nFor example, this returns every fruit that has a consecutive letter pair except for the rr in “berry” and only in the middle of a word\n\n\nstr_view(fruit, pattern = \"((?&lt;!\\\\b)(?&lt;!be)((\\\\w)\\\\3)(?!y))(?=\\\\B)\")\n\n [1] │ a&lt;pp&gt;le\n [5] │ bell pe&lt;pp&gt;er\n [8] │ blackcu&lt;rr&gt;ant\n [9] │ bl&lt;oo&gt;d orange\n[17] │ chili pe&lt;pp&gt;er\n[23] │ cu&lt;rr&gt;ant\n[28] │ e&lt;gg&gt;plant\n[33] │ g&lt;oo&gt;seberry\n[57] │ pa&lt;ss&gt;ionfruit\n[60] │ persi&lt;mm&gt;on\n[62] │ pinea&lt;pp&gt;le\n[66] │ purple mangost&lt;ee&gt;n\n[71] │ redcu&lt;rr&gt;ant\n[77] │ tamari&lt;ll&gt;o",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---frustrating-for-everyone",
    "href": "Lectures/08_Strings/index.html#dates---frustrating-for-everyone",
    "title": "Characters and Dates",
    "section": "Dates - Frustrating for Everyone",
    "text": "Dates - Frustrating for Everyone\n\n\n\nDates are complicated by several factors:\n\nNo set origin\nUneven days in a year\nTime zones\nDaylight savings\n\nThe lubridate package can help immensely",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---starting-today-and-now",
    "href": "Lectures/08_Strings/index.html#dates---starting-today-and-now",
    "title": "Characters and Dates",
    "section": "Dates - Starting Today and Now",
    "text": "Dates - Starting Today and Now\n\nStart by getting today’s date with base R or lubridate\n\n\nSys.Date()\n\n[1] \"2024-07-21\"\n\nlubridate::today()\n\n[1] \"2024-07-21\"\n\n\n\nBoth of these are functionally identical as date class\n\n\nstr(today())\n\n Date[1:1], format: \"2024-07-21\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---starting-today-and-now-1",
    "href": "Lectures/08_Strings/index.html#dates---starting-today-and-now-1",
    "title": "Characters and Dates",
    "section": "Dates - Starting Today and Now",
    "text": "Dates - Starting Today and Now\n\nUse Sys.time() or now() to get the current date-time\n\n\nSys.time()\n\n[1] \"2024-07-21 20:25:54 CDT\"\n\nlubridate::now()\n\n[1] \"2024-07-21 20:25:54 CDT\"\n\n\n\nThese are a special class referred to as a POSIX or POSIXct\n\n\nstr(now())\n\n POSIXct[1:1], format: \"2024-07-21 20:25:54\"\n\n\n\nNote the inclusion of our time zone",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---parsing-dates",
    "href": "Lectures/08_Strings/index.html#dates---parsing-dates",
    "title": "Characters and Dates",
    "section": "Dates - Parsing Dates",
    "text": "Dates - Parsing Dates\n\nR representations of dates follow ISO8601 i.e. YYYY-MM-DD\nDate-time is “YYYY-MM-DD HH:MM:SS\nString representations of dates are varied, lubridate can tell R what to expect with a family of parsing functions for year, month, and day along with hour, minute, and seconds\nSupplying a date or date-time string to a ymd or ymd_hms function coerces a date in the expected ISO8601",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---parsing-dates-1",
    "href": "Lectures/08_Strings/index.html#dates---parsing-dates-1",
    "title": "Characters and Dates",
    "section": "Dates - Parsing Dates",
    "text": "Dates - Parsing Dates\n\nMany orders and delimiters can be accepted (see the list)\n\n\nymd(\"2004/2/11\")\n\n[1] \"2004-02-11\"\n\ndmy(\"11-2-04\")\n\n[1] \"2004-02-11\"\n\nmdy(\"021104\")\n\n[1] \"2004-02-11\"\n\nymd_hm(\"04_2_11 18:02\")\n\n[1] \"2004-02-11 18:02:00 UTC\"\n\n\n\nSupply a time zone to force a date into a date-time\n\n\nmdy(\"2/11/2004\", tz = \"UTC\")\n\n[1] \"2004-02-11 UTC\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---parsing-dates-in-a-data-frame",
    "href": "Lectures/08_Strings/index.html#dates---parsing-dates-in-a-data-frame",
    "title": "Characters and Dates",
    "section": "Dates - Parsing Dates in a Data Frame",
    "text": "Dates - Parsing Dates in a Data Frame\n\nOther helpers create date data within data frames like make_datetime()\n\n\nfirst_flights &lt;- flights |&gt;\n  select(year, month, day, hour, minute) |&gt;\n  slice(1:5)\n\nfirst_flights |&gt; mutate(depart_time = make_datetime(year, month, day, hour, minute))  #&lt;&lt;\n\n# A tibble: 5 × 6\n   year month   day  hour minute depart_time        \n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n1  2013     1     1     5     15 2013-01-01 05:15:00\n2  2013     1     1     5     29 2013-01-01 05:29:00\n3  2013     1     1     5     40 2013-01-01 05:40:00\n4  2013     1     1     5     45 2013-01-01 05:45:00\n5  2013     1     1     6      0 2013-01-01 06:00:00",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---the-power-of-dates",
    "href": "Lectures/08_Strings/index.html#dates---the-power-of-dates",
    "title": "Characters and Dates",
    "section": "Dates - The Power of Dates",
    "text": "Dates - The Power of Dates\n\nProperly formatted dates and times have extensive utility\n\n\nggplot(flights, aes(x = depart_time)) + \n  geom_freqpoly(binwidth = 86400) + \n  labs(title = \"Number of Flights per Day - 2013\") + \n  theme_bw()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---the-power-of-dates-1",
    "href": "Lectures/08_Strings/index.html#dates---the-power-of-dates-1",
    "title": "Characters and Dates",
    "section": "Dates - The Power of Dates",
    "text": "Dates - The Power of Dates\n\nProperly formatted dates and times have extensive utility\n\n\nfilter(flights, depart_time &lt; ymd(20130602) & depart_time &gt; ymd(20130601)) |&gt;\nggplot(aes(x = depart_time)) + \n  geom_freqpoly(binwidth = 600) + \n  labs(title = \"Number of Flights Every 10 Minutes - 06/01/2013\") + \n  theme_bw()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---date-components",
    "href": "Lectures/08_Strings/index.html#dates---date-components",
    "title": "Characters and Dates",
    "section": "Dates - Date Components",
    "text": "Dates - Date Components\n\nComponents of a date-time can be extracted and modified\n\n\ndeparture_time &lt;- ymd_hms(\"2024-10-31 18:30:00\")\ndeparture_time\n\n[1] \"2024-10-31 18:30:00 UTC\"\n\nyear(departure_time)\n\n[1] 2024\n\nday(departure_time)\n\n[1] 31\n\nhour(departure_time)\n\n[1] 18\n\nhour(departure_time) &lt;- 20\ndeparture_time\n\n[1] \"2024-10-31 20:30:00 UTC\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---date-math",
    "href": "Lectures/08_Strings/index.html#dates---date-math",
    "title": "Characters and Dates",
    "section": "Dates - Date Math",
    "text": "Dates - Date Math\n\nComponents can also be used for date math\n\n\ndob &lt;- ymd(\"1945-12-31\")\nyear(today()) - year(dob)\n\n[1] 79\n\n\n\nBut we can do better since the birthday isn’t until later in the year\n\n\nage_interval &lt;- today() - dob\nage_interval\n\nTime difference of 28692 days\n\nfloor(as.numeric(age_interval) / 365.25)\n\n[1] 78\n\n\n\nBut this is still brutish",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---working-with-intervals",
    "href": "Lectures/08_Strings/index.html#dates---working-with-intervals",
    "title": "Characters and Dates",
    "section": "Dates - Working with Intervals",
    "text": "Dates - Working with Intervals\n\nlubridate has an interval class that is much more pliable for math\n\n\nage_interval &lt;- interval(dob, today()); age_interval\n\n[1] 1945-12-31 UTC--2024-07-21 UTC\n\n\n\nIntervals are specific but can be combined with more general time spans of periods and durations with durations being more precise\n\n\nyears(1) #A period of 1 year\n\n[1] \"1y 0m 0d 0H 0M 0S\"\n\ndyears(1) #A duration of 1 year\n\n[1] \"31557600s (~1 years)\"\n\n\n\nage_interval / years(1)\n\n[1] 78.55464\n\n\n\nDurations can also work with difftime objects from base R",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---time-zones",
    "href": "Lectures/08_Strings/index.html#dates---time-zones",
    "title": "Characters and Dates",
    "section": "Dates - Time Zones",
    "text": "Dates - Time Zones\n\nAny POSIXct class needs a time zone associated with its HMS component; UTC (GMT) is the default\n\n\ndate_curr &lt;- ymd_hm(\"2020-02-20 12:00\"); date_curr\n\n[1] \"2020-02-20 12:00:00 UTC\"\n\n\n\nTime zones can be changed but you need to know what they are\n\n\nSys.timezone()  #Get the time zone for your current locale\n\n[1] \"America/Chicago\"\n\ntz(date_curr) &lt;- Sys.timezone(); date_curr\n\n[1] \"2020-02-20 12:00:00 CST\"\n\n\n\nymd_hm(\"2020-07-20 12:00\", tz = \"America/Chicago\")  #Be careful of Daylight Savings\n\n[1] \"2020-07-20 12:00:00 CDT\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---why-so-much-effort",
    "href": "Lectures/08_Strings/index.html#dates---why-so-much-effort",
    "title": "Characters and Dates",
    "section": "Dates - Why So Much Effort",
    "text": "Dates - Why So Much Effort\n\nDates and times have geographical and geopolitical considerations\n\n\n#Because the local time and hour in Birmingham\nnow(); hour(now())\n\n[1] \"2024-07-21 20:25:57 CDT\"\n\n\n[1] 20\n\n\n\n#Is different than the local time and hour for Coordinated Time\nnow(tzone = \"UTC\"); hour(now(tzone = \"UTC\"))\n\n[1] \"2024-07-22 01:25:57 UTC\"\n\n\n[1] 1\n\n\n\n#Even though they're the same time\nnow() - now(tzone = \"UTC\")\n\nTime difference of -3.528595e-05 secs",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#dates---why-so-much-effort-1",
    "href": "Lectures/08_Strings/index.html#dates---why-so-much-effort-1",
    "title": "Characters and Dates",
    "section": "Dates - Why So Much Effort",
    "text": "Dates - Why So Much Effort\n\nKnowing the calendar is critical\n\n\nymd(\"2024-02-29\") #2024 was a leap year\n\n[1] \"2024-02-29\"\n\nymd(\"1997-02-29\") #But 1997 was not\n\nWarning: 1 failed to parse.\n\n\n[1] NA\n\n\n\nAs is having a unified Unix Epoch\n\n\norigin\n\n[1] \"1970-01-01 UTC\"\n\n\n\nDates and times are inherently confusing but with some time and effort can be leveraged in powerfully meaningful ways",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/08_Strings/index.html#learning-more",
    "href": "Lectures/08_Strings/index.html#learning-more",
    "title": "Characters and Dates",
    "section": "Learning More",
    "text": "Learning More\n\nAgain, for more on regular expressions, check out https://www.regular-expressions.info/ or the stringr vignette on regular expressions\nThe lubridate vignette can be valuable as is the cheat sheets\nNext time, I/O and handling multiple tables",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "html_files/08_Strings/exercises_solutions.html",
    "href": "html_files/08_Strings/exercises_solutions.html",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "These exercises will help you practice applying separate_*, unite, regular expressions, and a bit with dates. You will use a messy dataset with information about cardiovascular disease (CVD).\n\n\nThese were the packages used for the exercises.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(gtsummary)\n\n#StandWithUkraine\n\n\n\n\n\n\ncvd_messy_descr &lt;-\n  c(\"ID\" = 'Participant identification',\n    \"question_age\" = \"Question: how old are you / when where you born? Participants 51 or older answered the second question.\",\n    \"question_substance\" = 'Question: do you smoke or drink?',\n    \"question_bp\" = 'Question: what is your blood pressure? Are you taking medications to lower your blood pressure?',\n    \"labs\" = 'A collection of laboratory values concatenated into a single string. Notably, the order of lab values is random',\n    \"cvd_fup\" = 'Report of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview')\n\n# the enframe function transforms a vector into a tibble,\ntibble::enframe(cvd_messy_descr) |&gt; \n  gt::gt(rowname_col = \"name\") |&gt;\n  gt::tab_stubhead(label = 'Variable name') |&gt; \n  gt::cols_label(value = 'Variable description') |&gt; \n  gt::cols_align('left') |&gt; \n  gt::tab_header(title = 'Description of messy cardiovascular disease data')\n\n\n\n\n\n\n\nDescription of messy cardiovascular disease data\n\n\nVariable name\nVariable description\n\n\n\n\nID\nParticipant identification\n\n\nquestion_age\nQuestion: how old are you / when where you born? Participants 51 or older answered the second question.\n\n\nquestion_substance\nQuestion: do you smoke or drink?\n\n\nquestion_bp\nQuestion: what is your blood pressure? Are you taking medications to lower your blood pressure?\n\n\nlabs\nA collection of laboratory values concatenated into a single string. Notably, the order of lab values is random\n\n\ncvd_fup\nReport of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview\n\n\n\n\n\n\n\n\n\n\nLoad in the dataset which is called cvd_messy.\n\ncvd_messy &lt;- readr::read_rds('data/cvd_messy.rds')\n\ncvd_messy"
  },
  {
    "objectID": "html_files/08_Strings/exercises_solutions.html#setup",
    "href": "html_files/08_Strings/exercises_solutions.html#setup",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "These were the packages used for the exercises.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(gtsummary)\n\n#StandWithUkraine"
  },
  {
    "objectID": "html_files/08_Strings/exercises_solutions.html#data-dictionary",
    "href": "html_files/08_Strings/exercises_solutions.html#data-dictionary",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "cvd_messy_descr &lt;-\n  c(\"ID\" = 'Participant identification',\n    \"question_age\" = \"Question: how old are you / when where you born? Participants 51 or older answered the second question.\",\n    \"question_substance\" = 'Question: do you smoke or drink?',\n    \"question_bp\" = 'Question: what is your blood pressure? Are you taking medications to lower your blood pressure?',\n    \"labs\" = 'A collection of laboratory values concatenated into a single string. Notably, the order of lab values is random',\n    \"cvd_fup\" = 'Report of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview')\n\n# the enframe function transforms a vector into a tibble,\ntibble::enframe(cvd_messy_descr) |&gt; \n  gt::gt(rowname_col = \"name\") |&gt;\n  gt::tab_stubhead(label = 'Variable name') |&gt; \n  gt::cols_label(value = 'Variable description') |&gt; \n  gt::cols_align('left') |&gt; \n  gt::tab_header(title = 'Description of messy cardiovascular disease data')\n\n\n\n\n\n\n\nDescription of messy cardiovascular disease data\n\n\nVariable name\nVariable description\n\n\n\n\nID\nParticipant identification\n\n\nquestion_age\nQuestion: how old are you / when where you born? Participants 51 or older answered the second question.\n\n\nquestion_substance\nQuestion: do you smoke or drink?\n\n\nquestion_bp\nQuestion: what is your blood pressure? Are you taking medications to lower your blood pressure?\n\n\nlabs\nA collection of laboratory values concatenated into a single string. Notably, the order of lab values is random\n\n\ncvd_fup\nReport of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview"
  },
  {
    "objectID": "html_files/08_Strings/exercises_solutions.html#import",
    "href": "html_files/08_Strings/exercises_solutions.html#import",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "Load in the dataset which is called cvd_messy.\n\ncvd_messy &lt;- readr::read_rds('data/cvd_messy.rds')\n\ncvd_messy"
  },
  {
    "objectID": "downloads.html#characters-and-dates",
    "href": "downloads.html#characters-and-dates",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "html_files/08_Strings/class_exercises.html",
    "href": "html_files/08_Strings/class_exercises.html",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "These exercises will help you practice applying separate_*, unite, regular expressions, and a bit with dates. You will use a messy dataset with information about cardiovascular disease (CVD).\n\n\nAgain, I am not loading packages. You can load your own as you determine what tools are needed.\n\n\n\n\ncvd_messy_descr &lt;-\n  c(\"ID\" = 'Participant identification',\n    \"question_age\" = \"Question: how old are you / when where you born? Participants 51 or older answered the second question.\",\n    \"question_substance\" = 'Question: do you smoke or drink?',\n    \"question_bp\" = 'Question: what is your blood pressure? Are you taking medications to lower your blood pressure?',\n    \"labs\" = 'A collection of laboratory values concatenated into a single string. Notably, the order of lab values is random',\n    \"cvd_fup\" = 'Report of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview')\n\n# the enframe function transforms a vector into a tibble,\ntibble::enframe(cvd_messy_descr) |&gt; \n  gt::gt(rowname_col = \"name\") |&gt;\n  gt::tab_stubhead(label = 'Variable name') |&gt; \n  gt::cols_label(value = 'Variable description') |&gt; \n  gt::cols_align('left') |&gt; \n  gt::tab_header(title = 'Description of messy cardiovascular disease data')\n\n\n\n\n\n\n\nDescription of messy cardiovascular disease data\n\n\nVariable name\nVariable description\n\n\n\n\nID\nParticipant identification\n\n\nquestion_age\nQuestion: how old are you / when where you born? Participants 51 or older answered the second question.\n\n\nquestion_substance\nQuestion: do you smoke or drink?\n\n\nquestion_bp\nQuestion: what is your blood pressure? Are you taking medications to lower your blood pressure?\n\n\nlabs\nA collection of laboratory values concatenated into a single string. Notably, the order of lab values is random\n\n\ncvd_fup\nReport of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview\n\n\n\n\n\n\n\n\n\n\nLoad in the dataset which is called cvd_messy.\n\ncvd_messy &lt;- readr::read_rds('data/cvd_messy.rds')\ncvd_messy",
    "crumbs": [
      "Home",
      "Assignments",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "html_files/08_Strings/class_exercises.html#setup",
    "href": "html_files/08_Strings/class_exercises.html#setup",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "Again, I am not loading packages. You can load your own as you determine what tools are needed.",
    "crumbs": [
      "Home",
      "Assignments",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "html_files/08_Strings/class_exercises.html#data-dictionary",
    "href": "html_files/08_Strings/class_exercises.html#data-dictionary",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "cvd_messy_descr &lt;-\n  c(\"ID\" = 'Participant identification',\n    \"question_age\" = \"Question: how old are you / when where you born? Participants 51 or older answered the second question.\",\n    \"question_substance\" = 'Question: do you smoke or drink?',\n    \"question_bp\" = 'Question: what is your blood pressure? Are you taking medications to lower your blood pressure?',\n    \"labs\" = 'A collection of laboratory values concatenated into a single string. Notably, the order of lab values is random',\n    \"cvd_fup\" = 'Report of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview')\n\n# the enframe function transforms a vector into a tibble,\ntibble::enframe(cvd_messy_descr) |&gt; \n  gt::gt(rowname_col = \"name\") |&gt;\n  gt::tab_stubhead(label = 'Variable name') |&gt; \n  gt::cols_label(value = 'Variable description') |&gt; \n  gt::cols_align('left') |&gt; \n  gt::tab_header(title = 'Description of messy cardiovascular disease data')\n\n\n\n\n\n\n\nDescription of messy cardiovascular disease data\n\n\nVariable name\nVariable description\n\n\n\n\nID\nParticipant identification\n\n\nquestion_age\nQuestion: how old are you / when where you born? Participants 51 or older answered the second question.\n\n\nquestion_substance\nQuestion: do you smoke or drink?\n\n\nquestion_bp\nQuestion: what is your blood pressure? Are you taking medications to lower your blood pressure?\n\n\nlabs\nA collection of laboratory values concatenated into a single string. Notably, the order of lab values is random\n\n\ncvd_fup\nReport of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview",
    "crumbs": [
      "Home",
      "Assignments",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "html_files/08_Strings/class_exercises.html#import",
    "href": "html_files/08_Strings/class_exercises.html#import",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "Load in the dataset which is called cvd_messy.\n\ncvd_messy &lt;- readr::read_rds('data/cvd_messy.rds')\ncvd_messy",
    "crumbs": [
      "Home",
      "Assignments",
      "08 - Characters and Dates"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html",
    "href": "Lectures/09_Joins/index.html",
    "title": "Joins and I/O",
    "section": "",
    "text": "Binding data frames\nMerges and joins\nInput and output",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#agenda",
    "href": "Lectures/09_Joins/index.html#agenda",
    "title": "Joins and I/O",
    "section": "Agenda",
    "text": "Agenda\n\n\n\nBinding data frames\nMerges and joins\nInput and output",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---brute-force",
    "href": "Lectures/09_Joins/index.html#binding---brute-force",
    "title": "Joins and I/O",
    "section": "Binding - Brute Force",
    "text": "Binding - Brute Force\n\nThe most basic way to combine data frames or tibbles is using binding\nCan bind by rows (make longer) or by columns (make wider)\nIt works but it’s not recommended\n\nPuts resposibility on the programmer\nIs reliant on consistent structure in the data frame\nIs brutish compared to formal merges\n\nGood as illustrative exercise",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---one-datasetto-bind-them",
    "href": "Lectures/09_Joins/index.html#binding---one-datasetto-bind-them",
    "title": "Joins and I/O",
    "section": "Binding - One Dataset…to Bind Them",
    "text": "Binding - One Dataset…to Bind Them\n\nSome Lord of the Rings dialogue data\n\n\nfship &lt;- tribble(\n                         ~Film,    ~Race, ~Female, ~Male,\n  \"The Fellowship Of The Ring\",    \"Elf\",    1229,   971,\n  \"The Fellowship Of The Ring\", \"Hobbit\",      14,  3644,\n  \"The Fellowship Of The Ring\",    \"Man\",       0,  1995\n)\nrking &lt;- tribble(\n                         ~Film,    ~Race, ~Female, ~Male,\n      \"The Return Of The King\",    \"Elf\",     183,   510,\n      \"The Return Of The King\", \"Hobbit\",       2,  2673,\n      \"The Return Of The King\",    \"Man\",     268,  2459\n)\nttow &lt;- tribble(\n                         ~Film,    ~Race, ~Female, ~Male,\n              \"The Two Towers\",    \"Elf\",     331,   513,\n              \"The Two Towers\", \"Hobbit\",       0,  2463,\n              \"The Two Towers\",    \"Man\",     401,  3589\n)",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---binding-row-wise",
    "href": "Lectures/09_Joins/index.html#binding---binding-row-wise",
    "title": "Joins and I/O",
    "section": "Binding - Binding Row-wise",
    "text": "Binding - Binding Row-wise\n\nRow binding increases your observations\nThe main consideration is the nature of the variables\n\nDo the same variables exist in each?\nAre they the same type/class?\nAre they in the same position?\n\nIf all these hold, then a row bind is feasible using rbind() or rbind.data.frame() in base R or bind_rows() from dplyr\n\n\n\n\n\n\n\n\nImportant\n\n\nOnus is on the programmer to verify these variable criteria",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---the-9-rows-of-man",
    "href": "Lectures/09_Joins/index.html#binding---the-9-rows-of-man",
    "title": "Joins and I/O",
    "section": "Binding - The 9 Rows of Man",
    "text": "Binding - The 9 Rows of Man\n\nRow-wise binding in action\n\n\nbind_rows(fship, rking, ttow)\n\n# A tibble: 9 × 4\n  Film                       Race   Female  Male\n  &lt;chr&gt;                      &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 The Fellowship Of The Ring Elf      1229   971\n2 The Fellowship Of The Ring Hobbit     14  3644\n3 The Fellowship Of The Ring Man         0  1995\n4 The Return Of The King     Elf       183   510\n5 The Return Of The King     Hobbit      2  2673\n6 The Return Of The King     Man       268  2459\n7 The Two Towers             Elf       331   513\n8 The Two Towers             Hobbit      0  2463\n9 The Two Towers             Man       401  3589",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---row-binding-protection",
    "href": "Lectures/09_Joins/index.html#binding---row-binding-protection",
    "title": "Joins and I/O",
    "section": "Binding - Row Binding Protection",
    "text": "Binding - Row Binding Protection\n\nSimple coercion, mainly factor to character, is allowed\n\n\nttow_factor &lt;- mutate(ttow, Race = fct(Race))\nrbind(fship, rking, ttow_factor)\n\n# A tibble: 9 × 4\n  Film                       Race   Female  Male\n  &lt;chr&gt;                      &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 The Fellowship Of The Ring Elf      1229   971\n2 The Fellowship Of The Ring Hobbit     14  3644\n3 The Fellowship Of The Ring Man         0  1995\n4 The Return Of The King     Elf       183   510\n5 The Return Of The King     Hobbit      2  2673\n6 The Return Of The King     Man       268  2459\n7 The Two Towers             Elf       331   513\n8 The Two Towers             Hobbit      0  2463\n9 The Two Towers             Man       401  3589",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---row-binding-protection-1",
    "href": "Lectures/09_Joins/index.html#binding---row-binding-protection-1",
    "title": "Joins and I/O",
    "section": "Binding - Row Binding Protection",
    "text": "Binding - Row Binding Protection\n\nFactor levels can be disparate\n\n\nttow_factor &lt;- mutate(ttow, Race = fct(Race), Race = fct_expand(Race, \"Orc\"))\nfship_factor &lt;- mutate(fship, Race = fct(Race), Race = fct_expand(Race, \"Ent\"))\nrbind(fship_factor, ttow_factor)\n\n# A tibble: 6 × 4\n  Film                       Race   Female  Male\n  &lt;chr&gt;                      &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 The Fellowship Of The Ring Elf      1229   971\n2 The Fellowship Of The Ring Hobbit     14  3644\n3 The Fellowship Of The Ring Man         0  1995\n4 The Two Towers             Elf       331   513\n5 The Two Towers             Hobbit      0  2463\n6 The Two Towers             Man       401  3589\n\nlevels(rbind(fship_factor, ttow_factor)$Race)\n\n[1] \"Elf\"    \"Hobbit\" \"Man\"    \"Ent\"    \"Orc\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---row-binding-protection-2",
    "href": "Lectures/09_Joins/index.html#binding---row-binding-protection-2",
    "title": "Joins and I/O",
    "section": "Binding - Row Binding Protection",
    "text": "Binding - Row Binding Protection\n\nPositioning can be different as long as names match\n\n\nttow_rev &lt;- relocate(ttow, c(Male, Female, Race, Film))\nrbind(fship, rking, ttow_rev)\n\n# A tibble: 9 × 4\n  Film                       Race   Female  Male\n  &lt;chr&gt;                      &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 The Fellowship Of The Ring Elf      1229   971\n2 The Fellowship Of The Ring Hobbit     14  3644\n3 The Fellowship Of The Ring Man         0  1995\n4 The Return Of The King     Elf       183   510\n5 The Return Of The King     Hobbit      2  2673\n6 The Return Of The King     Man       268  2459\n7 The Two Towers             Elf       331   513\n8 The Two Towers             Hobbit      0  2463\n9 The Two Towers             Man       401  3589",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---row-binding-protection-3",
    "href": "Lectures/09_Joins/index.html#binding---row-binding-protection-3",
    "title": "Joins and I/O",
    "section": "Binding - Row Binding Protection",
    "text": "Binding - Row Binding Protection\n\nbind_rows() will fill empty columns with NA but not rbind()\n\n\nttow_empty &lt;- select(ttow, c(Film, Race, Female))\nbind_rows(fship, rking, ttow_empty)\n\n# A tibble: 9 × 4\n  Film                       Race   Female  Male\n  &lt;chr&gt;                      &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 The Fellowship Of The Ring Elf      1229   971\n2 The Fellowship Of The Ring Hobbit     14  3644\n3 The Fellowship Of The Ring Man         0  1995\n4 The Return Of The King     Elf       183   510\n5 The Return Of The King     Hobbit      2  2673\n6 The Return Of The King     Man       268  2459\n7 The Two Towers             Elf       331    NA\n8 The Two Towers             Hobbit      0    NA\n9 The Two Towers             Man       401    NA\n\nrbind(fship, rking, ttow_empty)\n\nError in rbind(deparse.level, ...): numbers of columns of arguments do not match",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---row-binding-gone-wrong",
    "href": "Lectures/09_Joins/index.html#binding---row-binding-gone-wrong",
    "title": "Joins and I/O",
    "section": "Binding - Row Binding Gone Wrong",
    "text": "Binding - Row Binding Gone Wrong\n\nSome coercion tosses an error\n\n\nttow_numeric &lt;- mutate(ttow, Race = as.numeric(fct(Race)))\nbind_rows(fship, rking, ttow_numeric)\n\nError in `bind_rows()`:\n! Can't combine `..1$Race` &lt;character&gt; and `..3$Race` &lt;double&gt;.",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---row-binding-gone-wrong-1",
    "href": "Lectures/09_Joins/index.html#binding---row-binding-gone-wrong-1",
    "title": "Joins and I/O",
    "section": "Binding - Row Binding Gone Wrong",
    "text": "Binding - Row Binding Gone Wrong\n\nBut if the same variables have different names, you suffer\n\n\nrking_rename &lt;- rename(rking, \"Fem\" = Female)\nrbind(fship, rking_rename, ttow)\n\nError in match.names(clabs, names(xi)): names do not match previous names\n\nbind_rows(fship, rking_rename, ttow) |&gt; slice(c(1:6))\n\n# A tibble: 6 × 5\n  Film                       Race   Female  Male   Fem\n  &lt;chr&gt;                      &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 The Fellowship Of The Ring Elf      1229   971    NA\n2 The Fellowship Of The Ring Hobbit     14  3644    NA\n3 The Fellowship Of The Ring Man         0  1995    NA\n4 The Return Of The King     Elf        NA   510   183\n5 The Return Of The King     Hobbit     NA  2673     2\n6 The Return Of The King     Man        NA  2459   268\n\n\n\nCheck your work or even better, don’t use row binding",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---column-binding",
    "href": "Lectures/09_Joins/index.html#binding---column-binding",
    "title": "Joins and I/O",
    "section": "Binding - Column Binding",
    "text": "Binding - Column Binding\n\n\n\nMuch scarier than row binding\nRow MUST be aligned to avoid data quality issues\nMany other safer options exists\n\nmutate()\nseparate_wider_\nEven $ is better\n\n\n\n\n\n\n\n\n\n\nEnforce constraints rather than using cbind() or bind_cols()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---column-binding-in-action-gulp",
    "href": "Lectures/09_Joins/index.html#binding---column-binding-in-action-gulp",
    "title": "Joins and I/O",
    "section": "Binding - Column Binding In Action <gulp>",
    "text": "Binding - Column Binding In Action &lt;gulp&gt;\n\nColumn binding frequently works even when you think it shouldn’t\n\n\nbind_cols(fship, rking, ttow)\n\n# A tibble: 3 × 12\n  Film...1    Race...2 Female...3 Male...4 Film...5 Race...6 Female...7 Male...8\n  &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 The Fellow… Elf            1229      971 The Ret… Elf             183      510\n2 The Fellow… Hobbit           14     3644 The Ret… Hobbit            2     2673\n3 The Fellow… Man               0     1995 The Ret… Man             268     2459\n# ℹ 4 more variables: Film...9 &lt;chr&gt;, Race...10 &lt;chr&gt;, Female...11 &lt;dbl&gt;,\n#   Male...12 &lt;dbl&gt;\n\ncbind(fship, rking, ttow)\n\n                        Film   Race Female Male                   Film   Race\n1 The Fellowship Of The Ring    Elf   1229  971 The Return Of The King    Elf\n2 The Fellowship Of The Ring Hobbit     14 3644 The Return Of The King Hobbit\n3 The Fellowship Of The Ring    Man      0 1995 The Return Of The King    Man\n  Female Male           Film   Race Female Male\n1    183  510 The Two Towers    Elf    331  513\n2      2 2673 The Two Towers Hobbit      0 2463\n3    268 2459 The Two Towers    Man    401 3589",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---column-binding-in-action-gulp-1",
    "href": "Lectures/09_Joins/index.html#binding---column-binding-in-action-gulp-1",
    "title": "Joins and I/O",
    "section": "Binding - Column Binding In Action <gulp>",
    "text": "Binding - Column Binding In Action &lt;gulp&gt;\n\ncbind() in particular is frightening because of recycling\n\n\nfship_rking &lt;- bind_rows(fship, rking)\ncbind(fship_rking, ttow)\n\n                        Film   Race Female Male           Film   Race Female Male\n1 The Fellowship Of The Ring    Elf   1229  971 The Two Towers    Elf    331  513\n2 The Fellowship Of The Ring Hobbit     14 3644 The Two Towers Hobbit      0 2463\n3 The Fellowship Of The Ring    Man      0 1995 The Two Towers    Man    401 3589\n4     The Return Of The King    Elf    183  510 The Two Towers    Elf    331  513\n5     The Return Of The King Hobbit      2 2673 The Two Towers Hobbit      0 2463\n6     The Return Of The King    Man    268 2459 The Two Towers    Man    401 3589\n\n\n\nCheck your work, or even better, don’t use column binding",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#binding---just-dont",
    "href": "Lectures/09_Joins/index.html#binding---just-dont",
    "title": "Joins and I/O",
    "section": "Binding - Just Don’t",
    "text": "Binding - Just Don’t\n\n\n\nBottom line is this:\n\nRow bind when needed but be sure to check your work afterwards\nColumn bind only if absolutely necessary and be exceedingly distrustful of the results\n\nThere are much better and safer options called joins",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---built-from-relational-data",
    "href": "Lectures/09_Joins/index.html#joins---built-from-relational-data",
    "title": "Joins and I/O",
    "section": "Joins - Built from Relational Data",
    "text": "Joins - Built from Relational Data\n\n\n\nMultiple separate but associated datasets comprise relational data\nNow we think beyond structuring data in rows and columns but to include tables that can be linked (i.e. related)\nThese relationships allow for joins by associative variables called keys\nFYI R (like Excel) is NOT a RDBMS\n\n\n\n\n\n\n\n\n\nhttps://cloud.google.com/learn/what-is-a-relational-database",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---keys",
    "href": "Lectures/09_Joins/index.html#joins---keys",
    "title": "Joins and I/O",
    "section": "Joins - Keys",
    "text": "Joins - Keys\n\nAll joins involve keys in the connecting tables\n\nPrimary keys are the unique identifier for a record in a dataset\nEach table only has one primary key and ensures each observation can be uniquely identified\nCompound keys use two or more columns / variables to identify unique records\nThe combination ensures uniqueness although surrogate primary keys may be useful\nForeign keys in one table uniquely identify a record in another table\nEstablish the link from the child table to the parent/referenced table",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---what-keys-do",
    "href": "Lectures/09_Joins/index.html#joins---what-keys-do",
    "title": "Joins and I/O",
    "section": "Joins - What Keys Do",
    "text": "Joins - What Keys Do\n\nKeys are great for many reason like ensuring uniqueness, enforcing integrity, and facilitating indexing\nThey are also the backbone of joins since they establish how tables are related\nWe join tables by matching the primary keys in one table to the foreign key in another\nBy matching tables record-wise by key we can make single tables",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---catching-another-flight",
    "href": "Lectures/09_Joins/index.html#joins---catching-another-flight",
    "title": "Joins and I/O",
    "section": "Joins - Catching Another Flight",
    "text": "Joins - Catching Another Flight\n\nThe nycflights13 dataset has many tables beyond our flights\n\nairlines records the carrier name and its two letter code (PK)\nairports gives positional/idetifying data for each airport with each identified by its unique faa call (PK)\nplanes has data about each plane itself with its tail number (PK) as the identifier\nweather gives weather data at each origin airport by time (compound PK)\n\nThese primary keys all link back to foreign keys within flights",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---mapping-the-relationships",
    "href": "Lectures/09_Joins/index.html#joins---mapping-the-relationships",
    "title": "Joins and I/O",
    "section": "Joins - Mapping the Relationships",
    "text": "Joins - Mapping the Relationships",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---mapping-to-flights",
    "href": "Lectures/09_Joins/index.html#joins---mapping-to-flights",
    "title": "Joins and I/O",
    "section": "Joins - Mapping to Flights",
    "text": "Joins - Mapping to Flights\n\nFor our joins, we’ll consider a reduced set of flights called flight\n\n\nflight &lt;- select(flights, c(year, time_hour, origin, dest, tailnum, carrier))\nflight\n\n# A tibble: 336,776 × 6\n    year time_hour           origin dest  tailnum carrier\n   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     \n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     \n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     \n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     \n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     \n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6     \n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV     \n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6     \n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA     \n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---some-caveats",
    "href": "Lectures/09_Joins/index.html#joins---some-caveats",
    "title": "Joins and I/O",
    "section": "Joins - Some Caveats",
    "text": "Joins - Some Caveats\n\nLife is easier when the same variables have the same name, but not always the case\nDifferent variables ideally have different names, but not always the case e.g. year in flights and planes are different\nData WILL be missing from one table of the other\nRows will invariably have different units of observation",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---the-dplyr-verbs",
    "href": "Lectures/09_Joins/index.html#joins---the-dplyr-verbs",
    "title": "Joins and I/O",
    "section": "Joins - The dplyr Verbs",
    "text": "Joins - The dplyr Verbs\n\ndplyr has three families of functions used for joins:\n\nMutating joins combine variables from two data frames by matching rows from one table to another\nFiltering joins filter observations in one table based on whether they match a record in the other table\nSet operations combine observations as if they were set elements\n\nFor better or worse, dplyr only joins two tables at a time x and y",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---dplyr-joins-by-by",
    "href": "Lectures/09_Joins/index.html#joins---dplyr-joins-by-by",
    "title": "Joins and I/O",
    "section": "Joins - dplyr Joins by by",
    "text": "Joins - dplyr Joins by by\n\nAll dplyr joins generally control matching the same way, with by\nby = NULL uses all variables common to both tables aka a natural join\nby = \"x\", where \"x\" is a character vector, is a natural join but only uses some common variables\nUseful when the tables have two distinct variables with the same name\nby = c(\"x\" = \"a\") matches variable \"x\" in table x with variable \"a\" in table y\nUseful when the matching variables have different names\nby = join_by() using an expression on variable names e.g. x == a",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---mutating-joins-to-add-variables",
    "href": "Lectures/09_Joins/index.html#joins---mutating-joins-to-add-variables",
    "title": "Joins and I/O",
    "section": "Joins - Mutating Joins to Add Variables",
    "text": "Joins - Mutating Joins to Add Variables\n\nThese joins will return all columns in x and all columns in y\nIf the foreign key matches multiple times, all combinations of PK-FK pairs are returned\n\nLeft join - return all rows in x and those in y that match in x\nRight join - return all rows in y and those in x that match in y\nInner join - return all rows that match in both x and y\nFull join - return all rows in x and all rows in y\n\nReturned rows that were unmatched get NA in the new columns from the other table",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---visual-diagram-of-mutating-joins",
    "href": "Lectures/09_Joins/index.html#joins---visual-diagram-of-mutating-joins",
    "title": "Joins and I/O",
    "section": "Joins - Visual Diagram of Mutating Joins",
    "text": "Joins - Visual Diagram of Mutating Joins",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---left-join-via-left_join",
    "href": "Lectures/09_Joins/index.html#joins---left-join-via-left_join",
    "title": "Joins and I/O",
    "section": "Joins - Left Join via left_join()",
    "text": "Joins - Left Join via left_join()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEasily the most common, always returns all rows of the parent table x",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---left_join-with-flight",
    "href": "Lectures/09_Joins/index.html#joins---left_join-with-flight",
    "title": "Joins and I/O",
    "section": "Joins - left_join() with flight",
    "text": "Joins - left_join() with flight\n\nA left join between flight and arlines\n\n\nleft_join(flight, airlines)\n\n# A tibble: 336,776 × 7\n    year time_hour           origin dest  tailnum carrier name                    \n   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;                   \n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines Inc.   \n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines Inc.   \n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines Inc.  \n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways         \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.    \n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines Inc.   \n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      JetBlue Airways         \n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      ExpressJet Airlines Inc.\n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      JetBlue Airways         \n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      American Airlines Inc.  \n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---left_join-with-flight-1",
    "href": "Lectures/09_Joins/index.html#joins---left_join-with-flight-1",
    "title": "Joins and I/O",
    "section": "Joins - left_join() with flight",
    "text": "Joins - left_join() with flight\n\nA left join between flight and weather with a select for temp/wind\n\n\nflight |&gt; left_join(weather |&gt; select(origin, time_hour, temp, wind_speed))\n\n# A tibble: 336,776 × 8\n    year time_hour           origin dest  tailnum carrier  temp wind_speed\n   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7\n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0\n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0\n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0\n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1\n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7\n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6       37.9       11.5\n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV       39.9       16.1\n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6       37.9       13.8\n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA       39.9       16.1\n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---left_join-with-flight-2",
    "href": "Lectures/09_Joins/index.html#joins---left_join-with-flight-2",
    "title": "Joins and I/O",
    "section": "Joins - left_join() with flight",
    "text": "Joins - left_join() with flight\n\nA left join between flight and planes with a failed natural join\n\n\nflight |&gt; left_join(planes)\n\n# A tibble: 336,776 × 13\n    year time_hour           origin dest  tailnum carrier type  manufacturer model engines seats speed engine\n   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; \n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;       NA    NA    NA &lt;NA&gt;  \n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---left_join-with-flight-3",
    "href": "Lectures/09_Joins/index.html#joins---left_join-with-flight-3",
    "title": "Joins and I/O",
    "section": "Joins - left_join() with flight",
    "text": "Joins - left_join() with flight\n\nSince year means different things, we want to specify by = tailnum\n\n\nflight |&gt; left_join(planes, by = \"tailnum\")\n\n# A tibble: 336,776 × 14\n   year.x time_hour           origin dest  tailnum carrier year.y type                    manufacturer     model       engines seats speed engine   \n    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;                   &lt;chr&gt;            &lt;chr&gt;         &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    \n 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999 Fixed wing multi engine BOEING           737-824           2   149    NA Turbo-fan\n 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998 Fixed wing multi engine BOEING           737-824           2   149    NA Turbo-fan\n 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990 Fixed wing multi engine BOEING           757-223           2   178    NA Turbo-fan\n 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012 Fixed wing multi engine AIRBUS           A320-232          2   200    NA Turbo-fan\n 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991 Fixed wing multi engine BOEING           757-232           2   178    NA Turbo-fan\n 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012 Fixed wing multi engine BOEING           737-924ER         2   191    NA Turbo-fan\n 7   2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6        2000 Fixed wing multi engine AIRBUS INDUSTRIE A320-232          2   200    NA Turbo-fan\n 8   2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV        1998 Fixed wing multi engine CANADAIR         CL-600-2B19       2    55    NA Turbo-fan\n 9   2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6        2004 Fixed wing multi engine AIRBUS           A320-232          2   200    NA Turbo-fan\n10   2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA          NA &lt;NA&gt;                    &lt;NA&gt;             &lt;NA&gt;             NA    NA    NA &lt;NA&gt;     \n# ℹ 336,766 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---right-join-via-right_join",
    "href": "Lectures/09_Joins/index.html#joins---right-join-via-right_join",
    "title": "Joins and I/O",
    "section": "Joins - Right Join via right_join()",
    "text": "Joins - Right Join via right_join()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFar less common than left joins",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---right_join-with-flight",
    "href": "Lectures/09_Joins/index.html#joins---right_join-with-flight",
    "title": "Joins and I/O",
    "section": "Joins - right_join() with flight",
    "text": "Joins - right_join() with flight\n\nA right join between flight and planes, equivalent to left_join(airlines, flight) aside from column order\n\n\nflight |&gt; right_join(planes, by = join_by(tailnum))\n\n# A tibble: 284,170 × 14\n   year.x time_hour           origin dest  tailnum carrier year.y type                    manufacturer     model       engines seats speed engine   \n    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;                   &lt;chr&gt;            &lt;chr&gt;         &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;    \n 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999 Fixed wing multi engine BOEING           737-824           2   149    NA Turbo-fan\n 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998 Fixed wing multi engine BOEING           737-824           2   149    NA Turbo-fan\n 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990 Fixed wing multi engine BOEING           757-223           2   178    NA Turbo-fan\n 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012 Fixed wing multi engine AIRBUS           A320-232          2   200    NA Turbo-fan\n 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991 Fixed wing multi engine BOEING           757-232           2   178    NA Turbo-fan\n 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012 Fixed wing multi engine BOEING           737-924ER         2   191    NA Turbo-fan\n 7   2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6        2000 Fixed wing multi engine AIRBUS INDUSTRIE A320-232          2   200    NA Turbo-fan\n 8   2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV        1998 Fixed wing multi engine CANADAIR         CL-600-2B19       2    55    NA Turbo-fan\n 9   2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6        2004 Fixed wing multi engine AIRBUS           A320-232          2   200    NA Turbo-fan\n10   2013 2013-01-01 06:00:00 JFK    PBI   N793JB  B6        2011 Fixed wing multi engine AIRBUS           A320-232          2   200    NA Turbo-fan\n# ℹ 284,160 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---inner-join-via-inner_join",
    "href": "Lectures/09_Joins/index.html#joins---inner-join-via-inner_join",
    "title": "Joins and I/O",
    "section": "Joins - Inner Join via inner_join()",
    "text": "Joins - Inner Join via inner_join()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple matching returns all combinations so it does make new rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---inner_join-with-flight",
    "href": "Lectures/09_Joins/index.html#joins---inner_join-with-flight",
    "title": "Joins and I/O",
    "section": "Joins - inner_join() with flight",
    "text": "Joins - inner_join() with flight\n\nAgain, combinations are returned even on inner joins if a match is found\n\n\nflight |&gt; inner_join(airports |&gt; filter(faa %in% c(\"JFK\", \"LGA\")), \n                     by = join_by(origin == faa))\n\n# A tibble: 215,941 × 13\n    year time_hour           origin dest  tailnum carrier name                  lat   lon   alt    tz dst   tzone           \n   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n 1  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia           40.8 -73.9    22    -5 A     America/New_York\n 2  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n 3  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n 4  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia           40.8 -73.9    22    -5 A     America/New_York\n 5  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      La Guardia           40.8 -73.9    22    -5 A     America/New_York\n 6  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n 7  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      La Guardia           40.8 -73.9    22    -5 A     America/New_York\n 8  2013 2013-01-01 06:00:00 JFK    PBI   N793JB  B6      John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n 9  2013 2013-01-01 06:00:00 JFK    TPA   N657JB  B6      John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n10  2013 2013-01-01 06:00:00 JFK    LAX   N29129  UA      John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n# ℹ 215,931 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---full-join-via-full_join",
    "href": "Lectures/09_Joins/index.html#joins---full-join-via-full_join",
    "title": "Joins and I/O",
    "section": "Joins - Full Join via full_join()",
    "text": "Joins - Full Join via full_join()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen you don’t want to lose any data anywhere",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---filtering-joins-to-reduce-rows",
    "href": "Lectures/09_Joins/index.html#joins---filtering-joins-to-reduce-rows",
    "title": "Joins and I/O",
    "section": "Joins - Filtering Joins to Reduce Rows",
    "text": "Joins - Filtering Joins to Reduce Rows\n\nPrimary action is to filter rows, columns are not added from y\nNo multiple matching is done, will never return more rows than originally in x\n\nSemi-join - keep all rows in x that have a match in y, discard all other rows from x\nSemi-joins are like inner joins but only return the one row from x\nAnti-join - returns only those rows x that do NOT have a match in y\nEspecially useful in identifying data that is implicitly missing\n\njoin_by() expressions using operators like &lt; or &gt; have great utility",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---full-join-via-full_join-1",
    "href": "Lectures/09_Joins/index.html#joins---full-join-via-full_join-1",
    "title": "Joins and I/O",
    "section": "Joins - Full Join via full_join()",
    "text": "Joins - Full Join via full_join()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote how this only returns columns from x",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---semi-join-with-semi_join",
    "href": "Lectures/09_Joins/index.html#joins---semi-join-with-semi_join",
    "title": "Joins and I/O",
    "section": "Joins - Semi-join with semi_join()",
    "text": "Joins - Semi-join with semi_join()\n\nWe join airports on flight to only get the origin airports\n\n\nairports |&gt; semi_join(flight, by = join_by(faa == origin))\n\n# A tibble: 3 × 8\n  faa   name                  lat   lon   alt    tz dst   tzone           \n  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---semi-join-with-semi_join-1",
    "href": "Lectures/09_Joins/index.html#joins---semi-join-with-semi_join-1",
    "title": "Joins and I/O",
    "section": "Joins - Semi-join with semi_join()",
    "text": "Joins - Semi-join with semi_join()\n\nOr to get the destination airports only\n\n\nairports |&gt; semi_join(flight, by = join_by(faa == dest))\n\n# A tibble: 101 × 8\n   faa   name                                lat    lon   alt    tz dst   tzone            \n   &lt;chr&gt; &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;            \n 1 ABQ   Albuquerque International Sunport  35.0 -107.   5355    -7 A     America/Denver   \n 2 ACK   Nantucket Mem                      41.3  -70.1    48    -5 A     America/New_York \n 3 ALB   Albany Intl                        42.7  -73.8   285    -5 A     America/New_York \n 4 ANC   Ted Stevens Anchorage Intl         61.2 -150.    152    -9 A     America/Anchorage\n 5 ATL   Hartsfield Jackson Atlanta Intl    33.6  -84.4  1026    -5 A     America/New_York \n 6 AUS   Austin Bergstrom Intl              30.2  -97.7   542    -6 A     America/Chicago  \n 7 AVL   Asheville Regional Airport         35.4  -82.5  2165    -5 A     America/New_York \n 8 BDL   Bradley Intl                       41.9  -72.7   173    -5 A     America/New_York \n 9 BGR   Bangor Intl                        44.8  -68.8   192    -5 A     America/New_York \n10 BHM   Birmingham Intl                    33.6  -86.8   644    -6 A     America/Chicago  \n# ℹ 91 more rows\n\n\n\nIn both cases these are just filtered variants of airports",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---full-join-via-full_join-2",
    "href": "Lectures/09_Joins/index.html#joins---full-join-via-full_join-2",
    "title": "Joins and I/O",
    "section": "Joins - Full Join via full_join()",
    "text": "Joins - Full Join via full_join()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRows from x that are missing in y i.e. implicitly missing",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---anti-join-with-anti_join",
    "href": "Lectures/09_Joins/index.html#joins---anti-join-with-anti_join",
    "title": "Joins and I/O",
    "section": "Joins - Anti-join with anti_join()",
    "text": "Joins - Anti-join with anti_join()\n\nWe can find flight destinations that don’t have a matching faa code in airports\n\n\nflight |&gt; anti_join(airports, by = join_by(dest == faa)) |&gt;\n  distinct(dest)\n\n# A tibble: 4 × 1\n  dest \n  &lt;chr&gt;\n1 BQN  \n2 SJU  \n3 STT  \n4 PSE  \n\n\n\nThese are destinations in flight missing from the airports data",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---set-operations",
    "href": "Lectures/09_Joins/index.html#joins---set-operations",
    "title": "Joins and I/O",
    "section": "Joins - Set Operations",
    "text": "Joins - Set Operations\n\nThe other two-table type of dplyr function are set operations\n\nx and y are expected to have the same variables\nRows / observations are treated like sets\n\n\n\nintersect(x,y) returns observations in both x and y\nunion(x,y) returns unique observations in x and y\nsetdiff(x,y) returns observations in x but not in y\n\n\nThese behave just like base R’s vector-based set operations but function row-wise on tables instead of element-wise on vectors",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#joins---final-comments",
    "href": "Lectures/09_Joins/index.html#joins---final-comments",
    "title": "Joins and I/O",
    "section": "Joins - Final Comments",
    "text": "Joins - Final Comments\n\nJoins that return columns with the same name have suffixes attached\n\nDefault is .x and .y\nThese can be specified using the suffix argument\n\nUnderstanding join_by() is especially powerful with filter joins\nBase R has merge() which can do basically everything by use of the all, by, suffixes, and no.dups arguments; dplyr is simply more explicit in its functionality",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---what-weve-done-before",
    "href": "Lectures/09_Joins/index.html#io---what-weve-done-before",
    "title": "Joins and I/O",
    "section": "I/O - What We’ve Done Before",
    "text": "I/O - What We’ve Done Before\n\nMost of our effort has been using .rds files already made in R or stock datasets\nDuring Advanced Visualization we discussed some other options:\n\nBase R functions like read.table() and read.csv()\nOptions for other file types most notably Excel with read_xl()\n\nAside from saving .rds or .RData files or Quarto rendering not much output",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---the-import-mindset",
    "href": "Lectures/09_Joins/index.html#io---the-import-mindset",
    "title": "Joins and I/O",
    "section": "I/O - The Import Mindset",
    "text": "I/O - The Import Mindset\n\nDuring data import you can generally either:\n\nBe adventurous - import your data as quickly as possible and start playing\nBe consistent - spend time prior to import getting your data as close to a tidy format as possible\n\nBoth have value and purpose but in general:\n\nManipulate the data outside of your reproducible workflow as minimally as you can\nUse arguments during import to get as far as you can as quickly as possible",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---the-export-mindset",
    "href": "Lectures/09_Joins/index.html#io---the-export-mindset",
    "title": "Joins and I/O",
    "section": "I/O - The Export Mindset",
    "text": "I/O - The Export Mindset\n\n\n\nToday’s output is tomorrow’s input whether it’s:\n\nA tidy data set ready for subsequent analysis and sharing\nAn operational output from a pipeline (summary metric, graphical output, statistical result, etc)\n\nDon’t get fancy, proprietary file formats my be unusable",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---import-with-readr",
    "href": "Lectures/09_Joins/index.html#io---import-with-readr",
    "title": "Joins and I/O",
    "section": "I/O - Import with readr",
    "text": "I/O - Import with readr\n\nreadr functions handle a lot of the basic input functions of base R\n\nread_delim() is functionally equivalent to read.table()\nOther variants include read_csv(), read_tsv(), and read_rds()\n\nIt’s main utility is parsing input meaningfully for storage in a tibble\nreadr will try to make informed guess on column types although you can overwrite these by passing lists to the col_types argument\nSee the vignette for more details",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---export-with-readr",
    "href": "Lectures/09_Joins/index.html#io---export-with-readr",
    "title": "Joins and I/O",
    "section": "I/O - Export with readr",
    "text": "I/O - Export with readr\n\nDespite its name, readr can also write rectangular data to file with write_delim(), write_tsv(), write_csv() and even write_excel_csv()\nMajor distinction is what the default delim argument is with write_delim() using the space \" \"\nOtherwise, very similar to base R’s write.table() and write.csv()",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---working-with-excel",
    "href": "Lectures/09_Joins/index.html#io---working-with-excel",
    "title": "Joins and I/O",
    "section": "I/O - Working with Excel",
    "text": "I/O - Working with Excel\n\nWe previously discussed read_xl but there is also write_excel which has the write_xlsx() function\nBoth functions have similar arguments where you specify path and sheet\nwrite_xlsx() is very lightweight and won’t allow for formatting during writing\nFor more engaged writing to Excel I recommend openxlsx2 with xlsx being another alternative",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---a-cautionary-tale",
    "href": "Lectures/09_Joins/index.html#io---a-cautionary-tale",
    "title": "Joins and I/O",
    "section": "I/O - A Cautionary Tale",
    "text": "I/O - A Cautionary Tale\n\nSaving to a non-R file loses meta information e.g. factors\nConsider gapminder with country ordered by lifeExp\n\n\ngapminder_reorder &lt;- gapminder |&gt;\n  filter(year == 1997) |&gt;\n  mutate(country = fct_reorder(country, desc(lifeExp))) |&gt;\n  arrange(country)\n\nprint(gapminder_reorder, n=5)\n\n# A tibble: 142 × 6\n  country          continent  year lifeExp       pop gdpPercap\n  &lt;fct&gt;            &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;dbl&gt;\n1 Japan            Asia       1997    80.7 125956499    28817.\n2 Hong Kong, China Asia       1997    80     6495918    28378.\n3 Sweden           Europe     1997    79.4   8897619    25267.\n4 Switzerland      Europe     1997    79.4   7193761    32135.\n5 Iceland          Europe     1997    79.0    271192    28061.\n# ℹ 137 more rows",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---a-cautionary-tale-1",
    "href": "Lectures/09_Joins/index.html#io---a-cautionary-tale-1",
    "title": "Joins and I/O",
    "section": "I/O - A Cautionary Tale",
    "text": "I/O - A Cautionary Tale\n\nThe factor levels saves this ordering over the default alphabetical\n\n\nlevels(gapminder_reorder$country)[1:10]\n\n [1] \"Japan\"            \"Hong Kong, China\" \"Sweden\"           \"Switzerland\"      \"Iceland\"          \"Australia\"        \"Italy\"           \n [8] \"Spain\"            \"France\"           \"Canada\"          \n\n\n\nBut if this is saved to file and then reloaded\n\n\nwrite_delim(gapminder_reorder, \"data/gapminder_reorder.txt\", delim = \"\\t\")\n\ngapminder_reorder_readin &lt;- read_delim(\"data/gapminder_reorder.txt\")\n\n\nNot only is the reordering lost but readr defaults to a character\n\n\nclass(gapminder_reorder_readin$country)\n\n[1] \"character\"",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---improving-your-personal-flows",
    "href": "Lectures/09_Joins/index.html#io---improving-your-personal-flows",
    "title": "Joins and I/O",
    "section": "I/O - Improving Your Personal Flows",
    "text": "I/O - Improving Your Personal Flows\n\nWhenever possible, save your objects as .rds files to maintain all R-specific metadata\nThese can easily be recalled using readRDS() and writeRDS() in base R or read_rds() or write_rds() from readr\nDon’t be afraid to save entire environments as .RData files with save() and load(); these can get rather cumbersome though and saving multiple variants can be hard to keep track of\nYou may not share these with collaborators but you’ll make extensive personal use of them",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---final-warnings-on-delimited-files",
    "href": "Lectures/09_Joins/index.html#io---final-warnings-on-delimited-files",
    "title": "Joins and I/O",
    "section": "I/O - Final Warnings on Delimited Files",
    "text": "I/O - Final Warnings on Delimited Files\n\n\n\n\n\n\nTip\n\n\nWrite data for computers but write code for humans\n\n\n\n\nCollaborators never follow the former so delimited files will fail on import in odd ways\n\nYour requested delimiters (e.g. \",\" or \"\\t\") will be part of the file\nNew lines will lead to jagged rows or missing keys\nQuotes will be used which cause odd string behavior\nMore ways you never even considered",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#io---final-warnings-on-delimited-files-1",
    "href": "Lectures/09_Joins/index.html#io---final-warnings-on-delimited-files-1",
    "title": "Joins and I/O",
    "section": "I/O - Final Warnings on Delimited Files",
    "text": "I/O - Final Warnings on Delimited Files\n\nIf you can limit these issues during data capture it makes your job easier\ne.g. If dropdown menus via REDCap be used do so\nAvoid free text whenever possible\nBe ready to scrub those fields with regular expressions when you’re inevitably ignored\nHeaders as column names can be brutal on read-in\nDon’t forget about proper casing and janitor",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "Lectures/09_Joins/index.html#learning-more",
    "href": "Lectures/09_Joins/index.html#learning-more",
    "title": "Joins and I/O",
    "section": "Learning More",
    "text": "Learning More\n\ndplyr has a dedicated vignette on joining\nThe Import section in R4DS has several chapters on importing data from a variety of formats\nNext time, Quarto",
    "crumbs": [
      "Home",
      "Lecture HTML",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "html_files/09_Joins/class_exercises.html",
    "href": "html_files/09_Joins/class_exercises.html",
    "title": "Joining data",
    "section": "",
    "text": "These exercises will help you practice applying functions in the join family and the stringr and glue packages. You will use two datasets that describe a TV show called ‘The Office’.\n\n\nPackages used for this exercise set are loaded below.\n\n\n\nThe analysis will involve two datasets:\n\noffice_ratings.csv: the IMDB rating for each episode.\noffice_director_and_writers.csv the writers and director of each episode.\n\n\nratings_descr &lt;-\n  c(\"season\"      = \"Season that the episode aired\",\n    \"episode\"     = \"Episode number, relative to Season start\",\n    \"title\"       = \"Title of the episode\",\n    \"imdb_rating\" = \"Mean IMDB rating\",\n    \"total_votes\" = \"Total number of IMDB members who rated the episode\",\n    \"air_date\"    = \"Date that the episode aired\")\n\ndrctr_wrtr_descr &lt;- \n  c(\"season\"   = \"Season that the episode aired\", \n    \"title\"    = \"Title of the episode\", \n    \"director\" = \"Name of the episode's director\", \n    \"writer\"   = \"Name of contributing writer\")\n\ndata_names &lt;- c(\"ratings\", \"director and writers\")\n\ntbls &lt;- list(ratings_descr, drctr_wrtr_descr) |&gt; \n  map2(.y = data_names,\n    ~ enframe(.x) |&gt;\n      gt(rowname_col = \"name\") |&gt;\n      tab_stubhead(label = 'Variable name') |&gt; \n      cols_label(value = 'Variable description') |&gt; \n      cols_align('left') %&gt;% \n      tab_header(title = glue('Description of {.y} data'))\n  )\n\ntbls[[1]]\n\n\n\n\n\n\n\nDescription of ratings data\n\n\nVariable name\nVariable description\n\n\n\n\nseason\nSeason that the episode aired\n\n\nepisode\nEpisode number, relative to Season start\n\n\ntitle\nTitle of the episode\n\n\nimdb_rating\nMean IMDB rating\n\n\ntotal_votes\nTotal number of IMDB members who rated the episode\n\n\nair_date\nDate that the episode aired\n\n\n\n\n\n\n\n\ntbls[[2]]\n\n\n\n\n\n\n\nDescription of director and writers data\n\n\nVariable name\nVariable description\n\n\n\n\nseason\nSeason that the episode aired\n\n\ntitle\nTitle of the episode\n\n\ndirector\nName of the episode's director\n\n\nwriter\nName of contributing writer\n\n\n\n\n\n\n\n\n\n\nYou can import the two datasets using the read_csv() function. Note that your project directory is the root of the file path.\n\n# Read in both the 'office_ratings.csv' file and \n# the 'office_director_and_writers.csv' file.",
    "crumbs": [
      "Home",
      "Assignments",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "html_files/09_Joins/class_exercises.html#setup",
    "href": "html_files/09_Joins/class_exercises.html#setup",
    "title": "Joining data",
    "section": "",
    "text": "Packages used for this exercise set are loaded below.",
    "crumbs": [
      "Home",
      "Assignments",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "html_files/09_Joins/class_exercises.html#data-dictionary",
    "href": "html_files/09_Joins/class_exercises.html#data-dictionary",
    "title": "Joining data",
    "section": "",
    "text": "The analysis will involve two datasets:\n\noffice_ratings.csv: the IMDB rating for each episode.\noffice_director_and_writers.csv the writers and director of each episode.\n\n\nratings_descr &lt;-\n  c(\"season\"      = \"Season that the episode aired\",\n    \"episode\"     = \"Episode number, relative to Season start\",\n    \"title\"       = \"Title of the episode\",\n    \"imdb_rating\" = \"Mean IMDB rating\",\n    \"total_votes\" = \"Total number of IMDB members who rated the episode\",\n    \"air_date\"    = \"Date that the episode aired\")\n\ndrctr_wrtr_descr &lt;- \n  c(\"season\"   = \"Season that the episode aired\", \n    \"title\"    = \"Title of the episode\", \n    \"director\" = \"Name of the episode's director\", \n    \"writer\"   = \"Name of contributing writer\")\n\ndata_names &lt;- c(\"ratings\", \"director and writers\")\n\ntbls &lt;- list(ratings_descr, drctr_wrtr_descr) |&gt; \n  map2(.y = data_names,\n    ~ enframe(.x) |&gt;\n      gt(rowname_col = \"name\") |&gt;\n      tab_stubhead(label = 'Variable name') |&gt; \n      cols_label(value = 'Variable description') |&gt; \n      cols_align('left') %&gt;% \n      tab_header(title = glue('Description of {.y} data'))\n  )\n\ntbls[[1]]\n\n\n\n\n\n\n\nDescription of ratings data\n\n\nVariable name\nVariable description\n\n\n\n\nseason\nSeason that the episode aired\n\n\nepisode\nEpisode number, relative to Season start\n\n\ntitle\nTitle of the episode\n\n\nimdb_rating\nMean IMDB rating\n\n\ntotal_votes\nTotal number of IMDB members who rated the episode\n\n\nair_date\nDate that the episode aired\n\n\n\n\n\n\n\n\ntbls[[2]]\n\n\n\n\n\n\n\nDescription of director and writers data\n\n\nVariable name\nVariable description\n\n\n\n\nseason\nSeason that the episode aired\n\n\ntitle\nTitle of the episode\n\n\ndirector\nName of the episode's director\n\n\nwriter\nName of contributing writer",
    "crumbs": [
      "Home",
      "Assignments",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "html_files/09_Joins/class_exercises.html#import",
    "href": "html_files/09_Joins/class_exercises.html#import",
    "title": "Joining data",
    "section": "",
    "text": "You can import the two datasets using the read_csv() function. Note that your project directory is the root of the file path.\n\n# Read in both the 'office_ratings.csv' file and \n# the 'office_director_and_writers.csv' file.",
    "crumbs": [
      "Home",
      "Assignments",
      "09 - Joins and I/O"
    ]
  },
  {
    "objectID": "downloads.html#joins-and-io",
    "href": "downloads.html#joins-and-io",
    "title": "BST680 Downloads",
    "section": "",
    "text": "Exercises - [.qmd file] and [.R file]\nData and Solutions folder - [.zip file]",
    "crumbs": [
      "Home",
      "Downloads",
      "Exercise Downloads"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html",
    "href": "html_files/Midterm/midterm_solutions.html",
    "title": "BST680 Midterm",
    "section": "",
    "text": "This midterm is comprised of two portions:\n\nA visualization using a curated variation of the gapminder dataset\nA data manipulation and summarisation exercise emphasizing gt output\n\nFor each question, provide your code in order to create the requested output and comment your code either within the code block or by adding annotations directly to the Quarto document. I’m less interested in the specific code you used than I am understanding your thought process in order to get to the solution. Your comments are critical and should be provided as if to direct someone who has never seen your code to be able to reproduce it easily and know why you settled on these options.\n\n\n\n\n\n\nWarning\n\n\n\nTo best accomplish these coding tasks, you’ll need to work with functions that we may have only briefly discussed in class\nPart of this course is to develop your skill set to discover and use functions you may not have been aware of previously\nAgain, look at the references and cheat sheets, they’re your friends\n\n\nGood luck!\nTo get you started, a zipped file with all the necessary files and folders can be [downloaded here]\n\n\n\n\n\n\nTip\n\n\n\nYou can check your work as you go through the assignment by viewing the midterm html document available online\nConversely to open this file locally, click on it in the ‘Files’ pane of Rstudio and then select the ‘View in web browser option’\nEvery problem has the answered displayed in this document so you can verify whether you have gotten the expected result",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#prepping-the-data",
    "href": "html_files/Midterm/midterm_solutions.html#prepping-the-data",
    "title": "BST680 Midterm",
    "section": "Prepping the data",
    "text": "Prepping the data\n\nWe will be using a curated version of the gapminder dataset\nFor more details on the Gapminder organization, see https://www.gapminder.org/about-gapminder/\nYou’ll find the modified variation of the gapminder data below called gap_data; you may continue to use this name\n\n\n# Load libraries\nsuppressPackageStartupMessages({\n  #For the main problems\n  library(gapminder)\n  library(tidyverse)\n  library(ggrepel)\n  \n  #For the optional problem\n  library(gganimate)\n  library(gifski)\n})\n\n#Create the gap_data dataset\ngap_data &lt;- gapminder |&gt;\n  \n  #Keep only rows where the year is 2007\n  filter(year == 2007) |&gt; \n  \n  #Label column is computed for each continent, separately\n  #Group data by continent before creating the label column\n  #This column will be used for later questions\n  group_by(continent) |&gt; \n  mutate(\n    #Income is highly skewed; create a log scale variant for ease\n    log_income = log(gdpPercap),\n    \n    #The country_label column is used later\n    country_label = case_when(\n      lifeExp %in% c(min(lifeExp), max(lifeExp)) ~ country\n    )\n  )",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-1",
    "href": "html_files/Midterm/midterm_solutions.html#problem-1",
    "title": "BST680 Midterm",
    "section": "Problem 1",
    "text": "Problem 1\nUsing gap_data, create the following plot, use theme elements such as a different backgrounds or text sizes to personalize your plot; it doesn’t need to match my conventions exactly but be creative\nNotes:\n\nThe x-axis and y-axis labels indicate which columns in gap_data were used to make the data\nYou will want to use geom_point(shape = 21) to set the fill of points later in the assignment\n\n\n#Prep a theme chunk that pumps up the text size for the axes and legends; also uses theme_bw\ntheme_cfm &lt;- \n  theme_bw() + \n  theme(plot.title = element_text(size = 30, hjust = 0.5),\n        axis.title = element_text(size = 20), \n        axis.text = element_text(size = 16),\n        legend.title = element_text(size = 20),\n        legend.text = element_text(size = 16))\n\n\n#Create the plot\nplot_curr &lt;- \n  ggplot(data = gap_data, aes(x = gdpPercap, y = lifeExp)) + \n    geom_point(shape = 21) + \n    theme_cfm\n\nplot_curr",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-2",
    "href": "html_files/Midterm/midterm_solutions.html#problem-2",
    "title": "BST680 Midterm",
    "section": "Problem 2",
    "text": "Problem 2\nMake some adjustments:\n\nUse log_income instead of gdpPercap as the x variable\nMake the countries (i.e. the points) have fills that correspond to the continent which the country belongs to\nMake the size of points proportional to the population of the country\n\n\n# Create the plot for problem 2\n\nplot_curr &lt;- \n  ggplot(data = gap_data, aes(x = log_income, y = lifeExp)) + \n    geom_point(aes(fill = continent, size = pop), shape = 21) +\n  theme_cfm\n\nplot_curr",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-3",
    "href": "html_files/Midterm/midterm_solutions.html#problem-3",
    "title": "BST680 Midterm",
    "section": "Problem 3",
    "text": "Problem 3\nMake a few more adjustments:\n\nSet the limits of the x-axis between 6 and 11 (i.e. xlim = c(6, 11))\nSet the limits of the y-axis between 30 and 85 (i.e. ylim = c(30, 85))\nAdd an annotation layer in the center of the plot indicating the year\nClean up the labels for the axes and legends\n\n\n\n\n\n\n\nTip\n\n\n\nThere are multiple ways to to do 3 such as using annotate or geom_text; I would recommend annotate to start but geom_text could prove easier for later questions\nYou might want to consider xlim, ylim and the mean function to help position your label in the exact center of the plot\n\n\n\n#Define some vectors for convenience\nxlim &lt;- c(6, 11)\nylim &lt;- c(30, 85)\nyear_display &lt;- unique(gap_data$year)[1]\n\n\nplot_curr &lt;- \n  ggplot(data = gap_data, aes(x = log_income, y = lifeExp)) + \n    annotate(\"text\", label = year_display, size = 72, color = \"grey\", alpha = 0.35, x = mean(xlim), y = mean(ylim)) + \n    geom_point(aes(size = pop, fill = continent), shape = 21) + \n    scale_y_continuous(name = \"Life Expectancy at Birth (years)\", limits = ylim) + \n    scale_x_continuous(name = \"Income (log GDP per capita)\", limits = xlim) + \n    scale_size_continuous(name = \"Population (millions)\") + \n    scale_fill_discrete(name = \"Continent\") + \n    theme_cfm\n\nplot_curr",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-4",
    "href": "html_files/Midterm/midterm_solutions.html#problem-4",
    "title": "BST680 Midterm",
    "section": "Problem 4",
    "text": "Problem 4\nMake some additional adjustments to your plot:\n\nSet the range of point sizes as c(1,20) hint: you’re using size is an aesthetic which means it has a scale_\nRemove the point size portion from the legend guide\nIncrease the size of points in the fill portion of the legend\n\n\n\n\n\n\n\nTip\n\n\n\nFor 2 and 3, you will need to make use of the guides() function from ggplot2\nFor 3 you will be using override.aes as an argument specifically\nSpend some time with the reference manual and cheat sheets if necessary\n\n\n\nplot_curr &lt;- plot_curr +  \n    scale_size_continuous(name = \"Population (millions)\", range = c(1,20)) + \n    guides(\n      size = \"none\",\n      fill = guide_legend(override.aes = list(size = 8))) + \n    theme_cfm\n\nplot_curr",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-5",
    "href": "html_files/Midterm/midterm_solutions.html#problem-5",
    "title": "BST680 Midterm",
    "section": "Problem 5",
    "text": "Problem 5\nTry arranging gap_data by population size, in descending order, prior to plotting\nThis plot may or may not appear different compared to problem 4\nIn your comments, explain why there is or isn’t a difference in the plot\n\ngap_data &lt;- gap_data |&gt;\n arrange(desc(pop))\n\n#Use %+% to apply a new dataset to the plot object\nplot_curr &lt;- plot_curr %+% gap_data + theme_cfm\n\nplot_curr\n\n\n\n\n\n\n\n\nThis highlights the way ggplot build the components for its geometry calls. Specifically, the geometry is built row by row through the tibble object. By reordering the dataframe in reverse, ggplot now plots the countries with the largest population size (and thus the largest points) first then overlaying the smaller ones on top. Note, smaller geometries would be plotted first with the larger point occluding the smaller ones if the decreasing argument weren’t included.",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-6",
    "href": "html_files/Midterm/midterm_solutions.html#problem-6",
    "title": "BST680 Midterm",
    "section": "Problem 6",
    "text": "Problem 6\nInclude the following label annotations on your plot:\n\nAdd a geom_label_repel layer to the plot that indicates which country in each continent has the highest or lowest life expectancy\nUse show.legend = FALSE to stop the text from being incorporated into the legend;\n\n\n\n\n\n\n\nTip\n\n\n\nMake sure all the labels are the same size and NOT proportional to the population size\nThink about how you want use size and ask “is it an aesthetic or an argument?”\n\n\n\nplot_curr &lt;- \n  plot_curr + \n  geom_label_repel(aes(label = country_label, fill = continent), min.segment.length = 0, size = 6, show.legend = FALSE) + \n    theme_cfm\n\nplot_curr",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-7",
    "href": "html_files/Midterm/midterm_solutions.html#problem-7",
    "title": "BST680 Midterm",
    "section": "Problem 7",
    "text": "Problem 7\n\n\n\n\n\n\nImportant\n\n\n\nThis problem is optional and will require the original gapminder dataset\n\n\nGet creative with animations\n\nUse the gganimate package to make a smooth animation to update the background image of the year variable in the plot\nPut a label over one country of your choosing\nFor added challenge, find a way to make the year label in the background smoothly transition without showing decimal places\n\n\n\n\n\n\n\nTip\n\n\n\nYou can find a great gganimate tutorial here: https://github.com/thomasp85/gganimate\n\n\n\n#Building the plot from the ground up\n\n#Set limits and theme\nxlim &lt;- c(6,11)\nylim &lt;- c(30, 85)\n\ntheme_cfm &lt;- \n  theme_bw() + \n  theme(plot.title = element_text(size = 30, hjust = 0.5),\n        axis.title = element_text(size = 20), \n        axis.text = element_text(size = 16),\n        legend.title = element_text(size = 20),\n        legend.text = element_text(size = 16))\n\n\n\n\n#Make the dataset from gapminder following all the necessary modification done in 1-6\ngap_data &lt;- gapminder |&gt; \n  \n  arrange(year, continent, desc(pop)) |&gt;\n  group_by(year, continent) |&gt;\n  \n  mutate(\n    log_income = log(gdpPercap),\n    #Pick Japan as the country for display\n    country_label = case_when(\n      country %in% c(\"Japan\") ~ country),\n    year_label = as.character(year)\n  ) \n\n\n\n\n\n#The full plot\nplot_curr &lt;- \n  #Main data and aesthetics\n  ggplot(data=gap_data, aes(x = log_income, y = lifeExp)) + \n  \n    #Set text for year at the back, we use geom_text() instead of annotate\n    geom_text(aes(label=sprintf(\"%i\", as.integer(year))), size=72, color=\"grey\", alpha=0.15, x=mean(xlim), y=mean(ylim)) +\n  \n    #Add the points and the label as before\n    geom_point(aes(size = pop, fill = continent), shape = 21) + \n    geom_label_repel(aes(label = country_label, fill = continent), point.padding=NA, size=6, show.legend=F) + \n  \n    #Set scales for labels and limits\n    scale_y_continuous(name = \"Life Expectancy at Birth (years)\", limits = ylim) + \n    scale_x_continuous(name = \"Income (log GDP per capita)\", limits = xlim) + \n    scale_size_continuous(name=\"Population (millions)\", range=c(1,20)) + scale_fill_discrete(name=\"Continent\") + \n  \n    #Update the guides\n    guides(\n      size = \"none\",\n      fill = guide_legend(override.aes=list(size=8))) +\n\n    #Use year as the transition time for gganimate\n    transition_time(year) + \n  \n  labs(title=\"Year: {as.integer(frame_time)}\")  + \n    theme_cfm +  \n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\n\n*The easiest way to handle the background image is to leverage it as a character instead of a numeric or integer object to avoid the decimals\nYou have many options to creat the annimation including:\n\nCreate a character column in the tibble directly to be added to the gap_data object or\nForce it as a character directly in the plot object using something like sprintf() which was done here\n\nOption 1 could be done using something like case_when(year%%5==0) ~ as.character(year) if you only wanted certain years listed\nBear in mind since year is an aesthetic from gap_data you’ll have difficulty using annotate which is why geom_text() is a better options*",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#prepping-the-data-1",
    "href": "html_files/Midterm/midterm_solutions.html#prepping-the-data-1",
    "title": "BST680 Midterm",
    "section": "Prepping the Data",
    "text": "Prepping the Data\n\nsuppressPackageStartupMessages({\n  #For table output\n  library(gt)\n})\ncvd_data &lt;- read_csv(\"data/synthdata_cvd.csv\")\n\n\n\n#This code shows how you can use gt() to make tables in html documents\n#This code can be reused to help you make tables for these problems\n#For details, check out the gt vignette linked below or the Intro file from the first lecture\n#https://gt.rstudio.com/articles/gt.html\n\ncvd_data_dict &lt;- read_rds('data/synthdata_guide.RDS') |&gt; \n  rename(abbreviation = abbr) |&gt;\n  gt() |&gt;\n  \n  #cols_align will not accept vectorized values to align, so each alignment type must be specified\n  #The columns argument can use tidy selection if you want to use things like starts_with() from dplyr\n  cols_align(align = \"left\", columns = c(\"variable\", \"group\", \"label\")) |&gt;\n  cols_align(align = \"center\", columns = c(\"type\", \"unit\", \"abbreviation\")) |&gt;\n\n  #For titles and captions you can wrap the string in html() or md() to use HTML or markdown to format the text\n  #e.g. you can use &lt;br/&gt; to make a new line with html()\n  tab_header(title = html(\"Description of variables in the synthetic cardiovascular disease data\")) |&gt;\n\n  #You can enable html within the table as well, you can specify columns with tidy selection like cols_align\n  #Like the caption, you can also wrap individual cells in html() or md()\n  fmt_markdown(columns = everything()) |&gt;\n\n  #Other stylistic options can be set within the tab_options() function\n  #Here we make the table the full width and make the font size a bit smaller\n  tab_options(table.width = \"100%\",\n              table.font.size = pct(85))\n\n#A final comment, many static options are lost when using either ihtml. arguments within tab_options() or using opt_interactive()\n#I recommend just use static tables for now, there are better packages for dynamic tables\n\nThe synthdata_cvd.csv file contains synthetic data on 10000 participants\nIn this fake study, cardiovascular disease (CVD; stroke or coronary heart disease) events were identified during follow-up with the following two key variables:\n\ntime_chd_strk: The time, in years, from baseline until death, a CVD event, or last contact\nchd_strk: A value of “Yes” indicates that a CVD event occurred at time_chd_strk while a value of “No” indicates that a CVD event did not occur (i.e., death or last contact DID occur) at time_chd_strk\n\nThe other variables in the data are described below:\n\ncvd_data_dict\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescription of variables in the synthetic cardiovascular disease data\n\n\nvariable\ngroup\nlabel\ntype\nunit\nabbreviation\n\n\n\n\nage\nNone\nAge\nnumeric\nyears\nNone\n\n\nsex\nNone\nSex at birth\nfactor\nNone\nNone\n\n\nsbp\nBlood pressure\nSystolic\nnumeric\nmm Hg\nNone\n\n\ndbp\nBlood pressure\nDiastolic\nnumeric\nmm Hg\nNone\n\n\nelev_bp\nBlood pressure\nElevated\nfactor\nNone\nNone\n\n\nalbumin\nKidney function\nUrinary albumin\nnumeric\nmg/24hr\nNone\n\n\ncreatinine\nKidney function\nUrinary creatinine\nnumeric\ng/24hr\nNone\n\n\nalbuminuria\nKidney function\nAlbuminuria\nfactor\nNone\nNone\n\n\nscrcc\nKidney function\nSerum creatinine\nnumeric\nmg/dL\nNone\n\n\ngfr\nKidney function\nestimated GFR\nnumeric\nml/min/1.73 m2\nGFR = glomerular filtration rate\n\n\nlow_gfr\nKidney function\nLow kidney function\nfactor\nNone\nNone\n\n\nbpmeds\nMedication use\nAnti-Hypertensive\nfactor\nNone\nNone\n\n\ndmmeds\nMedication use\nAnti-Diabetic\nfactor\nNone\nNone\n\n\nstatinmeds\nMedication use\nStatin\nfactor\nNone\nNone",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-1-1",
    "href": "html_files/Midterm/midterm_solutions.html#problem-1-1",
    "title": "BST680 Midterm",
    "section": "Problem 1",
    "text": "Problem 1\n\n\n\n\n\n\nTip\n\n\n\nThis will be much easier with some functions we’ve only touched in in lecture\nSpend some time looking at dplyr’s material on colwise operations and scoping using across()\n\n\nStarting with the cvd_data object, select\n\nage (participant age in years)\nsex (participant sex at birth)\nscrcc (serum creatinine)\nsbp (systolic blood pressure)\ndbp (diastolic blood pressure)\nalbumin (urinary albumin)\ncreatinine (urinary creatinine)\nbpmeds (blood pressure medication use)\ndmmeds (anti-diabetic medication use)\nstatinmeds (statin medication use)\ntime_chd_strk (see above)\nchd_strk (see above)\n\nNext, remove participants from the data who were lost to follow up during the first 10 years but be careful not to confuse ‘lost to follow up’ with ‘had a CVD event’\nDetermine the dimensions of your dataset to get the number of rows and columns and compare to the results from the midterm_start_here HTML file; you have many ways to get to these values\n\n#A simple select and filter combination to return a working dataframe.  This will be adapted throughout the problem set\ncvd_filter &lt;- cvd_data |&gt;\n  select(age, sex, scrcc, sbp, dbp, albumin, creatinine, bpmeds, dmmeds, statinmeds, time_chd_strk, chd_strk) |&gt;\n  filter(!(time_chd_strk&lt;10 & chd_strk==\"No\"))\n\n\n#A gt summarization to get the rows and columns of the dataset\ncvd_table &lt;-\n  tibble(Dim = c(\"Rows\", \"Columns\"), \n         Type = c(\"Observations\", \"Variables\"),\n         Count = dim(cvd_filter)) |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\")\n\ncvd_table\n\n\n\n\n\n\n\nDim\nType\nCount\n\n\n\n\nRows\nObservations\n8169\n\n\nColumns\nVariables\n12\n\n\n\n\n\n\n\nRows and columns of the dataset\nNow, create a table summarizing the proportion of missing values in each column of the data using the table provided here as reference to check your work\n\n#Proportion of missing, begin by creating a dataframe initalized with the column names\ncvd_table &lt;- \n  tibble(Variable = colnames(cvd_filter))\n\n#Use summarise_all() to get the percentage\nprop_missing &lt;- summarise(cvd_filter, across(everything(), ~round(sum(is.na(.) / length(.) * 100),2)))\n\n#Coerce the summary tibble to a numeric\ncvd_table$`Percent Missing` &lt;- as.numeric(prop_missing)\n\n\n#Knit a gt for printing\ncvd_table &lt;- cvd_table |&gt; \n  gt() |&gt;\n  cols_align(align = \"left\", columns = 1) |&gt;\n  cols_align(align = \"center\", columns = 2) |&gt;\n  tab_header(html(\"Percentage of missing values&lt;br/&gt;for simulated data variables\"))\n\ncvd_table\n\n\n\n\n\n\n\n\n\n\n\nPercentage of missing values\nfor simulated data variables\n\n\nVariable\nPercent Missing\n\n\n\n\nage\n0.00\n\n\nsex\n0.00\n\n\nscrcc\n1.43\n\n\nsbp\n0.37\n\n\ndbp\n0.37\n\n\nalbumin\n39.75\n\n\ncreatinine\n39.70\n\n\nbpmeds\n0.77\n\n\ndmmeds\n0.81\n\n\nstatinmeds\n0.88\n\n\ntime_chd_strk\n0.00\n\n\nchd_strk\n0.00\n\n\n\n\n\n\n\nLast, remove any row in the data where a participant has a missing value (NA) and print the dimensions of the data now that all rows with at least one missing value are filtered out. Your dimensions should match those given in the start here html file.\n\ncvd_filter &lt;- cvd_filter |&gt;\n  filter(if_all(everything(), ~!is.na(.x)))\n\n#Rows and columns of the dataset using the same table set-up as the first part of question 1\ntable_curr &lt;-\n  tibble(Dim = c(\"Rows\", \"Columns\"), \n         Type = c(\"Observations\", \"Variables\"),\n         Count = dim(cvd_filter)) |&gt;\n  gt() |&gt;\n  cols_align(align = \"center\")\n\ntable_curr\n\n\n\n\n\n\n\nDim\nType\nCount\n\n\n\n\nRows\nObservations\n4821\n\n\nColumns\nVariables\n12\n\n\n\n\n\n\n\nRows and columns of the dataset after removing NA values",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-2-1",
    "href": "html_files/Midterm/midterm_solutions.html#problem-2-1",
    "title": "BST680 Midterm",
    "section": "Problem 2",
    "text": "Problem 2\nUsing the data created in problem 1, identify the oldest male and female who are taking both blood pressure lowering medication and anti-diabetes medication\nUsing these two participants’ data, create the table shown in the starting html file\n\n#Prep the table by filtering to only have bpmeds and dmmeds subjects, then group by gender and filter on the max age for men and women; this will return a 1x2 tibble so no need to ungroup and spread\ntable_curr &lt;- cvd_filter |&gt;\n  group_by(sex) |&gt;\n  filter(bpmeds==\"Yes\" & dmmeds==\"Yes\") |&gt;\n  filter(age==max(age)) |&gt;\n  ungroup() |&gt;\n  select(sex, age) |&gt;\n  rename(Sex = sex, Age = age)\n   \n#Then knit the gt(), including a tab header with html\ntable_curr_print &lt;-\ntable_curr |&gt;\n  gt() |&gt;\n  cols_align(\"center\") |&gt;\n  tab_header(html(\"Age of the oldest participants taking both blood pressure lowering medication&lt;br/&gt;and anti-diabetic medication in male and female groups\"))\n\n\ntable_curr_print\n\n\n\n\n\n\n\n\n\n\n\nAge of the oldest participants taking both blood pressure lowering medication\nand anti-diabetic medication in male and female groups\n\n\nSex\nAge\n\n\n\n\nMale\n90\n\n\nFemale\n84",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-3-1",
    "href": "html_files/Midterm/midterm_solutions.html#problem-3-1",
    "title": "BST680 Midterm",
    "section": "Problem 3",
    "text": "Problem 3\nCreate the following variables:\n\ncvd10: This variable is ‘Yes’ if participants experienced a CVD event during the first 10 years of follow-up, and ‘No’ otherwise.\nalbuminuria: This variable is ‘Yes’ if a participant’s urinary albumin to creatinine ratio is greater than 30 mg/g, and ‘No’ otherwise.\negfr: (estimated glomerular filtration rate) This variable is computed conditionally for males and females based on serum creatinine (i.e., scrcc).\n\nFor females with scrcc \\(\\leq\\) 0.7, \\[\\texttt{gfr} = 166 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.7}\\right)^{-0.329}.\\]\nFor females with scrcc \\(&gt;\\) 0.7, \\[\\texttt{gfr} = 166 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.7}\\right)^{-1.209}.\\]\nFor males with scrcc \\(\\leq\\) 0.9, \\[\\texttt{gfr} = 163 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.9}\\right)^{-0.411}.\\]\nFor males with scrcc \\(\\geq\\) 0.9, \\[\\texttt{gfr} = 163 \\cdot \\left(0.993\\right)^{\\texttt{age}} \\left(\\frac{\\texttt{scrcc}}{0.9}\\right)^{-1.209}.\\]\n\nlow_gfr This variable is Yes if a participant’s estimated glomerular filtration rate is \\(&lt; 60 \\text{ml/min/1.73m}^2\\), and ‘No’ otherwise.\nelev_bp This variable is Yes if any of the following conditions are true:\n\nsystolic blood pressure &gt; 130 mm Hg\ndiastolic blood pressure &gt; 80 mm Hg\nthe participant is currently using blood pressure medications.\n\n\nLast, convert all character (chr) variables into factors (fct)\nApply the glimpse function to your data to show column types and values for all variables\nThis data will be used in all problems that follow and will be referred to as the sample from problem 3\n\n#Still using the filtered dataset without pre 10-year dropouts, just use mutate followed by if_else commands for the logicals and case_when for the more complex egfr.  End with a mutate_if to cast all character variables as factors.  Be sure to albuminuria uses the albumin/creatinine ratio\ncvd_filter &lt;- cvd_filter |&gt;\n  mutate(\n    cvd10 = if_else(time_chd_strk&lt;=10 & chd_strk==\"Yes\", \"Yes\", \"No\"),\n    albuminuria=if_else((albumin/creatinine)&gt;30, \"Yes\", \"No\"),\n    egfr=case_when(sex==\"Female\" & scrcc&lt;=0.7 ~ 166 * 0.993^age * (scrcc/0.7)^-0.329,\n                   sex==\"Female\" & scrcc&gt; 0.7 ~ 166 * 0.993^age * (scrcc/0.7)^-1.209,\n                   sex==\"Male\" & scrcc&lt;=0.9 ~ 163 * 0.993^age * (scrcc/0.9)^-0.411,\n                   sex==\"Male\" & scrcc&gt; 0.9 ~ 163 * 0.993^age * (scrcc/0.9)^-1.209),\n    low_gfr=if_else(egfr&lt;(60), \"Yes\", \"No\"),\n    elev_bp=if_else(sbp&gt;130 | dbp&gt;80 | bpmeds==\"Yes\", \"Yes\", \"No\")) |&gt;\n  mutate_if(is.character, factor)\n\nglimpse(cvd_filter)\n\nRows: 4,821\nColumns: 17\n$ age           &lt;dbl&gt; 50, 43, 69, 33, 40, 67, 61, 54, 59, 65, 36, 77, 80, 56, …\n$ sex           &lt;fct&gt; Female, Female, Female, Female, Male, Female, Female, Fe…\n$ scrcc         &lt;dbl&gt; 0.6637465, 0.8505938, 0.7571701, 0.8505938, 1.2242885, 1…\n$ sbp           &lt;dbl&gt; 132.9989, 110.0764, 124.7468, 123.8299, 112.8271, 144.00…\n$ dbp           &lt;dbl&gt; 78.3681, 62.5962, 66.7467, 67.5768, 80.8584, 67.5768, 78…\n$ albumin       &lt;dbl&gt; 1.81, 1.06, 1.31, 3.70, 0.58, 8.10, 2.15, 6.10, 0.68, 6.…\n$ creatinine    &lt;dbl&gt; 164.0, 156.0, 78.0, 84.0, 153.0, 88.0, 117.0, 223.0, 61.…\n$ bpmeds        &lt;fct&gt; No, No, No, No, No, No, Yes, Yes, Yes, Yes, No, Yes, Yes…\n$ dmmeds        &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ statinmeds    &lt;fct&gt; No, No, No, No, No, No, No, No, No, Yes, No, No, Yes, No…\n$ time_chd_strk &lt;dbl&gt; 11.542779, 12.114990, 11.748118, 11.594798, 11.154004, 2…\n$ chd_strk      &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, Yes, No, No…\n$ cvd10         &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, Yes, No, No…\n$ albuminuria   &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ egfr          &lt;dbl&gt; 118.89649, 96.96503, 92.97899, 104.02139, 84.83699, 58.0…\n$ low_gfr       &lt;fct&gt; No, No, No, No, No, Yes, No, No, No, No, No, No, Yes, No…\n$ elev_bp       &lt;fct&gt; Yes, No, No, No, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-4-1",
    "href": "html_files/Midterm/midterm_solutions.html#problem-4-1",
    "title": "BST680 Midterm",
    "section": "Problem 4",
    "text": "Problem 4\nGroup the data from problem 3 by sex, albuminuria, and low_gfr groups and, for each group, compute the incident rate of CVD per 1000 person-years: \\[\\texttt{incident CVD rate per 1000 person years} = 1000 \\cdot \\frac{\\texttt{no. of CVD events}}{\\texttt{no. of years at risk}}\\]\nAfter creating this summary data, use ggplot to create a tiled figure (i.e. geom_tile) that shows the incident CVD rate for all four categories of albuminuria and low_gfr among males and females, separately\nUse geom_label to place the exact rate of incident CVD as text into each tile of the figure\n\n#Calculate the incidence rate by first grouping on the three factors of interest, then use a summarise statement to calculate the rate as 1000 times the number of events over the total time of observation.  The mutate statement at the end just recasts the factors as numerics to aid with positioning of the labels in the ggplot object\ncvd_filter_plot&lt;- cvd_filter |&gt;\n  group_by(sex, albuminuria, low_gfr) |&gt;\n  summarise(chd_rate=1000*(sum(chd_strk==\"Yes\")/sum(time_chd_strk))) |&gt;\n  mutate(pos_x = as.numeric(albuminuria),\n         pos_y = as.numeric(low_gfr))\n\n`summarise()` has grouped output by 'sex', 'albuminuria'. You can override\nusing the `.groups` argument.\n\n#Prep the plot object, use geom_tile to define the x and y axes with the tile fill according to the calculated incidence rate.  Use scale_fill_gradient to get the coloring/legend correct and then use facet wrap formulated on sex to get the male/female tiles.  Themes can then be used to modify the axis details and the facet strip styles\n\ncvd_plot &lt;- ggplot(cvd_filter_plot) + \n  geom_tile(aes(x = albuminuria, y = low_gfr,fill = chd_rate)) + \n  geom_label(aes(x = pos_x, y = pos_y, label=sprintf(\"%.1f\", chd_rate))) + \n  scale_fill_gradient(name=\"Incident CVD rate\\nper 1000 person-years\", breaks=seq(25,125,25), low=\"white\", high=\"red\") + \n  scale_x_discrete(name=\"Albuminuria\") + scale_y_discrete(name=\"Low kidney function\") + \n  facet_wrap(~sex) + \n  theme_classic() +\n  theme(axis.line=element_blank(), axis.ticks=element_blank(),\n        axis.text=element_text(size=14), axis.title=element_text(face=\"bold\", size=16),\n        legend.title=element_text(face=\"bold.italic\", size=14), legend.text=element_text(size=12),\n        strip.background=element_blank(), strip.text=element_text(face=\"bold.italic\", size=15))\n   \ncvd_plot",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/Midterm/midterm_solutions.html#problem-5-1",
    "href": "html_files/Midterm/midterm_solutions.html#problem-5-1",
    "title": "BST680 Midterm",
    "section": "Problem 5",
    "text": "Problem 5\nCreate a new column in the data from problem 3 that indicates the various combinations of medications taken by each participant using the bpmeds, dmmeds, and statinmeds binary variables\nOverall, there are 2 x 2 x 2 = 8 possible medication patterns (recall that we removed any rows with missing values)\nUsing this variable you create, identify the four most common medication groups in the dataset\nModify the medication group variable so that any other groups apart from the four most common ones are labeled as ‘Other’\nFor example, this may include:\n\nA group wherein the participant is taking no medication at all\nA group who is taking medication to lower blood pressure only with no other medications\nA category for those taking statins plus medication to lower blood pressure\nA category encompassing all other combinations\n\nOverall, there are 2 x 2 x 2 = 8 possible medication patterns (recall that we removed any rows with missing values)\nPresent the frequency and proportion of observations for each medical profile and stratify your results by sex groups\n\n\n\n\n\n\nTip\n\n\n\nSpend some time with forcats to see how you can make this process easier\n\n\n\n#To prep this final table, use interaction to create the 8-level factor, the sort by frequency (fct_infreq), then lump all but the top four levels (fct_lump), then rename the remaining factor levels as needed (fct_recode)\ncvd_filter_table &lt;- cvd_filter |&gt;\n  mutate(med_use = interaction(bpmeds, dmmeds, statinmeds, sep=\"_\"),\n         med_use = fct_infreq(med_use), \n         med_use = fct_lump(med_use, n=4), \n         med_use = fct_recode(med_use, \"No Medications\"=\"No_No_No\", \"BP Meds Only\"=\"Yes_No_No\", \n                            \"BP Meds and Statins\"=\"Yes_No_Yes\", \"BP and DM Meds\"=\"Yes_Yes_No\")) |&gt;\n \n#Once the factor is set, group by gender, get a count within the levels, calculate the frequency, and then use the str_lue to get the final string that will be presented in the table, spread makes the table wide in a pivot fashion\n  group_by(sex) |&gt;\n  count(med_use, name = \"count_curr\") |&gt;\n  mutate(\n    freq_curr = round(count_curr/sum(count_curr)*100),\n    string_curr = str_glue(\"{count_curr} ({freq_curr}%)\")) |&gt;\n  ungroup() |&gt;\n  select(sex, \"Medication\\nProfile\"=med_use, string_curr) |&gt;\n  spread(sex, string_curr)\n\n#Format the gt() a bit and we're good\ncvd_filter_table &lt;- cvd_filter_table |&gt;\n  gt() |&gt;\n  cols_align(\"left\", 1) |&gt;\n  cols_align(\"center\", 2:3) |&gt;\n  tab_header(md(\"Top four medication profiles\\\\\\nin the data from problem 3\")) |&gt;\n  tab_footnote(\"Table values are frequency (%)\")\n  \ncvd_filter_table\n\n\n\n\n\n\n\n\n\n\n\n\nTop four medication profiles\nin the data from problem 3\n\n\nMedication Profile\nFemale\nMale\n\n\n\n\nNo Medications\n1355 (44%)\n911 (53%)\n\n\nBP Meds Only\n1006 (32%)\n420 (25%)\n\n\nBP and DM Meds\n254 (8%)\n127 (7%)\n\n\nBP Meds and Statins\n210 (7%)\n115 (7%)\n\n\nOther\n284 (9%)\n139 (8%)\n\n\n\nTable values are frequency (%)",
    "crumbs": [
      "Home",
      "Midterm",
      "Midterm Solutions"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html",
    "href": "html_files/01_Intro/intro_to_Quarto.html",
    "title": "Introduction to Quarto and gt",
    "section": "",
    "text": "In this tutorial we’ll discuss some basics of Quarto and the gt() vignette for tables",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#the-yaml",
    "href": "html_files/01_Intro/intro_to_Quarto.html#the-yaml",
    "title": "Introduction to Quarto and gt",
    "section": "The YAML",
    "text": "The YAML\nEverything begins and ends with the YAML found at the top of this .qmd file\nIn addition to specifying metadata related to the document (e.g. author), you can control several aspects of how the document is formatted\nWe’ll touch on the important ones but you can find brief descriptions on the various formatting options at the Quarto Reference Page\n\n#The current contents of the YAML\n---\ntitle: \"Introduction to Quarto and gt\"\nauthor: \"Chad Murchison\"\ndate-modified: last-modified\nformat:\n  html:\n    code_folding: show\n    df-print: paged\n    fig-caption: true\n    fig-height: 4\n    fig-width: 7\n    highlight: tango\n    theme: cosmo\n    toc: true\n    toc-float: true\n---",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#markdown-basics",
    "href": "html_files/01_Intro/intro_to_Quarto.html#markdown-basics",
    "title": "Introduction to Quarto and gt",
    "section": "Markdown basics",
    "text": "Markdown basics\nWe can find a lot of details on the basics of Markdown that are used by Quarto at https://quarto.org/docs/authoring/markdown-basics.html, some of which we’ll be discussing here\n\nAnd example - Subsections\nThe pound symbol lets you create new sections and subsections in your Quarto document. A single pound creates a new section, double pound creates a subsection, triple pound creates sub-subsection, and so on",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#paged-data",
    "href": "html_files/01_Intro/intro_to_Quarto.html#paged-data",
    "title": "Introduction to Quarto and gt",
    "section": "Paged data",
    "text": "Paged data\nTables can easily be displayed, even with next to no modification on the R side\nThe df-print: paged option is a wonderful option. It allows you to print data in an interactive way\n\niris",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#including-plots",
    "href": "html_files/01_Intro/intro_to_Quarto.html#including-plots",
    "title": "Introduction to Quarto and gt",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#themes",
    "href": "html_files/01_Intro/intro_to_Quarto.html#themes",
    "title": "Introduction to Quarto and gt",
    "section": "Themes",
    "text": "Themes\nQuarto includes 25 different themes from the Boostwatch\nA full list can be found on the Quarto Guide on HTML Theming\nTry replacing the word ‘united’ in the YAML header with some of these theme and find something you like\nYou will spend a lot of time staring at these documents, so it’s worth investing some time to make them look nice",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#code-highlights",
    "href": "html_files/01_Intro/intro_to_Quarto.html#code-highlights",
    "title": "Introduction to Quarto and gt",
    "section": "Code highlights",
    "text": "Code highlights\nThe highlight arguemtn specifies the syntax highlighting style\nAll standard Pandoc highlight themes are supported, along with several others; you can find a full list at https://quarto.org/docs/output-formats/html-code.html#highlighting\nPass null to prevent syntax highlighting",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#basics-of-gt",
    "href": "html_files/01_Intro/intro_to_Quarto.html#basics-of-gt",
    "title": "Introduction to Quarto and gt",
    "section": "Basics of gt",
    "text": "Basics of gt\nLet’s use a less common dataset that is available in the R datasets package: islands. It’s actually not a data frame but a named vector. That’s okay though, the code below converts it into a tibble (we’ll learn more about these later):\n\n# ctrl + alt + p will run all previous code.\n# ctrl + enter will run highlighted code\n\n# how pipes work: \n# mean(x) is equivalent to x |&gt; mean()\n\nislands_tbl &lt;- tibble::enframe(islands, value = 'size') |&gt;\n  dplyr::arrange(desc(size)) |&gt;\n  dplyr::slice(1:10)\n\n# Display the table\nislands_tbl\n\n\n  \n\n\n\nGiven that islands_tbl is a tibble, we now have a suitable input for gt.\nThe main entry point into the gt API is the gt() function. If we pass islands_tbl to the function gt(), we’ll get a gt Table as output. As an aside, we could have easily used a data frame instead as valid Table Data for gt.\n\n# Create a display table showing ten of\n# the largest islands in the world\ngt_tbl_1 &lt;- gt::gt(data = islands_tbl)\n\n# Show the gt Table\ngt_tbl_1\n\n\n\n\n\n\n\nname\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\n\n\n\n\nThat doesn’t look too bad. Sure, it’s basic but we really didn’t really ask for much. We did receive a proper table with column labels and the data. Also, that default striping is a nice touch. Oftentimes however, you’ll want a bit more: a Table header, a Stub, and sometimes footnotes and source notes in the Table Footer part.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#adding-parts",
    "href": "html_files/01_Intro/intro_to_Quarto.html#adding-parts",
    "title": "Introduction to Quarto and gt",
    "section": "Adding parts",
    "text": "Adding parts\nThe gt package makes it relatively easy to add parts so that the resulting gt Table better conveys the information you want to present. These table parts work well together and there the possible variations in arrangement can handle most tabular presentation needs. The previous gt Table demonstrated had only two parts, the Column Labels and the Table Body. The next few examples will show all of the other table parts that are available.\nThis is the way the main parts of a table (and their subparts) fit together:\n\n\n\nThe parts (roughly from top to bottom) are:\n\nthe Table Header (optional; with a title and possibly a subtitle)\nthe Stub and the Stub Head (optional; contains row labels, optionally within row groups having row group labels and possibly summary labels when a summary is present)\nthe Column Labels (contains column labels, optionally under spanner column labels)\nthe Table Body (contains columns and rows of cells)\nthe Table Footer (optional; possibly with footnotes and source notes)\n\nThe way that we add parts like the Table Header and footnotes in the Table Footer is to use the tab_*() family of functions. A Table Header is easy to add so let’s see how the previous table looks with a title and a subtitle. We can add this part using the tab_header() function:\n\n# Make a display table with the `islands_tbl`\n# table; put a heading just above the column labels\ngt_tbl_2 &lt;- gt::tab_header(\n  data = gt_tbl_1,\n  title = \"Large Landmasses of the World\",\n  subtitle = \"The top ten largest are presented\"\n)\n\n# Show the gt Table\ngt_tbl_2\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nname\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\n\n\n\n\nThe Header table part provides an opportunity to describe the data that’s presented. The subtitle, which functions as a subtitle, is an optional part of the Header. We may also style the title and subtitle using Markdown! We do this by wrapping the values passed to title or subtitle with the md() function. Here is an example:\n\n# Use markdown for the heading's `title` and `subtitle` to\n# add bold and italicized characters\n\ngt_tbl_3 &lt;- gt::tab_header(\n  data = gt_tbl_1,\n  title = md(\"__Large Landmasses of the World__\"),\n  subtitle = md(\"The *top ten* largest are presented\")\n)\n\n# Show the gt Table\ngt_tbl_3\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nname\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\n\n\n\n\nA source note can be added to the table’s footer through use of the tab_source_note() function. It works in the same way as tab_header() (it also allows for Markdown inputs) except it can be called multiple times—each invocation results in the addition of a source note.\n\n# Display the `islands_tbl` data with a heading and\n# two source notes\n\ngt_tbl_4 &lt;- gt::tab_source_note(\n  data = gt_tbl_3,\n  source_note = \"Source: The World Almanac and Book of Facts, 1975, page 406.\"\n)\n\ngt_tbl_5 &lt;- gt::tab_source_note(\n  data = gt_tbl_4,\n  source_note = md(\"McNeil, D.R. (1977) _Interactive Data Analysis_. Wiley.\")\n)\n\n# Show the gt Table\ngt_tbl_5\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nname\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#the-stub",
    "href": "html_files/01_Intro/intro_to_Quarto.html#the-stub",
    "title": "Introduction to Quarto and gt",
    "section": "The stub",
    "text": "The stub\nThe Stub is the area to the left in a table that contains row labels, and may contain row group labels, and summary labels. Those subparts can be grouped in a sequence of row groups. The Stub Head provides a location for a label that describes the Stub. The Stub is optional since there are cases where a Stub wouldn’t be useful (e.g., the display tables presented above were just fine without a Stub).\nAn easy way to generate a Stub part is by specifying a stub column in the gt() function with the rowname_col argument. Alternatively, we can have an input dataset with a column named rowname—this magic column will signal to gt that that column should be used as the stub, making row labels. Let’s add a stub with our islands_tbl dataset by modifying the call to gt():\n\n# Create a gt table showing ten of the\n# largest islands in the world; this\n# time with a stub\ngt_tbl_1 &lt;- gt::gt(islands_tbl, rowname_col = \"name\")\n\n# Show the gt Table\ngt_tbl_1\n\n\n\n\n\n\n\n\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\n\n\n\n\nNotice that the landmass names are off the the left in an unstriped area? That’s the stub. We can apply what’s known as a stubhead label. This label can be added with the tab_stubhead() function:\n\n# Generate a simple table with a stub\n# and add a stubhead label\ngt_tbl_1 &lt;- gt::tab_stubhead(data = gt_tbl_1, label = \"landmass\")\n\n# Show the gt Table\ngt_tbl_1\n\n\n\n\n\n\n\nlandmass\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\n\n\n\n\nA very important thing to note here is that the table now has one column. Before, when there was no stub, two columns were present (with column labels name and size) but now column number 1 (the only column) is size.\nTo apply our table parts as before (up to and including the footnotes) we use the following statements:\n\n# Display the `islands_tbl` data with a stub,\n# a heading, source notes, and footnotes\n\n# Make a display table with the `islands_tbl`\n# table; put a heading just above the column labels\ngt_tbl_2 &lt;- gt::tab_header(\n  data = gt_tbl_1,\n  title = md(\"__Large Landmasses of the World__\"),\n  subtitle = md(\"The _top ten_ largest are presented\")\n)\n\ngt_tbl_3 &lt;- gt::tab_source_note(\n  data = gt_tbl_2,\n  source_note = \"Source: The World Almanac and Book of Facts, 1975, page 406.\"\n)\n\ngt_tbl_4 &lt;- gt::tab_source_note(\n  data = gt_tbl_3,\n  source_note = md(\"McNeil, D.R. (1977) _Interactive Data Analysis_. Wiley.\")\n)\n\n\n# Show the gt Table\ngt_tbl_4\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nlandmass\nsize\n\n\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.\n\n\n\n\n\n\n\n\nLet’s incorporate row groups into the display table. This divides rows into groups, creating row groups, and results in a display of a row group labels right above the each group. This can be easily done with a table containing row labels. We can make a new row group with each call of the tab_row_group() function. The inputs are group names in the group argument, and row references in the rows argument. We can use any of the strategies to reference rows as we did we footnotes (e.g., vectors of names/indices, select helpers, etc.).\nHere we will create three row groups (with row group labels continent, country, and subregion) to have a grouping of rows.\n\n# Add a column to islands_tbl\nislands_tbl$group &lt;- c(\n  \"Continents\",\n  \"Continents\",\n  \"Continents\",\n  \"Continents\",\n  \"Continents\",\n  \"Continents\",\n  \"Other\",\n  \"Other\",\n  \"Other\",\n  \"Other\"\n)\n\ngt_tbl_1 &lt;- gt::gt(islands_tbl, rowname_col = \"name\", groupname_col = 'group')\ngt_tbl_2 &lt;- gt::tab_stubhead(data = gt_tbl_1, label = \"landmass\")\n\ngt_tbl_3 &lt;- gt::tab_header(\n  data = gt_tbl_2,\n  title = md(\"__Large Landmasses of the World__\"),\n  subtitle = md(\"The _top ten_ largest are presented\")\n)\n\ngt_tbl_4 &lt;- gt::tab_source_note(\n  data = gt_tbl_3,\n  source_note = \"Source: The World Almanac and Book of Facts, 1975, page 406.\"\n)\n\ngt_tbl_5 &lt;- gt::tab_source_note(\n  data = gt_tbl_4,\n  source_note = md(\"McNeil, D.R. (1977) _Interactive Data Analysis_. Wiley.\")\n)\n\n# Show the gt Table\ngt_tbl_5\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nlandmass\nsize\n\n\n\n\nContinents\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nOther\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.\n\n\n\n\n\n\n\n\nTwo row groups have been made since there are two unique categories under groupname. Across the top of each row group is the row group label contained in a separate row (these cut across the field and they contain nothing but the row group label). A rearrangement of rows is carried out to ensure each of the rows is collected within the appropriate row groups.\nHaving groups of rows in row groups is a great way to present information - let’s make it even cleaner. The tab_style() function lets you access and modify any conceivable part of your table. In this example, we’ll access the rows that describe groups and then we’ll set their text to be bold.\n\ngt_tbl_6 &lt;- gt::tab_style(\n  data = gt_tbl_5,\n  locations = cells_row_groups(), \n  style = cell_text(weight = 'bold')\n)\n\ngt_tbl_6\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nlandmass\nsize\n\n\n\n\nContinents\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nOther\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.\n\n\n\n\n\n\n\n\nWe will circle back to grouping rows when we have learned about group_by in the dplyr package. We will also talk about including data summaries particular to each group is a natural extension of this idea. This process of adding summary rows with summary labels is covered here if you are eager to learn more.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#column-labels",
    "href": "html_files/01_Intro/intro_to_Quarto.html#column-labels",
    "title": "Introduction to Quarto and gt",
    "section": "Column labels",
    "text": "Column labels\nThe table’s Column Labels part contains, at a minimum, columns and their column labels. The last example had a single column: size. Let’s give it a better label.\n\ngt_tbl_7 &lt;- gt::cols_label(\n  .data = gt_tbl_6,\n  size = \"Area in square miles\"\n)\n\n# Show the gt Table\ngt_tbl_7\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nlandmass\nArea in square miles\n\n\n\n\nContinents\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nOther\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.\n\n\n\n\n\n\n\n\nIf you have some experience with html code, you can apply the html function to format your labels:\n\ngt_tbl_7 &lt;- gt::cols_label(\n  .data = gt_tbl_6,\n  size = html(\"Area, miles&lt;sup&gt;2&lt;/sup&gt;\")\n)\n\n# Show the gt Table\ngt_tbl_7\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nlandmass\nArea, miles2\n\n\n\n\nContinents\n\n\nAsia\n16988\n\n\nAfrica\n11506\n\n\nNorth America\n9390\n\n\nSouth America\n6795\n\n\nAntarctica\n5500\n\n\nEurope\n3745\n\n\nOther\n\n\nAustralia\n2968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#format-values",
    "href": "html_files/01_Intro/intro_to_Quarto.html#format-values",
    "title": "Introduction to Quarto and gt",
    "section": "Format values",
    "text": "Format values\nThe last thing we’ll do to finish this table is format values in a specific column.\n\ngt::fmt_number(\n  data = gt_tbl_7, \n  columns = 'size', \n  sep_mark = ',',\n  decimals = 0\n)\n\n\n\n\n\n\n\nLarge Landmasses of the World\n\n\nThe top ten largest are presented\n\n\nlandmass\nArea, miles2\n\n\n\n\nContinents\n\n\nAsia\n16,988\n\n\nAfrica\n11,506\n\n\nNorth America\n9,390\n\n\nSouth America\n6,795\n\n\nAntarctica\n5,500\n\n\nEurope\n3,745\n\n\nOther\n\n\nAustralia\n2,968\n\n\nGreenland\n840\n\n\nNew Guinea\n306\n\n\nBorneo\n280\n\n\n\nSource: The World Almanac and Book of Facts, 1975, page 406.\n\n\nMcNeil, D.R. (1977) Interactive Data Analysis. Wiley.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#but-why",
    "href": "html_files/01_Intro/intro_to_Quarto.html#but-why",
    "title": "Introduction to Quarto and gt",
    "section": "But why?",
    "text": "But why?\nClearly, this is not as straightforward as writing our numbers in a Microsoft Word document. In fact, you probably could have completed 3 tables in Microsoft Word in the amount of time it took me to explain how this code works. So, why bother?\nAgility and Accuracy.\n\nYou will be asked to re-do analyses over and over.\nIn some cases, the tables will be very thorough and tedious.\nIf you learn this now, you can automate your analysis so that the tables you make are self-populated.\n\nNo more copying and pasting your numbers\nNo more errors from copying and pasting numbers to the incorrect place!\n\nYou will also feel like a programming wizard every time your tables can be updated in an automated way.",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/intro_to_Quarto.html#learning-more",
    "href": "html_files/01_Intro/intro_to_Quarto.html#learning-more",
    "title": "Introduction to Quarto and gt",
    "section": "Learning more",
    "text": "Learning more\nThis covers a minimal first example and we will be learning more about gt() throughout the semester\nTo learn more about the package or to get help when you are using gt for homework, the package website is a great resource",
    "crumbs": [
      "Home",
      "Additional Info",
      "01a - Intro to Quarto and gt()"
    ]
  },
  {
    "objectID": "html_files/01_Intro/exercises.html",
    "href": "html_files/01_Intro/exercises.html",
    "title": "Table Exercise",
    "section": "",
    "text": "Get some practice working with gt\nUse what you learned in the intro to markdown file to create the table below:\n\nHints:\n\nNote, we’re using rows 1, 2, 3, 51, 52, 53, 101, 102, and 103 of the iris dataset\nThe iris dataset is already loaded in your R environment, no need to import it\n\n\nlibrary(gt)\nreadr::read_rds('solutions/iris_table.rds')\n\n\n\n\n  \n    \n      Iris dataset\n    \n    \n      The first three rows for each species are presented\n    \n    \n      Sepal Length\n      Sepal Width\n      Petal Length\n      Petal Width\n    \n  \n  \n    \n      Setosa\n    \n    5.1\n3.5\n1.4\n0.2\n    4.9\n3.0\n1.4\n0.2\n    4.7\n3.2\n1.3\n0.2\n    \n      Versicolor\n    \n    7.0\n3.2\n4.7\n1.4\n    6.4\n3.2\n4.5\n1.5\n    6.9\n3.1\n4.9\n1.5\n    \n      Virginica\n    \n    6.3\n3.3\n6.0\n2.5\n    5.8\n2.7\n5.1\n1.9\n    7.1\n3.0\n5.9\n2.1\n  \n  \n    \n      Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems Annals of Eugenics, 7, Part II, 179–188.\n    \n    \n      The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5.\n    \n    \n      All table values are in centimeters.\n    \n  \n  \n\n\n\n\n\n\nThere are a couple of things not discussed in the vignette that are applied here, not necessary but if you’re feeling ambitious…\n\nProper case on the species names\nHint - Not a gt function, do this early\nCenter aligning the columns\nHint - Use the gt::col_align() function\nUsing Georgia as the table font\nHint - There are many opt_ functions in gt, maybe there’s one for table fonts?\nRemoving bootstrap striping\n\n\n\n\n\n\n\nCaution\n\n\n\n#4 will take some digging in Quarto, good luck!\n\n\n\n#INSERT YOUR CODE HERE - DON'T FORGET TO COMMENT",
    "crumbs": [
      "Home",
      "Assignments",
      "01 - Working with Tables"
    ]
  },
  {
    "objectID": "html_files/01_Intro/exercises.html#problem-1",
    "href": "html_files/01_Intro/exercises.html#problem-1",
    "title": "Table Exercise",
    "section": "",
    "text": "Get some practice working with gt\nUse what you learned in the intro to markdown file to create the table below:\n\nHints:\n\nNote, we’re using rows 1, 2, 3, 51, 52, 53, 101, 102, and 103 of the iris dataset\nThe iris dataset is already loaded in your R environment, no need to import it\n\n\nlibrary(gt)\nreadr::read_rds('solutions/iris_table.rds')\n\n\n\n\n  \n    \n      Iris dataset\n    \n    \n      The first three rows for each species are presented\n    \n    \n      Sepal Length\n      Sepal Width\n      Petal Length\n      Petal Width\n    \n  \n  \n    \n      Setosa\n    \n    5.1\n3.5\n1.4\n0.2\n    4.9\n3.0\n1.4\n0.2\n    4.7\n3.2\n1.3\n0.2\n    \n      Versicolor\n    \n    7.0\n3.2\n4.7\n1.4\n    6.4\n3.2\n4.5\n1.5\n    6.9\n3.1\n4.9\n1.5\n    \n      Virginica\n    \n    6.3\n3.3\n6.0\n2.5\n    5.8\n2.7\n5.1\n1.9\n    7.1\n3.0\n5.9\n2.1\n  \n  \n    \n      Fisher, R. A. (1936) The use of multiple measurements in taxonomic problems Annals of Eugenics, 7, Part II, 179–188.\n    \n    \n      The data were collected by Anderson, Edgar (1935). The irises of the Gaspe Peninsula, Bulletin of the American Iris Society, 59, 2–5.\n    \n    \n      All table values are in centimeters.\n    \n  \n  \n\n\n\n\n\n\nThere are a couple of things not discussed in the vignette that are applied here, not necessary but if you’re feeling ambitious…\n\nProper case on the species names\nHint - Not a gt function, do this early\nCenter aligning the columns\nHint - Use the gt::col_align() function\nUsing Georgia as the table font\nHint - There are many opt_ functions in gt, maybe there’s one for table fonts?\nRemoving bootstrap striping\n\n\n\n\n\n\n\nCaution\n\n\n\n#4 will take some digging in Quarto, good luck!\n\n\n\n#INSERT YOUR CODE HERE - DON'T FORGET TO COMMENT",
    "crumbs": [
      "Home",
      "Assignments",
      "01 - Working with Tables"
    ]
  },
  {
    "objectID": "html_files/02_Visual/exercises_start_here.html",
    "href": "html_files/02_Visual/exercises_start_here.html",
    "title": "Data Visualization Basics",
    "section": "",
    "text": "Overview\nThe gapminder data are related to a famous TED talk given by Hans Rosling. In his talk, Dr. Rosling shows an animated visualization depicting the relationship between life expectancy and average income levels by country. Our goal in this module is to reproduce Dr. Rosling’s visualization.\nWe will access the gapminder data from the gapminder R package. This package contains a dataset (technically, a tibble) called gapminder with 6 variables:\n\n\n\nvariable\nmeaning\n\n\n\n\ncountry\ncountry\n\n\ncontinent\ncontinent\n\n\nyear\nyear\n\n\nlifeExp\nlife expectancy at birth\n\n\npop\ntotal population\n\n\ngdpPercap\nper-capita GDP\n\n\n\nPer-capita GDP (Gross domestic product) is given in units of international dollars, “a hypothetical unit of currency that has the same purchasing power parity that the U.S. dollar had in the United States at a given point in time” – 2005, in this case.\nNote: the gapminder R package exists for the purpose of teaching and making code examples. It is an excerpt of data found in specific spreadsheets on Gapminder.org circa 2010. It is not a definitive source of socioeconomic data.\n\n\nPackages\nLoad the tidyverse and gapminder packages. We are using tidyverse to access the ggplot2 package and using gapminder to access the data.\n\n\nInspect your data\nIn gapminder, each country has 12 rows distinguished by year.\n\n\n\n  \n\n\n\n\n\nExercise 1\nCreate a scatter plot using gdpPercap as the x-variable and lifeExp as the y-variable:\n\n\n\n\n\n\n\n\n\n\n#######################\n###YOUR CODE HERE!!!###\n#######################\n\nggplot(data=gapminder) + \n  aes(x = gdpPercap, y=lifeExp) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\nExercise 2\nModify your figure from exercise 1: transform the scale of your x-axis to be in log base 10 units. (See ?scale_x_log10)\n\n\n\n\n\n\n\n\n\n\n#######################\n###YOUR CODE HERE!!!###\n#######################\n\nggplot(data=gapminder) + \n  aes(x = gdpPercap, y=lifeExp) + \n  geom_point() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\n\n\nExercise 3\nAdd x- and y-axis labels to your figure from exercise 2.\n\n\n\n\n\n\n\n\n\n\n#######################\n###YOUR CODE HERE!!!###\n#######################\n\n\n\nExercise 4\nAdd a smoothed curve to your plot, showing the overall population trend. (See ?geom_smooth)\n\n\n\n\n\n\n\n\n\n\n#######################\n###YOUR CODE HERE!!!###\n#######################\n\n\n\nExercise 5\nAdjust the points in your graph:\n\nSet their shape to be 21\nSet their color to be 'black'\nSet their fill to be 'grey'\n\nAdjust the overall population trend as well:\n\nSet the line’s color to be 'red'\nRemove the standard errors (shaded region around the line) from the plot.\n\n\n\n\n\n\n\n\n\n\n\n#######################\n###YOUR CODE HERE!!!###\n#######################\n\n\n\nExercise 6\nGo to the ggplot2 theme() reference page and scroll through the pictures that show some of the built-in ggplot2 themes. Pick a theme that you like and add it to the figure you created in exercise 5.\n\n\n\n\n\n\n\n\n\n\n#######################\n###YOUR CODE HERE!!!###\n#######################\n\n\n\nExercise 7\nThere is something happening in the upper levels of income. The population trend between income and life expectancy changes direction. There is an R package called plotly that can help you explore ggplot figures interactively. Converting a ggplot2 figure into a plotly figure is straightforward:\n\n#First call the library\nlibrary(plotly, warn.conflicts = FALSE)\n\n\n# step 1: create a ggplot2 figure\n\n# step 2: if you want to see data for individual points in your\n#         graph, you can add the label values using aes(), like this:\ngg_figure &lt;- read_rds('solutions/06_solution.rds') + \n  aes(label = country)\n  \n# step 3: use ggplotly on the figure\nggplotly(gg_figure)\n\n\n\n\n\nYou can tell by hovering your mouse over the far right points in the figure that the higher income but lower life expectancy country is Kuwait. Now, re-create this figure, but use year as a label instead of country, and identify the years that account for these points.\nOnce you’ve seen the year values associated with the points in the upper-income but lower than expected life expectancy, formulate a hypothesis explaining your data. After you’ve written your hypothesis down, go to Wikipedia’s Kuwait page and read about their modern history. Was your hypothesis correct?\n\n#######################\n###YOUR CODE HERE!!!###\n#######################",
    "crumbs": [
      "Home",
      "Assignments",
      "02 - Visualization Basics"
    ]
  },
  {
    "objectID": "html_files/03_Program/class_exercises.html",
    "href": "html_files/03_Program/class_exercises.html",
    "title": "Programming basics",
    "section": "",
    "text": "These exercises will help you practice what you have learned about functions and vectors.",
    "crumbs": [
      "Home",
      "Assignments",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "html_files/03_Program/class_exercises.html#overview",
    "href": "html_files/03_Program/class_exercises.html#overview",
    "title": "Programming basics",
    "section": "",
    "text": "These exercises will help you practice what you have learned about functions and vectors.",
    "crumbs": [
      "Home",
      "Assignments",
      "03 - Programming Basics"
    ]
  },
  {
    "objectID": "html_files/04_Isolate/class_exercises.html",
    "href": "html_files/04_Isolate/class_exercises.html",
    "title": "Isolating data with dplyr",
    "section": "",
    "text": "NHANES (The National Health and Nutrition Examination Survey) was designed to assess the health and nutritional status of the US population and is conducted by the National Center for Health Statistics of the Centers for Disease Control and Prevention. Since 1999-2000, NHANES has been conducted in two-year cycles. For each cycle, potential participants are identified through stratified, multistage probability sampling of the non-institutionalized US population. In this set of exercises, we will use the ten cycles conducted from 1999-2000 through 2017-2018.\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n  \n\n\n\n\n\n\nReview this briefly and use it as a reference to engage with the exercises below. A data dictionary is more comprehensive than these two columns,but these two columns are the core components of a data dictionary. I highly recommend you only engage with data when there is a data dictionary available. If a collaborator cannot share one of these with you when they ask you to analyze your data, then they should not be your collaborator.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nexam_status\nHow did SP engage with exam?\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\npregnant\nwas SP pregnant at time of exam?\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nn_msr_sbp\nNumber of valid systolic BP readings\n\n\nn_msr_dbp\nNumber of valid diastolic BP readings\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignments",
      "04 - Isolation with dplyr"
    ]
  },
  {
    "objectID": "html_files/04_Isolate/class_exercises.html#import",
    "href": "html_files/04_Isolate/class_exercises.html#import",
    "title": "Isolating data with dplyr",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Home",
      "Assignments",
      "04 - Isolation with dplyr"
    ]
  },
  {
    "objectID": "html_files/04_Isolate/class_exercises.html#data-dictionary",
    "href": "html_files/04_Isolate/class_exercises.html#data-dictionary",
    "title": "Isolating data with dplyr",
    "section": "",
    "text": "Review this briefly and use it as a reference to engage with the exercises below. A data dictionary is more comprehensive than these two columns,but these two columns are the core components of a data dictionary. I highly recommend you only engage with data when there is a data dictionary available. If a collaborator cannot share one of these with you when they ask you to analyze your data, then they should not be your collaborator.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nexam_status\nHow did SP engage with exam?\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\npregnant\nwas SP pregnant at time of exam?\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nn_msr_sbp\nNumber of valid systolic BP readings\n\n\nn_msr_dbp\nNumber of valid diastolic BP readings\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignments",
      "04 - Isolation with dplyr"
    ]
  },
  {
    "objectID": "html_files/05_Transform/class_exercises.html",
    "href": "html_files/05_Transform/class_exercises.html",
    "title": "Derive information with dplyr",
    "section": "",
    "text": "NHANES (The National Health and Nutrition Examination Survey) was designed to assess the health and nutritional status of the US population and is conducted by the National Center for Health Statistics of the Centers for Disease Control and Prevention. Since 1999-2000, NHANES has been conducted in two-year cycles. For each cycle, potential participants are identified through stratified, multistage probability sampling of the non-institutionalized US population. In this set of exercises, we will use the ten cycles conducted from 1999-2000 through 2017-2018.\n\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n  \n\n\n\n\n\n\nReview this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignments",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/05_Transform/class_exercises.html#import",
    "href": "html_files/05_Transform/class_exercises.html#import",
    "title": "Derive information with dplyr",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Home",
      "Assignments",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/05_Transform/class_exercises.html#data-dictionary",
    "href": "html_files/05_Transform/class_exercises.html#data-dictionary",
    "title": "Derive information with dplyr",
    "section": "",
    "text": "Review this briefly and use it as a reference to engage with the exercises below.\n\n\n\n\n\n\n\n\nDescription of NHANES data\n\n\nVariable name\nVariable description\n\n\n\n\nseqn\nSP identifier\n\n\nexam\nNHANES exam year\n\n\npsu\nprimary sampling unit\n\n\nstrata\nsurvey strata\n\n\nwts_mec_2yr\nsurvey weights\n\n\nage\nSP age, years\n\n\nage_group\nSP age group, years\n\n\nsex\nSP sex\n\n\nrace_ethnicity\nSP race and/or ethnicity\n\n\neducation\nSP education\n\n\nincome_hh\nSP household income\n\n\nbp_sys_mmhg\nSP systolic blood pressure, mm Hg\n\n\nbp_dia_mmhg\nSP diastolic blood pressure, mm Hg\n\n\nbp_controlled\nDid SP have controlled BP? (&lt;140/90 mm Hg)\n\n\nacr_mgg\nSP albumin-to-creatinine ratio, mg/g\n\n\nalbuminuria\nDid SP have albuminuria? (ACR &gt; 30 mg/g)\n\n\nchol_hdl_mgdl\nSP HDL-cholesterol, mg/dl\n\n\nchol_total_mgdl\nSP total cholesterol, mg/dl\n\n\nhealth_insurance\nSP health insurance status\n\n\nbp_high_aware\nSP ever told by Dr: 'you have high blood pressure'?\n\n\nbp_meds\nSP currently using antihypertensive medication?\n\n\nhc_usual_facility\nSP has a usual healthcare facility?\n\n\nhc_visit_1yr\nSP visited their healthcare facility last year?\n\n\n\nSP = survey participant; BP = blood pressure; HDL = high density lipoprotein",
    "crumbs": [
      "Home",
      "Assignments",
      "05 - Data Transformation"
    ]
  },
  {
    "objectID": "html_files/08_Strings/exercise_solutions.html",
    "href": "html_files/08_Strings/exercise_solutions.html",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "These exercises will help you practice applying separate_*, unite, regular expressions, and a bit with dates. You will use a messy dataset with information about cardiovascular disease (CVD).\n\n\nThese were the packages used for the exercises.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(gtsummary)\n\nWarning: package 'gtsummary' was built under R version 4.4.1\n\n\n\n\n\n\ncvd_messy_descr &lt;-\n  c(\"ID\" = 'Participant identification',\n    \"question_age\" = \"Question: how old are you / when where you born? Participants 51 or older answered the second question.\",\n    \"question_substance\" = 'Question: do you smoke or drink?',\n    \"question_bp\" = 'Question: what is your blood pressure? Are you taking medications to lower your blood pressure?',\n    \"labs\" = 'A collection of laboratory values concatenated into a single string. Notably, the order of lab values is random',\n    \"cvd_fup\" = 'Report of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview')\n\n# the enframe function transforms a vector into a tibble,\ntibble::enframe(cvd_messy_descr) |&gt; \n  gt::gt(rowname_col = \"name\") |&gt;\n  gt::tab_stubhead(label = 'Variable name') |&gt; \n  gt::cols_label(value = 'Variable description') |&gt; \n  gt::cols_align('left') |&gt; \n  gt::tab_header(title = 'Description of messy cardiovascular disease data')\n\n\n\n\n\n\n\nDescription of messy cardiovascular disease data\n\n\nVariable name\nVariable description\n\n\n\n\nID\nParticipant identification\n\n\nquestion_age\nQuestion: how old are you / when where you born? Participants 51 or older answered the second question.\n\n\nquestion_substance\nQuestion: do you smoke or drink?\n\n\nquestion_bp\nQuestion: what is your blood pressure? Are you taking medications to lower your blood pressure?\n\n\nlabs\nA collection of laboratory values concatenated into a single string. Notably, the order of lab values is random\n\n\ncvd_fup\nReport of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview\n\n\n\n\n\n\n\n\n\n\nLoad in the dataset which is called cvd_messy.\n\ncvd_messy &lt;- readr::read_rds('data/cvd_messy.rds')\n\ncvd_messy"
  },
  {
    "objectID": "html_files/08_Strings/exercise_solutions.html#setup",
    "href": "html_files/08_Strings/exercise_solutions.html#setup",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "These were the packages used for the exercises.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(gtsummary)\n\nWarning: package 'gtsummary' was built under R version 4.4.1"
  },
  {
    "objectID": "html_files/08_Strings/exercise_solutions.html#data-dictionary",
    "href": "html_files/08_Strings/exercise_solutions.html#data-dictionary",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "cvd_messy_descr &lt;-\n  c(\"ID\" = 'Participant identification',\n    \"question_age\" = \"Question: how old are you / when where you born? Participants 51 or older answered the second question.\",\n    \"question_substance\" = 'Question: do you smoke or drink?',\n    \"question_bp\" = 'Question: what is your blood pressure? Are you taking medications to lower your blood pressure?',\n    \"labs\" = 'A collection of laboratory values concatenated into a single string. Notably, the order of lab values is random',\n    \"cvd_fup\" = 'Report of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview')\n\n# the enframe function transforms a vector into a tibble,\ntibble::enframe(cvd_messy_descr) |&gt; \n  gt::gt(rowname_col = \"name\") |&gt;\n  gt::tab_stubhead(label = 'Variable name') |&gt; \n  gt::cols_label(value = 'Variable description') |&gt; \n  gt::cols_align('left') |&gt; \n  gt::tab_header(title = 'Description of messy cardiovascular disease data')\n\n\n\n\n\n\n\nDescription of messy cardiovascular disease data\n\n\nVariable name\nVariable description\n\n\n\n\nID\nParticipant identification\n\n\nquestion_age\nQuestion: how old are you / when where you born? Participants 51 or older answered the second question.\n\n\nquestion_substance\nQuestion: do you smoke or drink?\n\n\nquestion_bp\nQuestion: what is your blood pressure? Are you taking medications to lower your blood pressure?\n\n\nlabs\nA collection of laboratory values concatenated into a single string. Notably, the order of lab values is random\n\n\ncvd_fup\nReport of whether this participant exerienced a cardiovascular disease event (i.e., stroke or coronary heart disease) after their interview"
  },
  {
    "objectID": "html_files/08_Strings/exercise_solutions.html#import",
    "href": "html_files/08_Strings/exercise_solutions.html#import",
    "title": "Separate, unite, and strings",
    "section": "",
    "text": "Load in the dataset which is called cvd_messy.\n\ncvd_messy &lt;- readr::read_rds('data/cvd_messy.rds')\n\ncvd_messy"
  }
]